{"version":2,"ops":[{"type":1,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1601409500,"metadata":{"github-id":"MDU6SXNzdWU3MTE0MDcwNTU=","github-url":"https://github.com/dandi/dandi-cli/issues/249","origin":"github"},"title":"Python API: design","message":"Development prior this moment was targeting the command line client, and making it informative and \"nice looking\" to the users.  So some functionality (e.g. `ls`) still exists only as a \"click\" interface without underlying Python function.\n\nSome, more recently added or refactored, interfaces did get proper Python functions (e.g. `download`) but they seems\n  to provide neither \"the best\" (if any) return value Python coders would expect to receive, nor visual feedback to\n    the users using those functions \"interactive\" in Python shell or more likely - jupyter shell or notebook.  E.g. in    Jupyter notebook ATM `download` reports only INFO message that it is about to traverse the dandiset, and then no visual output until it is done (#246), and `download` returns no value.\n`validate` - is a generator which returns some (cryptic) records. \n`ls` - I think lacks any \"pure Python\" interface, and I guess others are not much better.\n\nSo it is time to harmonize Python interfaces and display produced by dandi commands.  Overall I think we should adopt\n DataLad's approach(es) which I mention below\n\n## Interfaces\n\n### Functions vs generators\n\n`download`, `upload`, `validate`, `ls`, `organize`: I think those should become/stay **generators** since they are\n intended to be ran for notable amount of time, so we better \"update\" outside code as soon as we know.\n\n`register`: could be just a function since it just needs to return a single value.\n\n### Returned values\n\nWe should make \"returned\" (yielded) values sensible for Python coding, in particular by default (i.e. without tuning  any options we might introduce).  In DataLad majority of commands now operate by returning \"result records\" and there is quite elaborate wrappers and invocation kwarg options which tune up returned values and behavior (datalad's `--on-failure {ignore,continue,stop}` e.g. to stop iterating as soon as first problem happened or not, etc) - it makes it flexible to compose multiple \"interfaces\" etc (but brings pains to debug at times; but here we will not have deep nesting of them).  In Python API DataLad's interfaces have \n\n```\nresult_xfm : {'datasets', 'successdatasets-or-none', 'paths', 'relpaths', 'metadata'} or callable or None, optional\n  if given, each to-be-returned result status dictionary is passed to\n  this callable, and its return value becomes the result instead. This\n  is different from `result_filter`, as it can perform arbitrary\n  transformation of the result value. This is mostly useful for top-\n  level command invocations that need to provide the results in a\n  particular format. Instead of a callable, a label for a pre-crafted\n  result transformation can be given. [Default: None]\nreturn_type : {'generator', 'list', 'item-or-list'}, optional\n  return value behavior switch. If 'item-or-list' a single value is\n  returned instead of a one-item return value list, or a list in case\n  of multiple return values. `None` is return in case of an empty\n  list. [Default: 'item-or-list']\n```\n\nwhere those kwarg default values can be interface specific.\nThat allows to make default returned value most convenient depending on how it is used (CLI vs Python API) and also\n to tune returned values (e.g. return full records vs just paths or some instance) where desired by outside code to\n  react more specifically. Default returned values could be \n\n- `download` -  file path(s) (`item-or-list`) as they are downloaded (or skipped if was so requested with `existing=` option).  If any path fails to download - at the end of the `download` we would raise an exception like `IncompleteDownloadError` (subclass of `IncompleteResultsError` - we have that one in datalad too) which would include paths for all files we failed to download.\n\n- `upload` - similarly yield paths of uploaded files\n\n- `register` - it is ok as a default;  but underlying record could be as returned from the API (coming) server (and\n only may be additionally annotated with the server information).\n\n#### Records\n\nActual underlying records may be very close if not identical to the records returned by the API (WiP).\nSo that unification might wait for API to stabilize a bit first, but meanwhile we could use records inspired by what\n datalad returns (see https://github.com/datalad/datalad/blob/master/datalad/interface/results.py#L46 (`get_status_dict`)) with fields `path`, `type` (typically a `file` but could be a `dandiset`), and `status`.  The rest would be command specific.\n\n### Display\n\nIf dandi-cli is used as a Python library for code to be ran in a terminal, or used interactively within ipython shell -- currently used pyout renders things nicely for `upload`, `download`, and `ls` commands.  Other commands do not use it.\nBut as mentioned above (#246) -- rendering in jupyter notebooks which are widely used now is problematic ATM with pyout.\nMost likely pyout will be fixed up (https://github.com/pyout/pyout/issues/120) for jupyter. But even then - we might want to provide simpler/leaner output for many such cases, and use pyout as the default one for CLI, while resorting to more basic display in any other case.  In particular, for use of dandi as underlying library by default no \"fancy\" output should be provided at all and we better just rely on the logger (which outside library can configure to its liking) to inform about progress of operations (e.g. for upload/download each 10% or each half-hour, whatever comes sooner, report overall progress (X (out of Y) files, A (out of B)TBs done) of operations.\n\nATM some commands provide options which affect \"display format\":\n- `ls`: ` -f, --format [auto|pyout|json|json_pp|yaml]`\n- `download`: `-f, --format [pyout|debug]` . With \"debug\" just printing those records it would have otherwise provide to `pyout` for rendering\n- `upload`: has no configurable display format, but with `--devel-debug` in `DEVEL_DEBUG=1` mode it disables use of pyout\n- `organize`, `register`, `validate`: no configurable display option. (`organize` has `--devel-debug` but that one just disables joblib.Parallel)\n\nI think we should aim to harmonize it: if all functions could return structured records, then we could pretty much adopt the approach of datalad to have `dandi -f {default,pyout,json,json_pp,yaml,tailored,'\u003ctemplate\u003e'},` with `default` possibly varying per command (e.g. tailored if present;).\n\n\n# Implementation\n\nDecouple display from 'implementation'. ATM `ls`, `upload` and `download` all rely on providing pyout records with  callbacks so it is for pyout to parallelize the invocation of callbacks.\nIMHO we should get away from that: may be it would still be allowed for records to have callbacks assigned to a tuple of fields, or just get a dedicated  `\"_callback\"` key and rely on the callback to return a `dict` which we would use to fill out returned fields. \nThen a corresponding generic logic would be used to either serialize or parallelize those callbacks, and feed corresponding  \"renderer\" (YAML, JSON, PyOUT etc like pretty much is done in `cmd_ls`) with either only a final record (e.g. yaml, json etc) or an \"update\" (in case of PyOUT).\nThis would allow for a consistent implementation and control of parallelization for any renderer (not just parallelize for pyout).\n\nNB parallelization is not solved for datalad internally yet either.  Situation is more complex though with all the \"subdatasets\" etc.","files":null}]}