{"version":2,"ops":[{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1649257582,"metadata":{"github-id":"IC_kwDODBZtRc5A_eGN","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1090380173"},"message":"From running the tests locally, the slowest 10 durations as reported by pytest are:\n\n```\n============================= slowest 10 durations =============================\n43.32s call     dandi/tests/test_bids_validator_xs.py::test_bids_datasets\n42.35s call     dandi/tests/test_validate.py::test_validate_bids\n31.97s setup    dandi/tests/test_dandiapi.py::test_upload\n14.49s call     dandi/tests/test_dandiapi.py::test_publish_and_manipulate\n11.70s teardown dandi/tests/test_validate.py::test_validate_bids\n8.49s call     dandi/tests/test_upload.py::test_upload_different_zarr_entry_conflicts\n8.14s call     dandi/tests/test_dandiapi.py::test_get_dandiset_published_other_version[True]\n8.05s call     dandi/tests/test_upload.py::test_upload_different_zarr_file_to_parent_dir\n7.14s call     dandi/tests/test_download.py::test_download_newest_version\n6.65s call     dandi/tests/test_dandiapi.py::test_get_dandiset_published_other_version[False]\n```\n\nNote that the \"setup\" and \"teardown\" entries are actually for the setup \u0026 teardown of the Dockerized dandi-archive environment.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1649868075,"metadata":{"github-id":"IC_kwDODBZtRc5BdjL-","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1098265342"},"message":"@TheChymera we might need to look into making bids testing leaner","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650277465,"metadata":{"github-id":"IC_kwDODBZtRc5BpGq7","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101294267"},"message":"one thing I can do is strip [the current testdata repo](https://github.com/dandi/bids-examples) down to a smaller amount of datasets. Other than that, they can probably also be parallelized, but validation is pretty quick at this stage so it's mainly download.","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650277984,"metadata":{"github-id":"IC_kwDODBZtRc5BpH1W","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101299030"},"message":"https://github.com/dandi/bids-examples/commit/0553aef7d9e7e1d5f042f54178a3a0b31e92bf16 took it down from 34s locally to 24s — another thing that's taking a bit is the full debugging output to stdout. I could:\n\n(1) remove it entirely from the validator (don't really like the idea, it's pretty useful particularly as we're still working on it)\n(2) remove it from testing.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650278130,"metadata":{"github-id":"UCE_lALODBZtRc5BpH1WziKJh5A"},"target":"fdc29ed15db818edf21503fc26c88f1389b1ce95949d115c6c039cd3ae91853e","message":"https://github.com/dandi/bids-examples/commit/0553aef7d9e7e1d5f042f54178a3a0b31e92bf16 took it down from 34s locally to 24s — maybe it is too slow :-/ but I don't think so, it's just a few seconds per dataset...","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650279549,"metadata":{"github-id":"IC_kwDODBZtRc5BpLD-","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101312254"},"message":"as of https://github.com/dandi/bids-examples/commit/9ed6649d2e14eec7fc7f0e5b2f1f11b7422af4d2 and https://github.com/dandi/dandi-cli/pull/955/commits/ca6e93d84817b9db70ee35cf2408277cce1f54cf it's down to 15s locally. Wouldn't strip it any furhter since we need datasets from different modalities.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650279586,"metadata":{"github-id":"UCE_lALODBZtRc5BpLD-ziKJncM"},"target":"d69801cd5cb16080f6deaf208ff17d3a4357f6f53914ba28aeb924c577636648","message":"as of https://github.com/dandi/bids-examples/commit/9ed6649d2e14eec7fc7f0e5b2f1f11b7422af4d2 and https://github.com/dandi/dandi-cli/pull/955/commits/ca6e93d84817b9db70ee35cf2408277cce1f54cf it's down to 15s on my machine. Wouldn't strip it any farhter since we need datasets from different modalities.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650288917,"metadata":{"github-id":"IC_kwDODBZtRc5Bpj64","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101414072"},"message":"Hm, I don't think it is worth stripping down datasets as the primary strategy to speed things up.  Do you know why it takes that while to go through them? :  \n- Is it IO or CPU bound? \n- If you run `py-spy` on that test process - what takes most of the time (regex matching?)?\nand then address corresponding bottle neck.\n\nIf we are to skip some datasets, just \"code that in\" in our tests: I would advise to avoid changing https://github.com/dandi/bids-examples beyond \"add few of our custom ones\" so we could later easily update for new example datasets etc.  As for how to \"code that in\" -- @jwodder , please advise on what would be the best way to orchestrate with pytest and our `bids_examples` fixture so unless some option is given to pytest (e.g., `all_bids_examples` mark), then \n```\ndandi/tests/test_validate.py:def test_validate_bids(bids_examples):\n```\nruns only a list of specific datasets there, not all.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650289136,"metadata":{"github-id":"IC_kwDODBZtRc5Bpkfh","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101416417"},"message":"@jwodder please also look into possibly optimizing\n```\n31.97s setup    dandi/tests/test_dandiapi.py::test_upload\n14.49s call     dandi/tests/test_dandiapi.py::test_publish_and_manipulate\n```\n[you listed](https://github.com/dandi/dandi-cli/issues/946#issuecomment-1090380173) . For `setup` -- what is spent time in docker compose -- to provision the environment? (then may be we could look into minimizing that) or some other steps?\n\nIn the test -- Is it a matter of file sizes for upload? slowness of API? or something else?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1650289313,"metadata":{"github-id":"IC_kwDODBZtRc5Bpk-D","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101418371"},"message":"@yarikoptic\n\n* `test_validate_bids` already limits what entries in `bids_examples` it validates to a fixed list.  Exactly what use do you envision for adding a option for testing custom sets of examples?\n* `setup` is largely multiple calls to `docker-compose`; I'm not sure which one takes the longest.\n* `test_publish_and_manipulate` publishes a Dandiset (which means waiting for the Dockerized server to validate it) and also uploads \u0026 downloads to it several times.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650290445,"metadata":{"github-id":"IC_kwDODBZtRc5BpoCJ","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101430921"},"message":"\u003e * `test_validate_bids` already limits what entries in `bids_examples` it validates to a fixed list.  Exactly what use do you envision for adding a option for testing custom sets of examples?\n\nmy bad -- I should have looked inside. indeed there is some whitelist.  Then I guess I am confused on what   @TheChymera was trying to achieve in [stripping datasets away](https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101299030).  @TheChymera -- were you removing files within those datasets??\n\nAlso @TheChymera  confusingly apparently there are two tests doing the same thing I think with just different \"validation\" entry points:\n\n- https://github.com/dandi/dandi-cli/blob/HEAD/dandi/tests/test_validate.py#L4  - `from dandi.validate import validate_bids`\n- https://github.com/dandi/dandi-cli/blob/HEAD/dandi/tests/test_bids_validator_xs.py#L291 - `from dandi.bids_validator_xs import validate_bids`  + has some more tests\n\nwhat is the point/need in having both of them?\n\nAlso I would recommend to move https://github.com/dandi/dandi-cli/blob/HEAD/dandi/tests/test_bids_validator_xs.py#L323 portion of that test into a dedicated test (eg. test_bids_datasets_selected_paths) . Probably moving out `whitelist` into module wide `BIDS_EXAMPLES_WHITELIST` constant to reuse across tests.  Then we would also see how long that particular portion of the test takes","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650290705,"metadata":{"github-id":"IC_kwDODBZtRc5Bpo1D","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101434179"},"message":"@jwodder \n\n\u003e * `setup` is largely multiple calls to `docker-compose`; I'm not sure which one takes the longest.\n\nPlease time then (`print` statements or some https://github.com/pyutils/line_profiler or alike could come handy) and see how long each one takes \n\n\u003e * `test_publish_and_manipulate` publishes a Dandiset (which means waiting for the Dockerized server to validate it) and also uploads \u0026 downloads to it several times.\n\ngood, very good test. Similarly -- what takes most of the time, anything in particular which we might see possible to optimize?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1650295281,"metadata":{"github-id":"IC_kwDODBZtRc5Bp3JB","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101492801"},"message":"@yarikoptic \n\n* Timings of `setup` steps (in seconds):\n    * `manage.py migrate`: 18.001302003860474\n    * `manage.py createsuperuser`: 3.3786816596984863\n    * `manage.py drf_create_token`: 3.290635108947754\n    * `up -d`: 2.275557279586792\n    * Waiting for containers to be ready: 4.523201942443848\n* Timings of major `test_publish_and_manipulate` steps (in seconds):\n    * initial upload: 1.5072083473205566\n    * wait_until_valid(): 2.692340850830078\n    * publish(): 0.2717759609222412\n    * Download published version: 1.2773911952972412\n    * Upload modified draft: 0.9313299655914307\n    * Download published version: 1.1366846561431885\n    * Upload modified draft: 1.025101900100708\n    * Download draft version: 1.8018062114715576\n    * Download published version: 1.4370958805084229\n    * Download draft version: 1.2907021045684814\n    * Download published version: 1.350187063217163","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1650295385,"metadata":{"github-id":"UCE_lALODBZtRc5Bp3JBziKK4PA"},"target":"9deb38955024c9565dcf82ec0c74b84490ac0f84c9578d9fe8ea987a470901ae","message":"@yarikoptic \n\n* Timings of `setup` steps (in seconds):\n    * `manage.py migrate`: 18.001302003860474\n    * `manage.py createsuperuser`: 3.3786816596984863\n    * `manage.py drf_create_token`: 3.290635108947754\n    * `up -d`: 2.275557279586792\n    * Waiting for containers to be ready: 4.523201942443848\n* Timings of major `test_publish_and_manipulate` steps (in seconds):\n    * initial upload: 1.5072083473205566\n    * wait_until_valid(): 2.692340850830078\n    * publish(): 0.2717759609222412\n    * Download published version: 1.2773911952972412\n    * Upload modified draft: 0.9313299655914307\n    * Download published version: 1.1366846561431885\n    * Upload modified draft: 1.025101900100708\n    * Download draft version: 1.8018062114715576\n    * Download published version: 1.4370958805084229\n    * Download draft version: 1.2907021045684814\n    * Download published version: 1.350187063217163\n\nFor `test_publish_and_manipulate`, the test could be rewritten to do all of its post-publication manipulations in a single \"cycle\" so that upload + download draft + download published only happens once.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650309718,"metadata":{"github-id":"IC_kwDODBZtRc5BqmYc","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1101686300"},"message":"So the major contributor of setup is `manage.py migrate: 18.001302003860474`.  I wonder if it does migrate something and we just need may be to update starting state or what does it really do for over half a minute?\n\nAll downloads take over a second, so might be worth looking into a singular download -- what makes it take that long,  it must not be data size which must be tiny, right?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1650375432,"metadata":{"github-id":"IC_kwDODBZtRc5BuV2i","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102667170"},"message":"\u003e I wonder if it does migrate something and we just need may be to update starting state or what does it really do for over half a minute?\n\ncc @dchiquito @AlmightyYakob @mvandenburgh","files":null},{"type":3,"author":{"id":"a9e2633aeb6d7e2366a97d09712312c2442c6054"},"timestamp":1650387101,"metadata":{"github-id":"IC_kwDODBZtRc5BvITO","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102873806"},"message":"\u003e \u003e I wonder if it does migrate something and we just need may be to update starting state or what does it really do for over half a minute?\n\u003e \n\u003e cc @dchiquito @AlmightyYakob @mvandenburgh\n\n`migrate` is populating the empty postgres database with all required models (and possibly other steps to represent a default app). If you wanted to skip `migrate` you'd need to run `migrate` beforehand and re-use that same postgres database. This presents a couple of problems:\n\n1. You'd need to have one test database that you hosted somewhere for this purpose, since the tests are bringing up an empty postgres db every time. This would also potentially present issues with concurrent access by tests running at the same time, conflicts, etc.\n2. You'd need to determine when to actually run new migrations, since if we add any migrations they need to be updated in that test postgres db. This could likely be accomplished with CI.\n\nI'm not sure why it's taking 18 seconds, but it's not _too_ surprising.","files":null},{"type":3,"author":{"id":"c3aba9547dfec2aff2928d9a69b39673172a76a7"},"timestamp":1650387599,"metadata":{"github-id":"IC_kwDODBZtRc5BvKH_","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102881279"},"message":"We could also try squashing the migrations. Not sure what kind of speed up it would give, but it would probably do something.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650392868,"metadata":{"github-id":"IC_kwDODBZtRc5BvclW","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102956886"},"message":"I do not quite get why there would be any problem @AlmightyYakob mentions [above](https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102873806) if we pre-migrate and save that docker image for reuse as the image instead of redoing migrations every time...\n\nare migrations  \"idempotent\" (can I run `migrate` multiple times without changes to  arrive to the same result or no action in subsequent?) and \"incremental\" (if we pre-migrate and I run with some newer set of migrations -- would then only not previously applied apply)?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650392997,"metadata":{"github-id":"IC_kwDODBZtRc5BvdEU","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102958868"},"message":"\u003e I do not quite get why there would be any problem @AlmightyYakob mentions [above](https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102873806) if we pre-migrate and save that docker image for reuse as the image instead of redoing migrations every time...\n\ndoh -- I probably forgot that we are talking about \"volumes\" and not images here so I am now not even sure how we could ship pre-migrated volume.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1650393029,"metadata":{"github-id":"IC_kwDODBZtRc5BvdLs","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1102959340"},"message":"My understanding is that database migrations themselves are only necessary if the database is using an old version of the application's DB schema.  Does Django not have a way to instantiate a database using just the current model definitions, thereby obviating the need for migrations?","files":null},{"type":3,"author":{"id":"a9e2633aeb6d7e2366a97d09712312c2442c6054"},"timestamp":1650401038,"metadata":{"github-id":"IC_kwDODBZtRc5BwIvS","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1103137746"},"message":"\u003e are migrations \"idempotent\" (can I run `migrate` multiple times without changes to arrive to the same result or no action in subsequent?) and \"incremental\" (if we pre-migrate and I run with some newer set of migrations -- would then only not previously applied apply)?\n\nThe answer to both of these questions is yes.\n\n\n\u003e My understanding is that database migrations themselves are only necessary if the database is using an old version of the application's DB schema. Does Django not have a way to instantiate a database using just the current model definitions, thereby obviating the need for migrations?\n\n\nMigrations will always be needed on a fresh postgres database, since migrations are what populates the database with the required tables and relationships that the applications needs to function. Django does have a way to create these migrations automatically based on model definitions (`manage.py makemigrations`, indeed what we use anytime we add/modify/delete models), but there are also some hand written migrations in our app which are required for full functionality.\n\n\nIMO, I'm not really sure any of this would make much of a difference for CLI test timing. Pulling from the last run of the CLI tests in our CI (https://github.com/dandi/dandi-archive/runs/6084842248?check_suite_focus=true), the tests take almost 7 minutes to run. Shaving off even the full 18 seconds wouldn't really matter much here, since `migrate` is only run once, before the tests begin.","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650460669,"metadata":{"github-id":"IC_kwDODBZtRc5BzIMM","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1103921932"},"message":"For the BIDS part at least, looking into this over here. Draft for now, more might come later. https://github.com/dandi/dandi-cli/pull/965","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1650580594,"metadata":{"github-id":"IC_kwDODBZtRc5B6ZXC","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1105827266"},"message":"@TheChymera Did you try to py-spy the BIDS testing to assess what most of the time is spent on?","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650868031,"metadata":{"github-id":"IC_kwDODBZtRc5CDK8t","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1108127533"},"message":"@yarikoptic so it seems that match is taking no time at all, and a lot of overhead is coming from `ruamel-yaml`.\n\nThis is the output of:\n```\npy-spy top -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/0e2847.md\n\n\nThis is the output of:\n```\npy-spy record --format speedscope -o profile.svg -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/bf78ac.svg (can be opened with https://www.speedscope.app/ ).\n\nNo idea what to do about this, or whether the issue is with:\n* my usage of the upstream BIDS code\n* the upstream BIDS code\n* someting in `ruamel-yaml`\n\nAll the functions listed under the load section seem to be `ruamel-yaml` internals — particularly check_event `(ruamel/yaml/parser.py:146)`. To be fair both my code and the BIDS code does a bit of iteration over the dictionary, but I don't think that should show up as belonging to the YAML parser.\n\nAlso the evaluation makes it look like `load_all` is run twice for each dataset. Not sure why, I checked manually and it only runs once.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650868235,"metadata":{"github-id":"UCE_lALODBZtRc5CDK8tziK2k2U"},"target":"e0b2299e927fbde206d1e197eae40660a08901e294a79a3b0d54ee9c10c91c25","message":"@yarikoptic so it seems that match is taking no time at all, and a lot of overhead is coming from `ruamel-yaml`.\n\nThis is the output of:\n```\npy-spy top -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/0e2847.md\n\n\nThis is the output of:\n```\npy-spy record --format speedscope -o profile.svg -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/bf78ac.svg (can be opened with https://www.speedscope.app/ ).\n\nNo idea what to do about this, or whether the issue is with:\n* my usage of the upstream BIDS code\n* the upstream BIDS code\n* someting in `ruamel-yaml`\n\nAll the functions listed under the load section seem to be `ruamel-yaml` internals — particularly check_event `(ruamel/yaml/parser.py:146)`. Both my code and the BIDS code do a bit of iteration — mine does it over entries, which I don't think should show up as belonging to the YAML parser. The upstream code runs `_yaml.load()` for each object and rules file, which would fit the picture, but there are only 24 files, I doubt that should take so long, and no idea really how that could be reduced.\n\nAlso the evaluation makes it look like `load_all` is run twice for each dataset. Not sure why, I checked manually and it only runs once.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650868835,"metadata":{"github-id":"UCE_lALODBZtRc5CDK8tziK2n7s"},"target":"e0b2299e927fbde206d1e197eae40660a08901e294a79a3b0d54ee9c10c91c25","message":"@yarikoptic so it seems that match is taking no time at all, and a lot of overhead is coming from `ruamel-yaml`.\n\nThis is the output of:\n```\npy-spy top -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/0e2847.md\n\n\nThis is the output of:\n```\npy-spy record --format speedscope -o profile.svg -- pytest -vvs tests/test_bids_validator_xs.py::test_bids_datasets\n```\nhttps://ppb.chymera.eu/bf78ac.svg (can be opened with https://www.speedscope.app/ ).\n\nNo idea what to do about this, or whether the issue is with:\n* my usage of the upstream BIDS code\n* the upstream BIDS code\n* someting in `ruamel-yaml`\n\nAll the functions listed under the load section seem to be `ruamel-yaml` internals — particularly check_event `(ruamel/yaml/parser.py:146)`. Both my code and the BIDS code do a bit of iteration — mine does it over a list of dictionaries, which I don't think should show up as belonging to the YAML parser. The upstream code runs `_yaml.load()` for each object and rules file, which would fit the picture, but there are only 24 files, I doubt that should take so long, and no idea really how that could be reduced.\n\nAlso the evaluation makes it look like `load_all` is run twice for each dataset. Not sure why, I checked manually and it only runs once.","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650869901,"metadata":{"github-id":"IC_kwDODBZtRc5CDPn2","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1108146678"},"message":"Hmmmm indeed it seems to be half from me:\n\n```console\nchymera@decohost ~/src/dandi-cli $ time python -c \"from dandi import bids_validator_xs; bids_validator_xs.load_all('dandi/support/bids/schemadata/1.7.0+012+dandi001/')\"\n\nreal\t0m1.926s\nuser\t0m1.886s\nsys\t0m0.040s\n\nchymera@decohost ~/src/dandi-cli $ time python -c \"from dandi.support.bids import schema; schema.load_schema('dandi/support/bids/schemadata/1.7.0+012+dandi001/')\"\n\nreal\t0m1.125s\nuser\t0m1.087s\nsys\t0m0.038s\n```\n\nThe issue seems to have been that although `dandi.bids_validator_xs.load_all()` is only run once, it runs `dandi.support.bids.schema.load_schema()` internally due to carry-over from an older logic. \n\nFixed in https://github.com/dandi/dandi-cli/pull/982 but might not improve it by more than 50%. Maybe that's ok?","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650870941,"metadata":{"github-id":"UCE_lALODBZtRc5CDPn2ziK2ytY"},"target":"c010f66ae5bfcb18862793fc69c93817adc1075d7e06e912ecf9a05d42240d4b","message":"Hmmmm indeed it seems to be half from me:\n\n```console\nchymera@decohost ~/src/dandi-cli $ time python -c \"from dandi import bids_validator_xs; bids_validator_xs.load_all('dandi/support/bids/schemadata/1.7.0+012+dandi001/')\"\n\nreal\t0m1.926s\nuser\t0m1.886s\nsys\t0m0.040s\n\nchymera@decohost ~/src/dandi-cli $ time python -c \"from dandi.support.bids import schema; schema.load_schema('dandi/support/bids/schemadata/1.7.0+012+dandi001/')\"\n\nreal\t0m1.125s\nuser\t0m1.087s\nsys\t0m0.038s\n```\n\nThe issue seems to have been that although `dandi.bids_validator_xs.load_all()` was only run once, it ran `dandi.support.bids.schema.load_schema()` twice internally due to carry-over from an older logic. \n\nFixed in https://github.com/dandi/dandi-cli/pull/982 but might not improve it by more than 50%. Maybe that's ok?","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650870794,"metadata":{"github-id":"IC_kwDODBZtRc5CDTU8","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1108161852"},"message":"\u003e 18.07s call     dandi/tests/test_bids_validator_xs.py::test_bids_datasets\n\nvs.\n\n\u003e 31.65s call     dandi/tests/test_bids_validator_xs.py::test_bids_datasets\n\nStill the slowest test, but yes, went down by almost 50%.\nBeyond this we probably need to look at `ruamel-yaml`, since the BIDS code seems pretty straight-forward.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650870847,"metadata":{"github-id":"UCE_lALODBZtRc5CDTU8ziK2yNo"},"target":"a9dc56e73b8389cfe9aef6d489f1516658d0c7393b844d3567ce6fdd60710c5f","message":"\u003e 18.07s call     dandi/tests/test_bids_validator_xs.py::test_bids_datasets\n\nvs.\n\n\u003e 31.65s call     dandi/tests/test_bids_validator_xs.py::test_bids_datasets\n\nStill the slowest test, but yes, went down by almost 50%.\nBeyond this we probably need to parallelize and/or look at `ruamel-yaml`, since the BIDS code seems pretty straight-forward.","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650953347,"metadata":{"github-id":"IC_kwDODBZtRc5CH9nl","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1109383653"},"message":"After the merged PR, there doesn't seem to be any obvious main time hog any more. The entire validation seems to take around 1s for all datasets, and before that there are about 2s more chalked up to pytest internals such as `parse (/usr/lib/python3.9/site-packages/_pytest/config/__init__.py:1304)`.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650953391,"metadata":{"github-id":"UCE_lALODBZtRc5CH9nlziK_-ZY"},"target":"23e17907223cdc06844114753bf435ca2f23e9ba990c4b9861c95081a16634a0","message":"After the merged PR, there doesn't seem to be any obvious main time hog any more. The entire validation seems to take around 1s for all datasets, and before that there are about 2s more chalked up to pytest internals such as `parse (/usr/lib/python3.9/site-packages/_pytest/config/__init__.py:1304)`.\n\nhttps://ppb.chymera.eu/85e818.svg — again, not a normal SVG files, best opened via https://www.speedscope.app/ .","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1650953399,"metadata":{"github-id":"UCE_lALODBZtRc5CH9nlziK_-cc"},"target":"23e17907223cdc06844114753bf435ca2f23e9ba990c4b9861c95081a16634a0","message":"After the merged PR, there doesn't seem to be any obvious main time hog any more. The entire validation seems to take around 1s for all datasets, and before that there are about 2s more chalked up to pytest internals such as `parse (/usr/lib/python3.9/site-packages/_pytest/config/__init__.py:1304)`.\n\nhttps://ppb.chymera.eu/85e818.svg — again, not a normal SVG file, best opened via https://www.speedscope.app/ .","files":null},{"type":5,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658935048,"metadata":{"github-id":"LE_lADODBZtRc5HJXfBzwAAAAGlo_CB"},"added":["tests"],"removed":[]},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658935136,"metadata":{"github-id":"IC_kwDODBZtRc5HVzaN","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1196897933"},"message":"@yarikoptic Is there anything to still do for this issue?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1670446213,"metadata":{"github-id":"IC_kwDODBZtRc5P9t8F","github-url":"https://github.com/dandi/dandi-cli/issues/946#issuecomment-1341579013"},"message":"let's consider it done FWIW since there were some improvements, but given that lots of slow ones remain we might come back to it afresh.","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1670446214,"metadata":{"github-id":"CE_lADODBZtRc5HJXfBzwAAAAHbwaTq"},"status":2}]}