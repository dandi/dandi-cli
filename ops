{"version":2,"ops":[{"type":1,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1717455778,"metadata":{"github-id":"I_kwDODBZtRc6LArKe","github-url":"https://github.com/dandi/dandi-cli/issues/1448","origin":"github"},"title":"Change validation of files (assets) to align with validation on the server","message":"The underlying trigger for the issue is\n\n- https://github.com/dandi/dandi-archive/issues/1944\n\nwhere assets started to fail validation, preventing publishing of dandisets, only when already on the archive.  It boiled down to the fails in validation against `jsonschema` export of pydantic models which is done to guarantee that meditor validation could be done online (thus in JS), and the difference in treating `date-time` format by jsonschema and pydantic (datetime).\n\nLooking at the code, in dandi-archive we do\n\n```python\nfrom dandischema.metadata import aggregate_assets_summary, validate\n...\n            metadata = asset.published_metadata()\n            validate(metadata, schema_key='PublishedAsset', json_validation=True)\n```\n\nwhile in the dandi-cli we do not use `dandischema..validate` construct and rather \n\n```\n        try:\n            asset = self.get_metadata(digest=self._DUMMY_DIGEST)\n            BareAsset(**asset.model_dump())\n        except ValidationError as e:\n            if devel_debug:\n                raise\n            return _pydantic_errors_to_validation_results(\n                e, self.filepath, scope=Scope.FILE\n            )\n```\n\nso in effect only validating against Pydantic (and for a BareAsset).\n\nWe should harmonize, and I feel that here we should use `dandischema.metadata.validate`.  I think it also aligns better with our desire to separate models from intended \"validity\" assumptions.","files":null}]}