{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1762393044,"metadata":{"github-id":"IC_kwDODBZtRc7QSILL","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3494413003"},"message":"@candleindark please have a look at this","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762451223,"metadata":{"github-id":"IC_kwDODBZtRc7QiFnq","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3498596842"},"message":"In the first pass, the errors seem to be failures in validating the dataset as a BIDS dataset. The 5 errors coming from `bids_validator_deno` are logged as a warning through the Python log system. The `bids_validator_deno` we put in awhile back is more restrictive than the previous validator.\n\n@kabilar Is it possible to have the collaborator to validate the dataset as a BIDS dataset at https://bids-standard.github.io/bids-validator/ or using https://pypi.org/project/bids-validator-deno/?\n\nNote (to self): The complain about `dandiset.yaml` shouldn't be there. The BIDS validator should be configured to ignore that in dandi-cli.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1762451659,"metadata":{"github-id":"IC_kwDODBZtRc7QiN7M","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3498630860"},"message":"@candleindark and @yarikoptic - just a bit of a note for the bids datasets that for many of these projects (not this one specifically), data are being generated in pieces at different institutions on the same samples (similar to dandiset 26). so many sites will be doing partial uploads. i just want to make sure that the cli will understand this. i can't remember now if this was implemented or not. i.e it should assume validity online (we can force a check on the archive in the future), and then ask if the files that are being uploaded are valid in the context of the dataset. this is more complicated, but most folks for these large datasets will not be able to download (or better should not have to download the dataset). \n\nat present i believe @kabilar has been instructing people to skip validation, which is not a good thing.","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762456042,"metadata":{"github-id":"IC_kwDODBZtRc7Qjjp2","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3498982006"},"message":"\u003e for many of these projects (not this one specifically), data are being generated in pieces at different institutions on the same samples (similar to dandiset 26). so many sites will be doing partial uploads. i just want to make sure that the cli will understand this. i can't remember now if this was implemented or not.\n\nPartial upload is implemented according to the documentation. One an upload specific files in a Dandiset. There is an `--existing` option in the upload subcommand to handle the situation in which a file to be uploaded already exists on the server.\n\n\u003e at present i believe @kabilar has been instructing people to skip validation, which is not a good thing.\n\nThe `upload` subcommand in dandi-cli has the `--validation skip` option. Is this what you are referring to, @satra? How would you do it otherwise if you are to assume the validity of the data to be valid at the time of upload?","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1762456450,"metadata":{"github-id":"IC_kwDODBZtRc7Qjp62","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3499007670"},"message":"\u003e The upload subcommand in dandi-cli has the --validation skip option. Is this what you are referring to\n\nyes, that. i would expect that a virtual dataset is created and the validation of names/paths is done over that virtual dataset. the current bids validator doesn't do that (i believe) and will also need access to the content, which makes this more tricky.\n\nthere was an effort in the cli for a light-weight validator that just checked paths (which is where most of the people make their mistakes). \n\nso ideally when `--existing` is passed, the validation step will treat them together as a virtual dataset.","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762456551,"metadata":{"github-id":"IC_kwDODBZtRc7QjrU5","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3499013433"},"message":"@kabilar I may have gotten the intend of this issue wrong initially.\n\nThe issue you are reporting is about the apparent inconsistency in the log levels of the logged warnings/errors and not about the warnings/errors themselves, right?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1762463699,"metadata":{"github-id":"IC_kwDODBZtRc7QlOGe","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3499418014"},"message":"yes, originally we were validating ONLY the filepaths to be legit using bidsschematools, now we run `bids-validator-deno`, thus pretty much relying on having a full bids dataset locally.  With `--validation skip` we would skip all validations.  I initiated a dedicated \n\n- https://github.com/dandi/dandi-cli/issues/1737\n\nas for actual original errors:\n\n- those warnings are legit WARNINGS (not ERRORS!) and point to deficiencies (not problems per se) where RECOMMENDED (not REQUIRED) fields of the dataset_description.json are missing which I guess all of them have but all of them have it incomplete\n- the ERROR one is about the `dandiset.yaml` which is not part of the bids spec . Ideally we should instruct bids-validator to ignore that file alone!  ATM we only instruct (is that part of the log?)\n\n```\n‚ùØ git grep -5 .bidsignore\ndandi/validate.py-                        == dandiset_metadata_file\ndandi/validate.py-                    ):\ndandi/validate.py-                        r.message = (\ndandi/validate.py-                            f\"The dandiset metadata file, `{dandiset_metadata_file}`, \"\ndandi/validate.py-                            f\"is not a part of BIDS specification. Please include a \"\ndandi/validate.py:                            f\"`.bidsignore` file with specification to ignore the \"\ndandi/validate.py-                            f\"metadata file in your dataset. For more details, see \"\ndandi/validate.py-                            f\"https://github.com/bids-standard/bids-specification/\"\ndandi/validate.py-                            f\"issues/131#issuecomment-461060166.\"\ndandi/validate.py-                        )\ndandi/validate.py-                    df_results.append(r)\n```\n\nbut I think we should take approach similar to openneuro to provide custom configuration file for bids-validator , see https://github.com/bids-standard/bids-validator?tab=readme-ov-file#configuration-file, which would ignore such an error. But I wonder how were we validating all other BIDS dandisets @candleindark ?","files":null},{"type":5,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1762463720,"metadata":{"github-id":"LE_lADODBZtRc7WGtywzwAAAATWFos-"},"added":["cmd-upload"],"removed":[]},{"type":3,"author":{"id":"d8203afd43c9e0a9d07c45dd62b58a81d53a2ebe"},"timestamp":1762526093,"metadata":{"github-id":"IC_kwDODBZtRc7Qyk5L","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3502919243"},"message":"\u003e The issue you are reporting is about the apparent inconsistency in the log levels of the logged warnings/errors and not about the warnings/errors themselves, right?\n\nYes, thanks, the issue is about the inconsistency.","files":null},{"type":3,"author":{"id":"d8203afd43c9e0a9d07c45dd62b58a81d53a2ebe"},"timestamp":1762526271,"metadata":{"github-id":"IC_kwDODBZtRc7QyoxA","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3502935104"},"message":"\u003e at present i believe @kabilar has been instructing people to skip validation, which is not a good thing.\n\nIn the past, I was indeed instructing people to skip validation if the data were not named correctly and suggested that we name the files correctly in the future. But I have been moving away from this approach. In this case, I worked with the team to organize and name the files correctly, and we did not skip validation.","files":null},{"type":3,"author":{"id":"d8203afd43c9e0a9d07c45dd62b58a81d53a2ebe"},"timestamp":1762526409,"metadata":{"github-id":"IC_kwDODBZtRc7Qyr1x","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3502947697"},"message":"\u003e Note (to self): The complain about dandiset.yaml shouldn't be there. The BIDS validator should be configured to ignore that in dandi-cli.\n\n\u003e the ERROR one is about the dandiset.yaml which is not part of the bids spec . Ideally we should instruct bids-validator to ignore that file alone! ATM we only instruct (is that part of the log?) but I think we should take approach similar to openneuro to provide custom configuration file for bids-validator , see https://github.com/bids-standard/bids-validator?tab=readme-ov-file#configuration-file, which would ignore such an error.\n\n+1","files":null},{"type":3,"author":{"id":"d8203afd43c9e0a9d07c45dd62b58a81d53a2ebe"},"timestamp":1762526724,"metadata":{"github-id":"IC_kwDODBZtRc7Qyy5q","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3502976618"},"message":"\u003e those warnings are legit WARNINGS (not ERRORS!) and point to deficiencies (not problems per se) where RECOMMENDED (not REQUIRED) fields of the dataset_description.json are missing which I guess all of them have but all of them have it incomplete\n\nSo then should we change the `dandi-cli` so that the following is logged as a `WARNING`?\n\n```\n2025-10-30T14:58:37-0400 [ERROR   ] dandi 21478:126210317428416 Error uploading /home/bglickman/I74_uCT_Lichtman/000049/dataset_description.json:\n```","files":null},{"type":3,"author":{"id":"d8203afd43c9e0a9d07c45dd62b58a81d53a2ebe"},"timestamp":1762527593,"metadata":{"github-id":"IC_kwDODBZtRc7QzEst","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3503049517"},"message":"Regarding the discussion on partial uploads, we have been doing it using the following steps and it has been working:\n\n1. Download the \"empty\" Dandiset:\n  `dandi download --preserve-tree dandi://linc/000010@draft/dataset_description.json`\n2. Add new files to the Dandiset directory\n3. Run `dandi upload`. Validation occurs on the files that are added to the Dandiset locally. (The log files do not suggest that validation runs on the local files that are being uploaded and in the context of the remote files, which what Satra is suggesting.)","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762536190,"metadata":{"github-id":"IC_kwDODBZtRc7Q14JT","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3503784531"},"message":"\u003e \u003e those warnings are legit WARNINGS (not ERRORS!) and point to deficiencies (not problems per se) where RECOMMENDED (not REQUIRED) fields of the dataset_description.json are missing which I guess all of them have but all of them have it incomplete\n\u003e \n\u003e So then should we change the `dandi-cli` so that the following is logged as a `WARNING`?\n\u003e \n\u003e ```\n\u003e 2025-10-30T14:58:37-0400 [ERROR   ] dandi 21478:126210317428416 Error uploading /home/bglickman/I74_uCT_Lichtman/000049/dataset_description.json:\n\u003e ```\n\nThe logs at the level of WARNING came directly from the BIDS validator. This one though was logged by `dandi-cli` as result of the failure to upload the `dataset_description.json` file  because uploading requires validation.","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762642673,"metadata":{"github-id":"IC_kwDODBZtRc7RCmHD","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3507118531"},"message":"Should we close this issue now that the level of the logs are explained? The https://github.com/dandi/dandi-cli/issues/1737 spinoff will be address separately though.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1762646420,"metadata":{"github-id":"IC_kwDODBZtRc7RC2-O","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3507187598"},"message":"@candleindark what about that error on dandiset.yaml and my question: \n\n\u003e but I think we should take approach similar to openneuro to provide custom configuration file for bids-validator , see https://github.com/bids-standard/bids-validator?tab=readme-ov-file#configuration-file, which would ignore such an error. But I wonder how were we validating all other BIDS dandisets @candleindark ?","files":null},{"type":3,"author":{"id":"f3557c4ceea08ee5e22c6aab1e8604bfb798bfa4"},"timestamp":1762898965,"metadata":{"github-id":"IC_kwDODBZtRc7Rvkd4","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3518908280"},"message":"\u003e [@candleindark](https://github.com/candleindark) what about that error on dandiset.yaml and my question:\n\nWith the current implementation, the error regarding `dandiset.yaml` can be set to be ignored by providing a `.bidsignore` file, https://github.com/bids-standard/bids-specification/issues/131#issuecomment-461060166.\n\n\u003e \u003e but I think we should take approach similar to openneuro to provide custom configuration file for bids-validator , see https://github.com/bids-standard/bids-validator?tab=readme-ov-file#configuration-file, which would ignore such an error. But I wonder how were we validating all other BIDS dandisets [@candleindark](https://github.com/candleindark) ?\n\nThe Python wrapper for `bids-validator-deno` is already capable of invoking `bids-validator-deno` with a config specified in a Python dictionary. With some modification, I can make it take a config file as well. At this point, the `--config` option in `bids-validator-deno` is not utilized as indicated in the only invocation of `bids-validator-deno` at https://github.com/dandi/dandi-cli/blob/e734c68994f1a0e8c4826c6ae041bf6fc0d57e25/dandi/files/bids.py#L115.\n\nTo pass in a config file to `bids-validator-deno`, we will have to add an option in both `dandi validate` and `dandi upload` that provides the path to the config file to achieve consistent behavior in both commands.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1762960080,"metadata":{"github-id":"IC_kwDODBZtRc7R8-os","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3522423340"},"message":"\u003e \u003e [@candleindark](https://github.com/candleindark) what about that error on dandiset.yaml and my question:\n\u003e \n\u003e With the current implementation, the error regarding `dandiset.yaml` can be set to be ignored by providing a `.bidsignore` file, [bids-standard/bids-specification#131 (comment)](https://github.com/bids-standard/bids-specification/issues/131#issuecomment-461060166).\n\nMy point is that we should facilitate that for a user one way or another... thinking about `.bidsignore` vs custom config -- since they could just run `bids-validator` themselves, ideally indeed there should be `.bidsignore` file physically present in the dataset, and we should not (ab)use config file since there is AFAIK no way to provide multiple\n\n- https://github.com/bids-standard/bids-validator/issues/294\n\nand thus we should not rely on some \"temp config\" since dataset could come with its own... Unless we instead of .bidsignore use that config but then situation is the same and IMHO `.bidsignore` is an easier target.\n\nI think we should address that with\n\n- better documentation that in case of BIDS datasets there should be `.bidsignore` containing `dandiset.yaml` (although we do not even have it in \"online\" version of dandiset). Filed https://github.com/dandi/dandi-docs/pull/215 , please review/improve\n- somehow/somewhere assist with producing such .bidsignore file - likely in `nwb2bids` (https://github.com/con/nwb2bids/issues/185) or may be future version of `dandi organize` which would use it\n- ensure that we do consider/upload `.bidsignore` file if present, even though it is not part of BIDS specification. @candleindark please ensure that. Also the same for `.bids-validator-config.json` although it is not yet \"default\" in a new validator (https://github.com/bids-standard/bids-validator/issues/293)\n\nNB I think @CodyCBakerPhD didn't run into this yet in the https://github.com/bids-dandisets effort since he is producing them from nwb files and thus there is no dandiset.yaml in those cases.","files":null},{"type":3,"author":{"id":"7eea5bdd45d6b031d3bf16a241db06db985fb528"},"timestamp":1762962616,"metadata":{"github-id":"IC_kwDODBZtRc7R9yAY","github-url":"https://github.com/dandi/dandi-cli/issues/1734#issuecomment-3522633752"},"message":"Would we eve rconsider making it `.dandiset.yaml`? (might automatically resolve such issues)\n\n\u003e NB I think @CodyCBakerPhD didn't run into this yet in the https://github.com/bids-dandisets effort since he is producing them from nwb files and thus there is no dandiset.yaml in those cases.\n\nI did this explicitly as a part of BIDS-Dandisets: https://github.com/bids-dandisets/000003/blob/draft/.bidsignore","files":null}]}