{"version":2,"ops":[{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739372468,"metadata":{"github-id":"UCE_lAHODBZtRc6pyCG3znGQWAs"},"target":"2d86acc3f87b2de502ef7037db30fb16bffe1634fbe554e33cfc05453726afa2","message":"Came up in a meetup with @talmo re their experiences in SLEAP working with video recordings of behavioral data.  In their experience, many, if not most, videos coming from audio/video recording hardware would be either uncompressed or badly compressed, resulting in those recordings taking LOTS of space (placing the aspect of number of files aside for now).  For that reason in https://sleap.ai/help.html#does-my-data-need-to-be-in-a-particular-format they provide recommended settings for ffmpeg to see such files compressed:\n\n```\nffmpeg -y -i \"input.mp4\" -c:v libx264 -pix_fmt yuv420p -preset superfast -crf 23 \"output.mp4\"\n```\n\nSimilarly, for ReproNim's reprostim project, where we capture audio/video of presented to MRI experiment stimuli using cheap magewell capture card, and on a small underpowered hardware, with @vmdocua we specify default settings in https://github.com/ReproNim/reprostim/blob/master/src/reprostim-capture/videocapture/config.yaml#L105 for ffmpeg video component as\n\n```\n-c:v libx264 -flush_packets 1 -preset ultrafast -crf 18 -tune zerolatency -b:v 8M -maxrate 8M -bufsize 16M -vf setpts=PTS-STARTPTS\n```\n\nATM.\n\nIn DANDI we already have 15 dandisets with video (.mkv or .mp4; might have missed others, invocation was `for f in 00*; do find $ds -iname '*.avi' -o -iname '*.mkv'; done \u003e /tmp/videos.txt`)\n\n~~(note  000559 contains over 2M files!)~~  edited: my invocation was bad/wrong... redoing\n\nI think it would be \n\n- useful to provide some guidance at the time of validation/upload to ensure that videos uploaded to archive are appropriately compressed and we are not blowing up the size of the archive with loosely or uncompressed videos.  Yet to figure out usable procedures for that but could be pretty much taking a sample video and recompressing with \"recommended\" settings and seeing how well it compresses\n- reviewing current videos in the archive and issue such recommendations?","files":null},{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739374019,"metadata":{"github-id":"UCE_lAHODBZtRc6pyCG3znGRH-c"},"target":"2d86acc3f87b2de502ef7037db30fb16bffe1634fbe554e33cfc05453726afa2","message":"Came up in a meetup with @talmo re their experiences in SLEAP working with video recordings of behavioral data.  In their experience, many, if not most, videos coming from audio/video recording hardware would be either uncompressed or badly compressed, resulting in those recordings taking LOTS of space (placing the aspect of number of files aside for now).  For that reason in https://sleap.ai/help.html#does-my-data-need-to-be-in-a-particular-format they provide recommended settings for ffmpeg to see such files compressed:\n\n```\nffmpeg -y -i \"input.mp4\" -c:v libx264 -pix_fmt yuv420p -preset superfast -crf 23 \"output.mp4\"\n```\n\nSimilarly, for ReproNim's reprostim project, where we capture audio/video of presented to MRI experiment stimuli using cheap magewell capture card, and on a small underpowered hardware, with @vmdocua we specify default settings in https://github.com/ReproNim/reprostim/blob/master/src/reprostim-capture/videocapture/config.yaml#L105 for ffmpeg video component as\n\n```\n-c:v libx264 -flush_packets 1 -preset ultrafast -crf 18 -tune zerolatency -b:v 8M -maxrate 8M -bufsize 16M -vf setpts=PTS-STARTPTS\n```\n\nATM.\n\nIn DANDI we already have 15 dandisets with video (.mkv or .mp4; might have missed others, invocation was `for f in 0*; do find $f -regextype posix-extended -iregex '.*\\.(mp4|avi|wmv|mov|flv|mkv)'; done  \u003e| /tmp/videos.txt`)\n\n~~(note  000559 contains over 2M files!)~~  edited: my invocation was bad/wrong... redoing\n\nI think it would be \n\n- useful to provide some guidance at the time of validation/upload to ensure that videos uploaded to archive are appropriately compressed and we are not blowing up the size of the archive with loosely or uncompressed videos.  Yet to figure out usable procedures for that but could be pretty much taking a sample video and recompressing with \"recommended\" settings and seeing how well it compresses\n- reviewing current videos in the archive and issue such recommendations?","files":null},{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739382169,"metadata":{"github-id":"UCE_lAHODBZtRc6pyCG3znGU6x8"},"target":"2d86acc3f87b2de502ef7037db30fb16bffe1634fbe554e33cfc05453726afa2","message":"Came up in a meetup with @talmo re their experiences in SLEAP working with video recordings of behavioral data.  In their experience, many, if not most, videos coming from audio/video recording hardware would be either uncompressed or badly compressed, resulting in those recordings taking LOTS of space (placing the aspect of number of files aside for now).  For that reason in https://sleap.ai/help.html#does-my-data-need-to-be-in-a-particular-format they provide recommended settings for ffmpeg to see such files compressed:\n\n```\nffmpeg -y -i \"input.mp4\" -c:v libx264 -pix_fmt yuv420p -preset superfast -crf 23 \"output.mp4\"\n```\n\nSimilarly, for ReproNim's reprostim project, where we capture audio/video of presented to MRI experiment stimuli using cheap magewell capture card, and on a small underpowered hardware, with @vmdocua we specify default settings in https://github.com/ReproNim/reprostim/blob/master/src/reprostim-capture/videocapture/config.yaml#L105 for ffmpeg video component as\n\n```\n-c:v libx264 -flush_packets 1 -preset ultrafast -crf 18 -tune zerolatency -b:v 8M -maxrate 8M -bufsize 16M -vf setpts=PTS-STARTPTS\n```\n\nATM.\n\n\u003cdetails\u003e\n\u003csummary\u003eedited: In DANDI we already have 44 dandisets with videos\u003c/summary\u003e \n\n```shell\ndandi@drogon:/mnt/backup/dandi/dandisets$ for f in 0*; do find $f -regextype posix-extended -iregex '.*\\.(mp4|avi|wmv|mov|flv|mkv)'; done  \u003e| /tmp/videos.txt \ndandi@drogon:/mnt/backup/dandi/dandisets$ grep -v '\\.git' /tmp/videos.txt | sed -e  's,/.*,,g' | sort | uniq -c | sort -nr | nl\n     1\t   2483 000559\n     2\t    899 000409\n     3\t    794 000779\n     4\t    495 000540\n     5\t    459 000951\n     6\t    400 000780\n     7\t    360 000793\n     8\t    360 000792\n     9\t    319 000782\n    10\t    319 000781\n    11\t    264 000831\n    12\t    264 000830\n    13\t    256 000867\n    14\t    256 000866\n    15\t    115 000231\n    16\t    105 000833\n    17\t    105 000832\n    18\t     82 000568\n    19\t     64 001084\n    20\t     40 000807\n    21\t     40 000806\n    22\t     40 000805\n    23\t     40 000804\n    24\t     40 000803\n    25\t     40 000802\n    26\t     40 000801\n    27\t     40 000800\n    28\t     32 000689\n    29\t     19 000624\n    30\t     18 000863\n    31\t     18 000862\n    32\t     16 001172\n    33\t      9 001259\n    34\t      9 000727\n    35\t      9 000576\n    36\t      8 001190\n    37\t      8 000718\n    38\t      3 001195\n    39\t      2 001180\n    40\t      1 001265\n    41\t      1 000892\n    42\t      1 000691\n    43\t      1 000360\n    44\t      1 000167\n```\n\u003c/details\u003e\n\nI think it would be \n\n- useful to provide some guidance at the time of validation/upload to ensure that videos uploaded to archive are appropriately compressed and we are not blowing up the size of the archive with loosely or uncompressed videos.  Yet to figure out usable procedures for that but could be pretty much taking a sample video and recompressing with \"recommended\" settings and seeing how well it compresses\n- reviewing current videos in the archive and issue such recommendations?","files":null},{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739382340,"metadata":{"github-id":"UCE_lAHODBZtRc6pyCG3znGU_No"},"target":"2d86acc3f87b2de502ef7037db30fb16bffe1634fbe554e33cfc05453726afa2","message":"Came up in a meetup with @talmo re their experiences in SLEAP working with video recordings of behavioral data.  In their experience, many, if not most, videos coming from audio/video recording hardware would be either uncompressed or badly compressed, resulting in those recordings taking LOTS of space (placing the aspect of number of files aside for now).  For that reason in https://sleap.ai/help.html#does-my-data-need-to-be-in-a-particular-format they provide recommended settings for ffmpeg to see such files compressed:\n\n```\nffmpeg -y -i \"input.mp4\" -c:v libx264 -pix_fmt yuv420p -preset superfast -crf 23 \"output.mp4\"\n```\n\nSimilarly, for ReproNim's reprostim project, where we capture audio/video of presented to MRI experiment stimuli using cheap magewell capture card, and on a small underpowered hardware, with @vmdocua we specify default settings in https://github.com/ReproNim/reprostim/blob/master/src/reprostim-capture/videocapture/config.yaml#L105 for ffmpeg video component as\n\n```\n-c:v libx264 -flush_packets 1 -preset ultrafast -crf 18 -tune zerolatency -b:v 8M -maxrate 8M -bufsize 16M -vf setpts=PTS-STARTPTS\n```\n\nATM.\n\n\u003cdetails\u003e\n\u003csummary\u003eedited: In DANDI we already have 44 dandisets with videos\u003c/summary\u003e \n\n```shell\ndandi@drogon:/mnt/backup/dandi/dandisets$ for f in 0*; do find $f -regextype posix-extended -iregex '.*\\.(mp4|avi|wmv|mov|flv|mkv)'; done  \u003e| /tmp/videos.txt \ndandi@drogon:/mnt/backup/dandi/dandisets$ grep -v '\\.git' /tmp/videos.txt | sed -e  's,/.*,,g' | sort | uniq -c | sort -nr | nl\n     1\t   2483 000559\n     2\t    899 000409\n     3\t    794 000779\n     4\t    495 000540\n     5\t    459 000951\n     6\t    400 000780\n     7\t    360 000793\n     8\t    360 000792\n     9\t    319 000782\n    10\t    319 000781\n    11\t    264 000831\n    12\t    264 000830\n    13\t    256 000867\n    14\t    256 000866\n    15\t    115 000231\n    16\t    105 000833\n    17\t    105 000832\n    18\t     82 000568\n    19\t     64 001084\n    20\t     40 000807\n    21\t     40 000806\n    22\t     40 000805\n    23\t     40 000804\n    24\t     40 000803\n    25\t     40 000802\n    26\t     40 000801\n    27\t     40 000800\n    28\t     32 000689\n    29\t     19 000624\n    30\t     18 000863\n    31\t     18 000862\n    32\t     16 001172\n    33\t      9 001259\n    34\t      9 000727\n    35\t      9 000576\n    36\t      8 001190\n    37\t      8 000718\n    38\t      3 001195\n    39\t      2 001180\n    40\t      1 001265\n    41\t      1 000892\n    42\t      1 000691\n    43\t      1 000360\n    44\t      1 000167\n```\n\u003c/details\u003e\n\nI think it would be \n\n- useful to provide some guidance at the time of validation/upload to ensure that videos uploaded to archive are appropriately compressed and we are not blowing up the size of the archive with loosely or uncompressed videos.  Yet to figure out usable procedures for that but could be pretty much taking a sample video and recompressing with \"recommended\" settings and seeing how well it compresses\n- validate that videos are seekable (ref: https://github.com/janclemenslab/napari-video/issues/3 per @talmo [comment below](https://github.com/dandi/dandi-cli/issues/1575#issuecomment-2653942958))\n- reviewing current videos in the archive and issue such recommendations?","files":null},{"type":5,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739371603,"metadata":{"github-id":"LE_lADODBZtRc6pyCG3zwAAAAPKfoLj"},"added":["ember"],"removed":[]},{"type":3,"author":{"id":"613d68720297f80d4375b91cab4a20d0925cab6b"},"timestamp":1739371865,"metadata":{"github-id":"IC_kwDODBZtRc6eL_Su","github-url":"https://github.com/dandi/dandi-cli/issues/1575#issuecomment-2653942958"},"message":"Cross linking relevant discussion: https://github.com/janclemenslab/napari-video/issues/3","files":null},{"type":2,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1739382363,"metadata":{"github-id":"RTE_lADODBZtRc6pyCG3zwAAAAPKqAR5"},"title":"\"sense\" video files as for the quality of their compression, seekability, ...","was":"\"sense\" video files as for the quality of their compression, seekability, ..."}]}