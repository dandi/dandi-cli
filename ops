{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1658517429,"metadata":{"github-id":"IC_kwDODBZtRc5HGbLe","github-url":"https://github.com/dandi/dandi-cli/issues/1074#issuecomment-1192866526"},"message":"First of I would like to clarify that `--allow-any-path` is a DEVEL option, i.e. typically shouldn't be used by users, and we should strive to arrive to that.  Also `--validation skip` should be discouraged since most likely it would result in dandiset with validation errors and thus not publishable.  So, typically, we should advise that neither of those options should be used.\n\n\u003e - if any paths are allowed, then there is no guarantee that the path is a bids path.\n\nThen we are to upload it, possibly without any extra (beyond the one of the [GenericAsset](https://github.com/dandi/dandi-cli/blob/HEAD/dandi/files.py#L552)) metadata\n\n\u003e should any bids proximity be checked?\n\nwhat do you mean by *proximity* here?  that filename looks BIDS-like so we could potentially extract some entities?\n\n\u003e - same for validation, if it is skipped what does it mean?\n\nhm, good question. I think for `nwb` it means that we can still extract/upload metadata even though it doesn't pass validation.  How does it work for BIDS file paths @TheChymera -- do we extract metadata for e.g. subject/session and from entities (thus may be relating to question above) if validation of that path fails?\n\n\u003e I think we have two different meanings. for nwb, validation was about running the validator on the nwb file, for bids, validation is about structure of the dataset rather than contents of file.\n\nYes/no.  For our DANDI layout we should have also added validation of the path to confirm to our \"DANDI layout\". Altogether, I think that the situation is similar between BIDS (over nii or nwb or whatnot) and DANDI layout on .nwb files, and there should (if not already there) be validation of both structure and contents.\n\n\u003e what if a bids dataset is detected, do we validate the entire tree or just the partial tree that's relevant to the directory or files being uploaded?\n\nI think ATM it is just about the partial tree, @TheChymera can correct me if I am wrong. Later, we indeed probably should ensure that it works for \"partial tree\" but with consideration of \"dataset component\".\nThis would relate then to your #1075  issue about \"partial BIDS dataset download/validation\". For DANDI layout is could be done easily ATM since we have only dandiset.yaml and corresponding files without any dependencies (if we do not look within .nwb for external refs). For BIDS -- I am still not 100% certain beyond validating some (e.g. not content dependent) aspects, possibly  as overlay on top of what is in the archive, possibly with some smart access to remote content where/if needed.  But that is \"bright future\" level of importance ATM IMHO.","files":null},{"type":3,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1658589714,"metadata":{"github-id":"IC_kwDODBZtRc5HHebd","github-url":"https://github.com/dandi/dandi-cli/issues/1074#issuecomment-1193141981"},"message":"\u003e what do you mean by proximity here? that filename looks BIDS-like so we could potentially extract some entities?\n\nThis sounds like the sort of fuzzy feature that could cause us a lot of misadventures :(\n\n\u003e it means that we can still extract/upload metadata even though it doesn't pass validation. How does it work for BIDS file paths [...] do we extract metadata for e.g. subject/session and from entities (thus may be relating to question above) if validation of that path fails?\n\nCurrently we only return the BIDS dataset roots which pass validation: \nhttps://github.com/dandi/dandi-cli/blob/1c947365311732943753e15199a57c9bfd2759bf/dandi/upload.py#L463-L465\n\nHowever, regardless of whether the dataset is evaluated as valid, the metadata is for all matches is exposed:\nhttps://github.com/dandi/dandi-cli/blob/1c947365311732943753e15199a57c9bfd2759bf/dandi/upload.py#L455\n\nInvalid files do not have metadata. Partial validation is on my nice-to-have roadmap, but I would argue it's only sensible to use such a feature to improve hinting for the end-user (i.e. this is probably where the mistake is, *probably*). I really don't think we should annotate metadata from invalid files, it's simply unreliable and potentially broken annotation is always worse than missing annotation.\n\n\u003e what if a bids dataset is detected, do we validate the entire tree or just the partial tree that's relevant to the directory or files being uploaded?\n\nValidation is run on directories which contain `dataset_description.json` at the top level.","files":null},{"type":6,"author":{"id":"0ab0e40999605aa8d5ec6be68372511fdc4a2fdf"},"timestamp":1658589731,"metadata":{"github-id":"UCE_lALODBZtRc5HHebdziVzNdU"},"target":"d1c3e74c55dfc004fae410cd15fad70740a655b24a2ce506e4734df487c91aad","message":"\u003e what do you mean by proximity here? that filename looks BIDS-like so we could potentially extract some entities?\n\nThis sounds like the sort of fuzzy feature that could cause us a lot of misadventures :(\n\n\u003e it means that we can still extract/upload metadata even though it doesn't pass validation. How does it work for BIDS file paths [...] do we extract metadata for e.g. subject/session and from entities (thus may be relating to question above) if validation of that path fails?\n\nCurrently we only return the BIDS dataset roots which pass validation: \nhttps://github.com/dandi/dandi-cli/blob/1c947365311732943753e15199a57c9bfd2759bf/dandi/upload.py#L463-L465\n\nHowever, regardless of whether the dataset is evaluated as valid, the metadata of all matches is exposed:\nhttps://github.com/dandi/dandi-cli/blob/1c947365311732943753e15199a57c9bfd2759bf/dandi/upload.py#L455\n\nInvalid files do not have metadata. Partial validation is on my nice-to-have roadmap, but I would argue it's only sensible to use such a feature to improve hinting for the end-user (i.e. this is probably where the mistake is, *probably*). I really don't think we should annotate metadata from invalid files, it's simply unreliable and potentially broken annotation is always worse than missing annotation.\n\n\u003e what if a bids dataset is detected, do we validate the entire tree or just the partial tree that's relevant to the directory or files being uploaded?\n\nValidation is run on directories which contain `dataset_description.json` at the top level.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1658590520,"metadata":{"github-id":"IC_kwDODBZtRc5HHe2k","github-url":"https://github.com/dandi/dandi-cli/issues/1074#issuecomment-1193143716"},"message":"@TheChymera and @yarikoptic - my question still remains. in the case of NWB, i can upload a single file independent of the validity of any other NWB file.\n\nin the case of BIDS, will i be able to upload a single file/directory if it finds invalid things in other directories outside of that specific tree. given the current bids datasets, it may be very onerous to fix every aspect before renewing upload. hence the check being limited to the sub tree relevant to that file and the bids_description.json.\n\nplease look at this through the lens of the current datasets and their complexities not any general bids case for now.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1658591584,"metadata":{"github-id":"IC_kwDODBZtRc5HHfbq","github-url":"https://github.com/dandi/dandi-cli/issues/1074#issuecomment-1193146090"},"message":"just to clarify for these datasets the following should work:\n\n```\nfor 000108\ncd some ses directory\ndandi upload --existing overwrite --sync .\n\nfor 000026\ncd some sub/ses directory or derivatives directory\ndandi upload --existing overwrite --sync .\n```\n\ni include existing as we would want to overwrite the metadata with appropriate extraction from the filename","files":null},{"type":5,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658934640,"metadata":{"github-id":"LE_lADODBZtRc5ODbKczwAAAAGloxfi"},"added":["cmd-upload"],"removed":[]}]}