{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1654704455,"metadata":{"github-id":"IC_kwDODBZtRc5EjVpt","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1150114413"},"message":"URL to log file seems to not work.\n\n- please provide invocation command\n- did you interrupted any prior upload ?\n- are you sure there is no other upload in the background? (`ps auxw | grep dandi` or alike)","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1654782024,"metadata":{"github-id":"IC_kwDODBZtRc5EnOyu","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1151134894"},"message":"Thanks for the quick response. I checked the log and it prompted me to download, but having downloaded the file and opened it with a text editor it appears to be intact. In any case I've added the log file to google drive as well, let me know if you can access it: https://drive.google.com/file/d/1KYrqwWpfaiIN7e4wZV7W-Iv5plnCjjGj/view?usp=sharing\n\n**1.** The exact command I ran was `DANDI_DEVEL=1 dandi upload --validation skip --allow-any-path /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h16m47s38/micr/sub-MITU01_ses-20220316h16m47s38_sample-13_stain-YO_run-1_chunk-5_SPIM.ome.zarr`\nfrom the home directory, having sourced satra's miniconda3 dandi environment. Could something rely on relative pathing, meaning I'd need to run the upload from the directory containing the file?\n\n**2.** I have interrupted a prior upload a day prior to this attempt, that had appeared to have stall.\n\n**3.** Unfortunately, checking with ps auxw reveals no other upload processes currently active on this machine","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1655143891,"metadata":{"github-id":"IC_kwDODBZtRc5EzB4l","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1154227749"},"message":"\u003e 2. I have interrupted a prior upload a day prior to this attempt, that had appeared to have stall.\n\nI thought that is the root of the issue but @jwodder says that code should have handled that (might need explicit flag for `--existing`)... stay tuned","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1655145549,"metadata":{"github-id":"IC_kwDODBZtRc5EzIBq","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1154252906"},"message":"I believe I know what happened.  While there is code for cancelling a Zarr upload, it only triggers if an error occurs while uploading one of the files.  However, if the user hits Cntrl-C, the code path in question won't see it, because the Zarr upload runs in a background thread managed by pyout while Cntrl-C in Python is received by the main thread.  Cancelling on Cntrl-C would require, at a minimum, modifying pyout to close iterators on shutdown, and I'm not familiar enough with pyout's code to know if that's even possible.\n\nAn alternative mitigation would be to check at the start of a Zarr upload whether there's already an upload in progress for that Zarr and then either error or, if a certain command-line option is given, cancel the upload.  This would require the archive to add an endpoint for checking whether there is currently an upload in progress for a Zarr.\n\n---\n\n@slaytonmarx Until the above happens, you should be able to get your upload working again by cancelling the in-progress upload with the following script.  Pass it your Dandiset ID and the asset path of the problematic Zarr (which appears to be `sub-MITU01/ses-20220316h16m47s38/micr/sub-MITU01_ses-20220316h16m47s38_sample-13_stain-YO_run-1_chunk-5_SPIM.ome.zarr`).\n\n```python\n#!/usr/bin/env python3\nimport sys\nfrom dandi.dandiapi import DandiAPIClient\n\ndandiset_id, asset_path = sys.argv[1:]\n\nwith DandiAPIClient.for_dandi_instance(\"dandi\", authenticate=True) as client:\n    dandiset = client.get_dandiset(dandiset_id)\n    asset = dandiset.get_asset_by_path(asset_path)\n    zarr_id = asset.zarr\n    client.delete(f\"/zarr/{zarr_id}/upload/\")\n```","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1655149287,"metadata":{"github-id":"IC_kwDODBZtRc5EzhgE","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1154357252"},"message":"- Given that we might want such \"force\" or \"delete prior\" upload to be done for some specific zarrs but not the others, and echoing on the discussion we had today about collection of admin service functionality which might (or not) be exposed via API, for this particular one, I think we should introduce `dandi service-scripts` (or alike, suggestions?) group of commands, and then have this particular snippet you have provided as `cancel-zarr-upload` (or alike, suggestions?) command, so that it would look like `dandi service-scripts cancel-zarr-upload [PATHs]`.  Then upon  upload encountering a rare situation\n- While encountering 400 with \"Simultaneous uploads are not allowed\". we should pyout ERROR status with message \"Upload is already ongoing, see log for more info\" (or alike) while logging the instruction to run  `dandi service-scripts cancel-zarr-upload THATPATH` to explicitly cancel that particular zarr upload if so desired\n- pyout\n  - \"Cancelling on Cntrl-C would require, at a minimum, modifying pyout to close iterators on shutdown\" - I think it is for us at this `except` handling https://github.com/dandi/dandi-cli/blob/HEAD/dandi/upload.py#L248 (within process_file) to cancel/DELETE  zarr upload if we have already started it  in `iter_upload` right above.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1655298857,"metadata":{"github-id":"IC_kwDODBZtRc5E7iNx","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1156457329"},"message":"@yarikoptic \n\n* I'd rather not make the client check whether there's an upload in progress by examining the text of the error message, which could change without warning.  The Dandi Archive team should either implement https://github.com/dandi/dandi-archive/issues/356 or, as I suggested above, add an endpoint for checking whether an upload is in progress.\n* We can't catch a `KeyboardInterrupt` in `process_path()`, as it's run in a thread by pyout, and `KeyboardInterrupt` only goes to the main thread.  Even if pyout were updated, cancelling a Zarr upload from the `process_path()` exception handler would be awkward; I think the proper course there would be to instead wrap `iter_upload()` in `contextlib.closing()` and adjust the exception handler in `ZarrAsset.iter_upload()`.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1655305248,"metadata":{"github-id":"IC_kwDODBZtRc5E8BmN","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1156585869"},"message":"\u003e I'd rather not make the client check whether there's an upload in progress by examining the text of the error message ...\n\nI'd rather not as well... the fastest way would probably be to suggest PR to dandi-archive to propose how to address that issue.  Alternative -- match on message (even though suboptimal) and just wait.    The choice is yours (I would prefer proper fix/PR).\n\n\u003e  I think the proper course there would be to instead wrap iter_upload() in contextlib.closing() and adjust the exception handler in ZarrAsset.iter_upload().\n\nplease try that approach out .","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1655305319,"metadata":{"github-id":"IC_kwDODBZtRc5E8B7-","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1156587262"},"message":"@yarikoptic \n\n\u003e please try that approach out .\n\nI meant that this approach would be required *in addition to* updating pyout.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1655305954,"metadata":{"github-id":"IC_kwDODBZtRc5E8E8J","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1156599561"},"message":"@jwodder and @yarikoptic - to start with, could we have just an optional cli force flag that cancels any existing upload (similar to the code snippet @jwodder posted above)? this should be ok for 99.9% of the cases.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1656620432,"metadata":{"github-id":"IC_kwDODBZtRc5F1cqd","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1171638941"},"message":"@yarikoptic What exactly do you want me to do for this?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1656626813,"metadata":{"github-id":"IC_kwDODBZtRc5F1xs0","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1171725108"},"message":"\u003e @yarikoptic What exactly do you want me to do for this?\n\nwell, we have  2 aspects:\n- **A1**: prevent leaving \"stale\" upload processes.  **We should fix that in dandi-cli** (and/or any library which needed).  Instead of hacking pyout, can't we register some `atexit` handler which would do that (if uploads didn't finish properly)?   If so -- let's add such handler, if not -- propose a change to pyout + dandi-cli to achieve the goal.  \n- **A2**: inform user about reason for 400 in UI:  wouldn't that be addressed already by https://github.com/dandi/dandi-cli/pull/1023/files ?\n- **A3**: provide user with ability to cancel those \"stale\" upload processes a still broken dandi-cli leaves behind, or in some unfortunate case where user's connection interrupts or computer goes down.  I still like that idea of having `dandi service-scripts cancel-zarr-upload [PATHs]` instead of adding some option to `upload` or exposing such command which generally should not be used at the top level of CLI.  So please interface your code snippet as such command.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1656691243,"metadata":{"github-id":"IC_kwDODBZtRc5F4sRT","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172489299"},"message":"I implemented a `dandi service-scripts cancel-zarr-upload` command, and I made it poll the server until the upload was actually cancelled in accordance with #929.  However, now that I'm testing the command, the polling has been going on for more than five minutes and the Zarr still has `\"upload_in_progress\": true`.  Note that the upload in question consisted of only two files, and no data was transferred.\n\n@dandi/dandiarchive Why is this taking so long?  Is there a task missing from [the celery container command-line](https://github.com/dandi/dandi-cli/blob/f7bb0a9850350f06925ff3358c7c75826b7b4843/dandi/tests/data/dandiarchive-docker/docker-compose.yml#L60)?","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1656691543,"metadata":{"github-id":"IC_kwDODBZtRc5F4tWj","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172493731"},"message":"@yarikoptic - i do not think this is a good UX for the researcher. for most researchers, it would be useful to be notified why there is an ERROR and what they can do. if they are doing an upload like `dandi upload .` then trying to figure out exact paths of each files is not going to be easy. as you saw in the email, many researchers don't even know how to use command line tools. \n\nthus making the UX simple will be important and asking them to redo the command with an option to cancel should be easier than the service scripts.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1656695126,"metadata":{"github-id":"IC_kwDODBZtRc5F46xT","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172548691"},"message":"@satra - this is a \"non-standard\" situation we are dealing with now. Users should not even get into it after we implement **A1** - those uploads should be \"canceled\" if user cancels them (but @jwodder might have discovered an issue [above](https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172489299)). The most obvious case when they would run into it is whenever their colleague (or them in another shell) **already** uploading for that path. If we make it trivial for them now to just \"cancel\" an ongoing upload we would just make it easy to bring up the confusion and/or frustration whenever they start canceling \"each other\".\nAnyways -- we need to have **A1** addressed first and have some interface to cancel for this particular incident.  We can always improve interface if we find it insufficient.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1656695632,"metadata":{"github-id":"IC_kwDODBZtRc5F48vh","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172556769"},"message":"BTW, #942 relates the aspect here of possibly adding a waiting/re-queuing of uploads  until they become available.  But let's first have that issue @jwodder ran into addressed I guess. May be it would not be needed if `cancel`ing would become fast enough.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1656704948,"metadata":{"github-id":"IC_kwDODBZtRc5F5Xr2","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172667126"},"message":"Link to comment relevant to this error posted in a different thread.\nhttps://github.com/dandi/dandi-cli/pull/1035#issuecomment-1172649298","files":null},{"type":3,"author":{"id":"a9e2633aeb6d7e2366a97d09712312c2442c6054"},"timestamp":1656706973,"metadata":{"github-id":"IC_kwDODBZtRc5F5c43","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172688439"},"message":"I believe I've found the root cause of this, documented here https://github.com/dandi/dandi-archive/pull/1154.\n\nIt was due to the combination of a missing parameter, and a rather sinister bug in our testing setup. I'll try to get this merged and deployed by EOD. After that upload cancels shouldn't hang indefinitely anymore.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1656708059,"metadata":{"github-id":"IC_kwDODBZtRc5F5fcx","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172698929"},"message":"Thank you @AlmightyYakob \n\n\u003e After that upload cancels shouldn't hang indefinitely anymore.\n\nhow fast such DELETEs should be? in other words -- is that is just a matter of flipping a boolean on \"upload_in_progress\" or it also involves some \"invalidation\" of previously minted S3 upload urls so those possibly \"ongoing\" uploads truly cancel (be forbidden by S3)?","files":null},{"type":3,"author":{"id":"a9e2633aeb6d7e2366a97d09712312c2442c6054"},"timestamp":1656708373,"metadata":{"github-id":"IC_kwDODBZtRc5F5gFE","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172701508"},"message":"\u003e how fast such DELETEs should be? in other words -- is that is just a matter of flipping a boolean on \"upload_in_progress\" or it also involves some \"invalidation\" of previously minted S3 upload urls so those possibly \"ongoing\" uploads truly cancel (be forbidden by S3)?\n\nI don't have exact figures but it should be pretty quick (on the order of seconds). It deletes every zarr upload file from the database, so it will scale with the number of active uploads. Currently, no presigned URLs are revoked (see [this](https://github.com/dandi/dandi-archive/blob/3d548209f06015ae8356ebfbe537e2ed541f0d59/dandiapi/api/models/zarr.py#L259-L267) comment), but we'd like to address that.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1656710170,"metadata":{"github-id":"IC_kwDODBZtRc5F5kRD","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1172718659"},"message":"OK, the tests are passing now that dandi-archive's been fixed.","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1657037362,"metadata":{"github-id":"CE_lADODBZtRc5LZcmhzwAAAAGdZ1kr"},"status":2},{"type":3,"author":{"id":"7a8552494914d3e4116f4b434eb4812a914ca405"},"timestamp":1657037421,"metadata":{"github-id":"IC_kwDODBZtRc5GDK5R","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1175236177"},"message":"\u003c!-- GITHUB_RELEASE COMMENT: released --\u003e\n:rocket: Issue was released in [`0.43.0`](https://github.com/dandi/dandi-cli/releases/tag/0.43.0) :rocket:","files":null},{"type":5,"author":{"id":"7a8552494914d3e4116f4b434eb4812a914ca405"},"timestamp":1657037422,"metadata":{"github-id":"LE_lADODBZtRc5LZcmhzwAAAAGdZ3LG"},"added":["released"],"removed":[]},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1657113582,"metadata":{"github-id":"IC_kwDODBZtRc5GG5k6","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176213818"},"message":"Dear @slaytonmarx . Necessary fixes were done server side and we released new dandi-cli. Please upgrade/try  our current `dandi` client:\n```\n$\u003e dandi --version\n0.43.0\n```\nwhere, we canceling of the upload should cancel ongoing zarr uploads, and also you get a helper command in cases of prior hanging upload zarr jobs still there:\n\n```\n$\u003e dandi service-scripts cancel-zarr-upload --help\nUsage: dandi service-scripts cancel-zarr-upload [OPTIONS] [PATHS]...\n\n  Cancel an in-progress Zarr upload operation on the server.\n\n  If a process uploading a Zarr is suddenly interrupted or killed, the server\n  might not be properly notified.  If a later attempt is made to upload the\n  same Zarr, the server will then report back that there is already an upload\n  operation in progress and prohibit the new upload.  Use this command in such\n  a case to tell the server to cancel the old upload operations for the Zarrs\n  at the given path(s).\n\nOptions:\n  -i, --dandi-instance [dandi|dandi-api-local-docker-tests|dandi-devel|dandi-staging]\n                                  DANDI instance to use  [env var:\n                                  DANDI_INSTANCE; default: dandi]\n  --help                          Show this message and exit.\n```\nso just point `dandi service-scripts cancel-zarr-upload` to paths for zarrs which have stale uploads, and then retry `dandi upload`.  Please let us know how it works.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1657122728,"metadata":{"github-id":"IC_kwDODBZtRc5GHk2D","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176391043"},"message":"Alright, running upload cancel on files in sample 10 (ses-20220326h13m51s50). Attempted to re-upload 10 first to verify that all files gave a 400 Error, confirmed, and am now running `dandi service-scripts cancel-zarr-upload ./*` in it's directory. I'm seeing promising output so far.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1657123236,"metadata":{"github-id":"IC_kwDODBZtRc5GHnq7","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176402619"},"message":"No errors yet, I'll keep my eye on it.\n![image](https://user-images.githubusercontent.com/36866774/177593713-b3208a1c-4852-43e5-9645-2aafb6e9ff7a.png)","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1657124126,"metadata":{"github-id":"IC_kwDODBZtRc5GHrbL","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176417995"},"message":"I'm getting errors, but at least we're able to attempt the re-upload, posting logs now.\n\n![image](https://user-images.githubusercontent.com/36866774/177595705-f206f1b6-a6f8-453c-b0af-e53823db09d4.png)\n\nhttps://drive.google.com/file/d/1xaQ1Apnj3ltN0AnpUY-5TTxqiJ-cLjHp/view?usp=sharing\n\nThese errors seem to be unrelated to simultaneous uploads though, so I'll split them off into their own issues.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1657125449,"metadata":{"github-id":"IC_kwDODBZtRc5GHwjc","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176439004"},"message":"Thank you! BTW how is bandwidth utilization during those zarrs upload? (if your run some `dstat` or alike to see factual pipe bandwidth)","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1657127783,"metadata":{"github-id":"IC_kwDODBZtRc5GH62B","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176481153"},"message":"I haven't used dstat before but I'll send over some output if you're willing to parse it.\n\n![image](https://user-images.githubusercontent.com/36866774/177606936-6c7ed85d-f368-4b6e-bb10-d5addcccb7aa.png)","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1657132159,"metadata":{"github-id":"IC_kwDODBZtRc5GIJxt","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1176542317"},"message":"so network gets filled up to slightly over 1Gbps down (I guess someone is fetching smth as well), and under (but was growing) 1Gbps up... If you run something like `dstat 60` you would get averaged per minute indicators, would be easier to assess sustained speeds (ATM rodan seems to be not busy with IO at all, boring ;))","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1664556374,"metadata":{"github-id":"IC_kwDODBZtRc5LU_7B","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1263795905"},"message":"I'm still running into this error while uploading the MITU01 human brain project on dandi version `0.46.3`.\n\n**Log:** https://drive.google.com/file/d/1CcXZmPxyXG9qVCx0dR4ZX-yxIe9x3ckK/view?usp=sharing\n\nThe uploads have been orchestrated via a simple bash script, with `file_list_by_sample.txt` containing a list of absolute paths to the desired upload directories. For the past few weeks I've been in a process of attempting to upload a directory, having most of the chunks eventually error out with this error, but gaining some progress.\n\n```\n#!/bin/bash\n\nfile=\"file_list_by_sample.txt\"\n\nwhile read -r line; do\n    sudo chmod 775 $line\n    cd $line\n    for i in 1 2; do\n      dandi service-scripts cancel-zarr-upload .\n      DANDI_DEVEL=1 dandi upload --validation skip --allow-any-path .\n    done\n    cd /mnt/beegfs/smarx/server-tools/dandi_q1_uploads\ndone \u003c$file\n```\n\nI'm not proud of trying to brute force things like this, but it seemed a viable option, though given it's slow speed over the past three weeks I'm hoping to escalate it.\n\nThank you!","files":null},{"type":4,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1664803488,"metadata":{"github-id":"REE_lADODBZtRc5LZcmhzwAAAAG_d30h"},"status":1},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1664804519,"metadata":{"github-id":"IC_kwDODBZtRc5LbWLi","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265459938"},"message":"@slaytonmarx FYI, `dandi service-scripts cancel-zarr-upload .` doesn't do anything; the `cancel-zarr-upload` command requires you to explicitly specify the individual paths to the Zarrs whose uploads you want to cancel.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1664806241,"metadata":{"github-id":"IC_kwDODBZtRc5Lbgmn","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265502631"},"message":"Roger that! Let me retool the script. Thank you","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1664810974,"metadata":{"github-id":"IC_kwDODBZtRc5LcDLB","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265644225"},"message":"This seems to be the cause of the 400 Errors, i.e cancelling uploads isn't actually going through.\n```\n2022-10-03T11:24:16-0400 [INFO    ] dandi 827497:139734640392000 dandi v0.46.3, hdmf v1.5.4, pynwb v1.2.1, h5py v2.10.0\n2022-10-03T11:24:16-0400 [INFO    ] dandi 827497:139734640392000 sys.argv = ['/mnt/beegfs/satra/miniconda3/envs/dandi/bin/dandi', 'service-scripts', 'cancel-zarr-upload', '/mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-1_SPIM.ome.zarr']\n2022-10-03T11:24:16-0400 [INFO    ] dandi 827497:139734640392000 os.getcwd() = /mnt/beegfs/smarx/server-tools/dandi_q1_uploads\n2022-10-03T11:24:17-0400 [DEBUG   ] urllib3.connectionpool 827497:139734640392000 Starting new HTTPS connection (1): rig.mit.edu:443\n2022-10-03T11:24:17-0400 [DEBUG   ] urllib3.connectionpool 827497:139734640392000 https://rig.mit.edu:443 \"GET /et/projects/dandi/dandi-cli HTTP/1.1\" 200 579\n2022-10-03T11:24:17-0400 [DEBUG   ] dandi 827497:139734640392000 No newer (than 0.46.3) version of dandi/dandi-cli found available\n2022-10-03T11:24:17-0400 [DEBUG   ] dandi 827497:139734640392000 Caught exception Found no dandiset.yaml anywhere.  Use 'dandi download' or 'organize' first\n2022-10-03T11:24:17-0400 [INFO    ] dandi 827497:139734640392000 Logs saved in /home/smarx/.cache/dandi-cli/log/20221003152416Z-827497.log\n```","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1664811005,"metadata":{"github-id":"IC_kwDODBZtRc5LcDW5","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265644985"},"message":"@slaytonmarx it would be great if we could figure out why you need to `cancel-zarr-upload` at all -- it must not be necessary.  In the log you shared \n\n\u003cdetails\u003e\n\u003csummary\u003eI do not see any other error than 400\u003c/summary\u003e \n\n```shell\n‚ùØ grep -v pyout 20220930154931Z-240790.log| grep ERROR\n2022-09-30T11:52:43-0400 [ERROR   ] dandi 240790:140528972719872 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/1251b078-041c-42ec-88ff-415d405f556e/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T11:52:47-0400 [ERROR   ] dandi 240790:140528972719872 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr:\n2022-09-30T11:53:17-0400 [ERROR   ] dandi 240790:140529057666816 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/3c78e396-5cf6-4e80-8264-ea19364aaa6d/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T11:53:20-0400 [ERROR   ] dandi 240790:140529057666816 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-6_SPIM.ome.zarr:\n2022-09-30T11:59:16-0400 [ERROR   ] dandi 240790:140528955934464 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/a38087af-9c2f-4412-ab99-16047c79a8b0/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T11:59:17-0400 [ERROR   ] dandi 240790:140528955934464 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-6_SPIM.ome.zarr:\n2022-09-30T11:59:31-0400 [ERROR   ] dandi 240790:140529057666816 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/78e5566d-a95e-43c4-8dc3-e96c9e9fe5c5/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T11:59:33-0400 [ERROR   ] dandi 240790:140529057666816 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-4_SPIM.ome.zarr:\n2022-09-30T12:01:33-0400 [ERROR   ] dandi 240790:140528981112576 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/7d28f3b0-7bf6-4170-b931-292ec21b8de3/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:01:34-0400 [ERROR   ] dandi 240790:140528981112576 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-3_SPIM.ome.zarr:\n2022-09-30T12:02:42-0400 [ERROR   ] dandi 240790:140528955934464 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:02:43-0400 [ERROR   ] dandi 240790:140528955934464 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr:\n2022-09-30T12:04:03-0400 [ERROR   ] dandi 240790:140529057666816 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/7b348a02-d20f-4e6f-8b21-5493fde85bd2/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:04:04-0400 [ERROR   ] dandi 240790:140529057666816 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-6_SPIM.ome.zarr:\n2022-09-30T12:06:08-0400 [ERROR   ] dandi 240790:140528964327168 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/d5d3dc1d-e39b-4435-9c7d-56749cdd5eb5/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:06:08-0400 [ERROR   ] dandi 240790:140528964327168 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-3_SPIM.ome.zarr:\n2022-09-30T12:06:19-0400 [ERROR   ] dandi 240790:140528981112576 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/8ccf0936-63f7-4681-857b-84e4ebab7662/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:06:21-0400 [ERROR   ] dandi 240790:140528981112576 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-1_SPIM.ome.zarr:\n2022-09-30T12:06:59-0400 [ERROR   ] dandi 240790:140529057666816 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/b8b833f4-fbb0-4759-a46f-941695cd137c/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:07:01-0400 [ERROR   ] dandi 240790:140529057666816 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-1_SPIM.ome.zarr:\n2022-09-30T12:14:50-0400 [ERROR   ] dandi 240790:140528964327168 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/a01c0b33-b53d-4adb-9603-5b6acf21ee20/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:14:51-0400 [ERROR   ] dandi 240790:140528964327168 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-5_SPIM.ome.zarr:\n2022-09-30T12:16:10-0400 [ERROR   ] dandi 240790:140528955934464 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/46571abd-68ce-4fde-84df-b761408b67f4/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:16:12-0400 [ERROR   ] dandi 240790:140528955934464 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-4_SPIM.ome.zarr:\n2022-09-30T12:17:42-0400 [ERROR   ] dandi 240790:140528972719872 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/5b97aef9-4fce-4c9f-8193-3a6b848630ea/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:17:45-0400 [ERROR   ] dandi 240790:140528972719872 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-5_SPIM.ome.zarr:\n2022-09-30T12:17:47-0400 [ERROR   ] dandi 240790:140528981112576 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/9f889ef4-104b-4bf9-9abd-05bfb304ab54/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:17:50-0400 [ERROR   ] dandi 240790:140528981112576 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-5_SPIM.ome.zarr:\n2022-09-30T12:18:02-0400 [ERROR   ] dandi 240790:140528964327168 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/d9433a86-eb1a-40a1-8e54-3de9c5d3e5be/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:18:04-0400 [ERROR   ] dandi 240790:140528964327168 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-2_SPIM.ome.zarr:\n2022-09-30T12:18:37-0400 [ERROR   ] dandi 240790:140528955934464 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/fb035cb4-6bf2-4072-8241-f9d8dbe92d72/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:18:39-0400 [ERROR   ] dandi 240790:140528955934464 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-2_SPIM.ome.zarr:\n2022-09-30T12:19:26-0400 [ERROR   ] dandi 240790:140529057666816 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/ad50ab40-2346-4528-b077-41eedf00c090/upload/: [\"Simultaneous uploads are not allowed.\"]\n2022-09-30T12:19:26-0400 [ERROR   ] dandi 240790:140529057666816 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-2_SPIM.ome.zarr:\n```\n\u003c/details\u003e\n\nso the question is -- how did you end up in that situation, i.e. how prior run has failed and did not `cancel-zarr-upload` for those zarrs \"automagically\" upon error (if there was any).  Do you get any output for something like this \"inquiry\" against logs?\n\n```\ngrep 1251b078-041c-42ec-88ff-415d405f556e ~/.cache/dandi-cli/log/202209[23]*log | grep -v pyout | grep -i error\n```","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1664811075,"metadata":{"github-id":"IC_kwDODBZtRc5LcDv4","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265646584"},"message":"\u003e This seems to be the cause of the 400 Errors, i.e cancelling uploads isn't actually going through.\n\nare you running in the top directory of that dandiset you are running `dandi upload` for?","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1664811881,"metadata":{"github-id":"IC_kwDODBZtRc5LcH9N","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265663821"},"message":"Retooled the upload script. Confirmed cancellations.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1664819775,"metadata":{"github-id":"IC_kwDODBZtRc5Lcu6c","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265823388"},"message":"@slaytonmarx what about the investigation after the initial reason on why cancellations were no happening automagically?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1665671234,"metadata":{"github-id":"IC_kwDODBZtRc5MKDLh","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1277702881"},"message":"@slaytonmarx ping on the question above.  Unfortunately 000108 is currently in a \"troublesome\" state (see e.g. https://github.com/dandisets/000108/issues/11 which causes us troubles in https://github.com/dandisets/000108/issues/13#issuecomment-1276670757) and we need to figure out how it arrives to such state.  It would be nice if you could stop your script which just ignores/restarts failing uploads, and we get to troubleshooting the situation, and then ensure that already uploaded zarrs are all good before proceeding with fresh uploads.","files":null},{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1665671619,"metadata":{"github-id":"UCE_lALODBZtRc5MKDLhzihU1YI"},"target":"add4860f50e2cf121ce8da0eeaadabfc98a8503af5d6455af442f737433b31ec","message":"@slaytonmarx ping on the question above.  Unfortunately 000108 is currently in a \"troublesome\" state (see e.g. https://github.com/dandisets/000108/issues/11 which causes us troubles in https://github.com/dandisets/000108/issues/13#issuecomment-1276670757) and we need to figure out how it arrives to such state.  It would be nice if you could stop your script which just ignores/restarts failing uploads, and we get to troubleshooting the situation (and resolve https://github.com/dandisets/000108/issues/12 and https://github.com/dandisets/000108/issues/13), then ensure that already uploaded zarrs are all good before proceeding with fresh uploads.","files":null},{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1665671650,"metadata":{"github-id":"UCE_lALODBZtRc5MKDLhzihU12I"},"target":"add4860f50e2cf121ce8da0eeaadabfc98a8503af5d6455af442f737433b31ec","message":"@slaytonmarx ping on the question above.  Unfortunately 000108 is currently in a \"troublesome\" state (see e.g. https://github.com/dandisets/000108/issues/11 which causes us troubles in https://github.com/dandisets/000108/issues/13#issuecomment-1276670757) and we need to figure out how it arrives to such state.  It would be nice if you could stop your script which just ignores/restarts failing uploads, and we get to troubleshooting the situation (and resolve https://github.com/dandisets/000108/issues/11 and https://github.com/dandisets/000108/issues/12), then ensure that already uploaded zarrs are all good before proceeding with fresh uploads.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1665691105,"metadata":{"github-id":"IC_kwDODBZtRc5MLnq-","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1278114494"},"message":"I've shut down the script. I've confirmed it has successfully uploaded 3 samples since switching to a more hands on approach three days ago. Please let me know when things are resolved and I can resume uploads.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1665691242,"metadata":{"github-id":"IC_kwDODBZtRc5MLoJ_","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1278116479"},"message":"@slaytonmarx i think @yarikoptic means something else than stopping when he says resolution, so i will leave it to him to direct you.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1665692595,"metadata":{"github-id":"IC_kwDODBZtRc5MLtKB","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1278136961"},"message":"Thank you @slaytonmarx . And indeed, as @satra mentions, the main goal is to figure out why you needed that custom script - i.e. why uploads were errorring out and how we could prevent that.  In [comment above](https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1265644985) I have asked for output of \n\n```\ngrep 1251b078-041c-42ec-88ff-415d405f556e ~/.cache/dandi-cli/log/202209[23]*log | grep -v pyout | grep -i error\n``` \nso we could potentially figure out what was going wrong back then.  But have you seen any errors recently again?","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1665693025,"metadata":{"github-id":"IC_kwDODBZtRc5MLvhH","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1278146631"},"message":"The logs from September were dumped to save space on the server, but I ran the grep on all of October's runs thus far for the following output:\n```\n/home/smarx/.cache/dandi-cli/log/20221003154612Z-831494.log:requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n/home/smarx/.cache/dandi-cli/log/20221003154612Z-831494.log:2022-10-03T11:55:42-0400 [DEBUG   ] dandi 831494:140248591886080 Error uploading zarr: HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n/home/smarx/.cache/dandi-cli/log/20221003154612Z-831494.log:requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n/home/smarx/.cache/dandi-cli/log/20221004005546Z-911409.log:2022-10-03T21:45:19-0400 [ERROR   ] dandi 911409:140236696794880 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/1251b078-041c-42ec-88ff-415d405f556e/upload/complete/: [\"No upload in progress.\"]\n/home/smarx/.cache/dandi-cli/log/20221004005546Z-911409.log:requests.exceptions.HTTPError: Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/1251b078-041c-42ec-88ff-415d405f556e/upload/complete/: [\"No upload in progress.\"]\n/home/smarx/.cache/dandi-cli/log/20221004082221Z-975648.log:requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/6/5/53?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221004%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221004T083200Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=ef97a2db162266ef7003fbd97985998d89606752b4654b5718c2290dc6aff3fe\n/home/smarx/.cache/dandi-cli/log/20221004082221Z-975648.log:2022-10-04T04:33:23-0400 [DEBUG   ] dandi 975648:140674970695424 Error uploading zarr: HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/6/5/53?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221004%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221004T083200Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=ef97a2db162266ef7003fbd97985998d89606752b4654b5718c2290dc6aff3fe\n/home/smarx/.cache/dandi-cli/log/20221004082221Z-975648.log:requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/6/5/53?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221004%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221004T083200Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=ef97a2db162266ef7003fbd97985998d89606752b4654b5718c2290dc6aff3fe\n```","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666049266,"metadata":{"github-id":"IC_kwDODBZtRc5MZA6M","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1281625740"},"message":"@slaytonmarx so is that particular zarr `1251b078-041c-42ec-88ff-415d405f556e` (has \"name\": \"sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr\", )  giving you troubles reproducibly?\n\n@jwodder @AlmightyYakob  --  any idea on why S3 might be returning \"501 Server Error: Not Implemented for url\" or what is special about those URLs?\n\nNB not sure if any of those exposed secrets (such as `X-Amz-Credential`) are sensitive -- or they were temp for that upload only,?WDYT?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666096966,"metadata":{"github-id":"IC_kwDODBZtRc5MbsZa","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282328154"},"message":"@yarikoptic The error message is different, but I suspect it's the same issue as in #1033, which I did my best to diagnose [here](https://github.com/dandi/dandi-cli/issues/1033#issuecomment-1176447518).","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666103364,"metadata":{"github-id":"IC_kwDODBZtRc5McT3O","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282489806"},"message":"nice digging @jwodder -- I forgot that we had that issue and indeed never double-checked [that diagnose you gave](https://github.com/dandi/dandi-cli/issues/1033#issuecomment-1176447518).  For the \n\n\u003e based on a brief look at requests's code, it appears that requests only sends a \"Transfer-Encoding\" (with value \"chunked\") when it's unable to determine the size of the request payload. \n\n@jwodder \n- which code piece it is exactly?\n- could you see if we could instrument (via some monkey patching etc) that portion of requests code to either add logging which we enable or add retries or just error out (may be just overload the underlying function from stdlib) to really pin point the underlygin file system issue if that is what keeps giving us trouble?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666103736,"metadata":{"github-id":"IC_kwDODBZtRc5McWAq","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282498602"},"message":"@yarikoptic We already implemented retrying based on the S3 response: https://github.com/dandi/dandi-cli/blob/a73a2de8b787ff002bf28f14717279aef550e226/dandi/files/zarr.py#L500.\n\n@slaytonmarx Could you please post the complete log file?","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666103759,"metadata":{"github-id":"UCE_lALODBZtRc5McWAqzih984c"},"target":"da776023ce80908bc9a579eb84308a06343b212ee64d9aa74d054a8a3e48da8a","message":"@yarikoptic [We already implemented retrying based on the S3 response.](https://github.com/dandi/dandi-cli/blob/a73a2de8b787ff002bf28f14717279aef550e226/dandi/files/zarr.py#L500)\n\n@slaytonmarx Could you please post the complete log file?","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1666104308,"metadata":{"github-id":"IC_kwDODBZtRc5McZY3","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282512439"},"message":"@jwodder the log ended up being 20gb in full, would it be alright to post excerpts surrounding the error messages (otherwise it will take around 30 minutes to post).","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666104351,"metadata":{"github-id":"IC_kwDODBZtRc5McZoe","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282513438"},"message":"@slaytonmarx Yes.","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1666104997,"metadata":{"github-id":"IC_kwDODBZtRc5Mcdpb","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282529883"},"message":"HTTP Connection Failure\n```\n   702974 2022-10-03T11:55:42-0400 [ERROR   ] dandi 831494:140246036764416 HTTP connection failed\n   702975 Traceback (most recent call last):\n   702976   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 202, in request\n   702977     for i, attempt in enumerate(\n   702978   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 400, in __iter__\n   702979     do = self.iter(retry_state=retry_state)\n   702980   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 378, in iter\n   702981     raise retry_exc.reraise()\n   702982   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 206, in reraise\n   702983     raise self.last_attempt.result()\n   702984   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   702985     return self.__get_result()\n   702986   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   702987     raise self._exception\n   702988   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 232, in request\n   702989     result.raise_for_status()\n   702990   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n   702991     raise HTTPError(http_error_msg, response=self)\n   702992 requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=6          00\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n```\n\nError Uploading\n```\n 703416 2022-10-03T11:55:43-0400 [ERROR   ] dandi 831494:140248591886080 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr:\n   703417 Traceback (most recent call last):\n   703418   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/upload.py\", line 228, in process_path\n   703419     for r in dfile.iter_upload(\n   703420   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/files/zarr.py\", line 443, in iter_upload\n   703421     size = fut.result()\n   703422   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   703423     return self.__get_result()\n   703424   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   703425     raise self._exception\n   703426   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n   703427     result = self.fn(*self.args, **self.kwargs)\n   703428   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/files/zarr.py\", line 494, in _upload_zarr_file\n   703429     storage_session.put(\n   703430   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 303, in put\n   703431     return self.request(\"PUT\", path, **kwargs)\n   703432   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 202, in request\n   703433     for i, attempt in enumerate(\n   703434   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 400, in __iter__\n   703435     do = self.iter(retry_state=retry_state)\n   703436   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 378, in iter\n   703437     raise retry_exc.reraise()\n   703438   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 206, in reraise\n   703439     raise self.last_attempt.result()\n   703440   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   703441     return self.__get_result()\n   703442   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   703443     raise self._exception\n   703444   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 232, in request\n   703445     result.raise_for_status()\n   703446   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n   703447     raise HTTPError(http_error_msg, response=self)\n   703448 requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=6          00\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n   703449 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Received result for ('size', 'errors', 'upload', 'status', 'message'): {'status': 'ERROR', 'message': '501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algo          rithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e'}\n   703450 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Processing result as mapping\n   703451 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247660754688 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-6_SPIM.ome.zarr/0/0/0/3/3/58\n   703452 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140248008861440 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-6_SPIM.ome.zarr/0/0/0/3/3/3\n   703453 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247291639552 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-3_SPIM.ome.zarr/0/0/0/1/6/105\n   703454 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247283246848 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-3_SPIM.ome.zarr/0/0/0/1/6/172\n   703455 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Acquiring write lock\n   703456 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Clearing summary of 3 line(s)\n   703457 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.common 831494:140248591886080 Updating content for row ('sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr',)\n   703458 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width for row {'path': 'sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr', 'size': 90606988135, 'errors': \u003cpyout.field.Nothing object at 0x7f8e308d0c10\u003e, 'upload': 2.6606732136333098, 'status': 'ERROR', 'message': '501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e'}\n```\n\nError 400\n```\n 25929318 2022-10-03T14:54:45-0400 [DEBUG   ] urllib3.connectionpool 831494:140247616182016 https://dandiarchive.s3.amazonaws.com:443 \"PUT /zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/100?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185          438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=6e3fbe114ba5e31d22c45734d36b6e54a9a775d0ad78e24d94959443e3025049 HTTP/1.1\" 200 0\n 25929319 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140248675858176 Response: 400\n 25929320 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Clearing summary of 11 line(s)\n 25929321 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247325210368 Response: 200\n 25929322 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247616182016 Response: 200\n 25929323 2022-10-03T14:54:45-0400 [ERROR   ] dandi 831494:140248675858176 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/8ccf0936-63f7-4681-857b-84e4ebab7662/upload/complete/: [\"No upload in progress.\"]\n 25929324 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Updating content for row ('sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr',)\n 25929325 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width for row {'path': 'sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr', 'size': 84717401747, 'errors': \u003cpyout.field.Nothing object at 0x7f8e308d0c10\u003e, 'upload': 40.001838092685276, 'status': 'uploading', 'message': 'exists - reuploading'}\n 25929326 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width of column 'path' (current field width: 40)\n 25929327 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140244187846400 PUT https://dandiarchive.s3.amazonaws.com/zarr/a01c0b33-b53d-4adb-9603-5b6acf21ee20/0/0/0/8/13/158?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185421Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=de7fb3706a802dcc39d29a8fed1d9ab157179c34bda91b8107f904d628b73cbe\n 25929328 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 value='sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr', value width=117, old field length=40, min width=20, max width=None =\u003e wants=117\n 25929329 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247616182016 PUT https://dandiarchive.s3.amazonaws.com/zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/36?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=8471e63b16bd700e76f2d011ab6df310522c67929c308f39756dece022aace8f\n 25929330 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247325210368 PUT https://dandiarchive.s3.amazonaws.com/zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/141?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=bc2a615283437a1dd5058ce5e12c2cd7434f89ade9b62effb07ab51481c019b1\n```\n\nThere were multiple instances of these failures but these cover the unique catagories","files":null},{"type":6,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1666105012,"metadata":{"github-id":"UCE_lALODBZtRc5Mcdpbzih-QT4"},"target":"636b8c09a0bde2db74c14ae7fc63cfa47ca77150a3cec01c85f3f3c16bd810e9","message":"HTTP Connection Failure\n```\n   702974 2022-10-03T11:55:42-0400 [ERROR   ] dandi 831494:140246036764416 HTTP connection failed\n   702975 Traceback (most recent call last):\n   702976   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 202, in request\n   702977     for i, attempt in enumerate(\n   702978   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 400, in __iter__\n   702979     do = self.iter(retry_state=retry_state)\n   702980   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 378, in iter\n   702981     raise retry_exc.reraise()\n   702982   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 206, in reraise\n   702983     raise self.last_attempt.result()\n   702984   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   702985     return self.__get_result()\n   702986   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   702987     raise self._exception\n   702988   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 232, in request\n   702989     result.raise_for_status()\n   702990   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n   702991     raise HTTPError(http_error_msg, response=self)\n   702992 requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=6          00\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n```\n\nError Uploading\n```\n 703416 2022-10-03T11:55:43-0400 [ERROR   ] dandi 831494:140248591886080 Error uploading /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr:\n   703417 Traceback (most recent call last):\n   703418   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/upload.py\", line 228, in process_path\n   703419     for r in dfile.iter_upload(\n   703420   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/files/zarr.py\", line 443, in iter_upload\n   703421     size = fut.result()\n   703422   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   703423     return self.__get_result()\n   703424   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   703425     raise self._exception\n   703426   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/thread.py\", line 57, in run\n   703427     result = self.fn(*self.args, **self.kwargs)\n   703428   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/files/zarr.py\", line 494, in _upload_zarr_file\n   703429     storage_session.put(\n   703430   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 303, in put\n   703431     return self.request(\"PUT\", path, **kwargs)\n   703432   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 202, in request\n   703433     for i, attempt in enumerate(\n   703434   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 400, in __iter__\n   703435     do = self.iter(retry_state=retry_state)\n   703436   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 378, in iter\n   703437     raise retry_exc.reraise()\n   703438   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/tenacity/__init__.py\", line 206, in reraise\n   703439     raise self.last_attempt.result()\n   703440   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 437, in result\n   703441     return self.__get_result()\n   703442   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n   703443     raise self._exception\n   703444   File \"/home/smarx/.local/lib/python3.8/site-packages/dandi/dandiapi.py\", line 232, in request\n   703445     result.raise_for_status()\n   703446   File \"/mnt/beegfs/satra/miniconda3/envs/dandi/lib/python3.8/site-packages/requests/models.py\", line 943, in raise_for_status\n   703447     raise HTTPError(http_error_msg, response=self)\n   703448 requests.exceptions.HTTPError: 501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=6          00\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e\n   703449 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Received result for ('size', 'errors', 'upload', 'status', 'message'): {'status': 'ERROR', 'message': '501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algo          rithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e'}\n   703450 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Processing result as mapping\n   703451 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247660754688 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-6_SPIM.ome.zarr/0/0/0/3/3/58\n   703452 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140248008861440 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-NN_run-1_chunk-6_SPIM.ome.zarr/0/0/0/3/3/3\n   703453 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247291639552 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-3_SPIM.ome.zarr/0/0/0/1/6/105\n   703454 2022-10-03T11:55:43-0400 [DEBUG   ] dandi.support.digests 831494:140247283246848 Estimating digests for /mnt/beegfs/Lee/dandi/sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-LEC_run-1_chunk-3_SPIM.ome.zarr/0/0/0/1/6/172\n   703455 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Acquiring write lock\n   703456 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Clearing summary of 3 line(s)\n   703457 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.common 831494:140248591886080 Updating content for row ('sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr',)\n   703458 2022-10-03T11:55:43-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width for row {'path': 'sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-4_SPIM.ome.zarr', 'size': 90606988135, 'errors': \u003cpyout.field.Nothing object at 0x7f8e308d0c10\u003e, 'upload': 2.6606732136333098, 'status': 'ERROR', 'message': '501 Server Error: Not Implemented for url: https://dandiarchive.s3.amazonaws.com/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T155437Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=f8073a5d18b39acadee0a53917d2e3a3b55ecf8cbb0b7a2709b678b97bde255e'}\n```\n\nError 400\n```\n 25929318 2022-10-03T14:54:45-0400 [DEBUG   ] urllib3.connectionpool 831494:140247616182016 https://dandiarchive.s3.amazonaws.com:443 \"PUT /zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/100?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185          438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=6e3fbe114ba5e31d22c45734d36b6e54a9a775d0ad78e24d94959443e3025049 HTTP/1.1\" 200 0\n 25929319 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140248675858176 Response: 400\n 25929320 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.interface 831494:140248591886080 Clearing summary of 11 line(s)\n 25929321 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247325210368 Response: 200\n 25929322 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247616182016 Response: 200\n 25929323 2022-10-03T14:54:45-0400 [ERROR   ] dandi 831494:140248675858176 Error 400 while sending POST request to https://api.dandiarchive.org/api/zarr/8ccf0936-63f7-4681-857b-84e4ebab7662/upload/complete/: [\"No upload in progress.\"]\n 25929324 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Updating content for row ('sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr',)\n 25929325 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width for row {'path': 'sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr', 'size': 84717401747, 'errors': \u003cpyout.field.Nothing object at 0x7f8e308d0c10\u003e, 'upload': 40.001838092685276, 'status': 'uploading', 'message': 'exists - reuploading'}\n 25929326 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 Checking width of column 'path' (current field width: 40)\n 25929327 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140244187846400 PUT https://dandiarchive.s3.amazonaws.com/zarr/a01c0b33-b53d-4adb-9603-5b6acf21ee20/0/0/0/8/13/158?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185421Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=de7fb3706a802dcc39d29a8fed1d9ab157179c34bda91b8107f904d628b73cbe\n 25929328 2022-10-03T14:54:45-0400 [DEBUG   ] pyout.common 831494:140248591886080 value='sub-MITU01/ses-20220316h10m52s23/micr/sub-MITU01_ses-20220316h10m52s23_sample-12_stain-YO_run-1_chunk-3_SPIM.ome.zarr', value width=117, old field length=40, min width=20, max width=None =\u003e wants=117\n 25929329 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247616182016 PUT https://dandiarchive.s3.amazonaws.com/zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/36?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=8471e63b16bd700e76f2d011ab6df310522c67929c308f39756dece022aace8f\n 25929330 2022-10-03T14:54:45-0400 [DEBUG   ] dandi 831494:140247325210368 PUT https://dandiarchive.s3.amazonaws.com/zarr/cca49be5-ca68-4bbb-99e0-b97c22291c05/0/0/0/10/8/141?X-Amz-Algorithm=AWS4-HMAC-SHA256\u0026X-Amz-Credential=AKIAUBRWC5GAEKH3223E%2F20221003%2Fus-east-2%2Fs3%2Faws4_request\u0026X-Amz-Date=20221003T185438Z\u0026X-Amz-Expires=600\u0026X-Amz-SignedHeaders=host%3Bx-amz-acl\u0026X-Amz-Signature=bc2a615283437a1dd5058ce5e12c2cd7434f89ade9b62effb07ab51481c019b1\n```\n\nThere were multiple instances of these failures but these cover the unique categories","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666108682,"metadata":{"github-id":"IC_kwDODBZtRc5Mc13u","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282629102"},"message":"\u003e @yarikoptic [We already implemented retrying based on the S3 response.](https://github.com/dandi/dandi-cli/blob/a73a2de8b787ff002bf28f14717279aef550e226/dandi/files/zarr.py#L500)\n\nI meant retrying to get the size of the payload.  Were you talking about https://github.com/kennethreitz/requests/blob/HEAD/requests/utils.py#L119 ?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666108770,"metadata":{"github-id":"IC_kwDODBZtRc5Mc2U_","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282630975"},"message":"@yarikoptic No, my point was that we already implemented retrying in order to deal with this exact issue, only in a reactive way rather than a proactive, monkey-patching way.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666109695,"metadata":{"github-id":"IC_kwDODBZtRc5Mc7cA","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282651904"},"message":"@slaytonmarx \n\n* What version of dandi are you using?\n* If you delete all the pyout lines from the log, what does the file size go down to?\n* Could you give me more context, before and after the errors, with all pyout lines removed?","files":null},{"type":3,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1666114163,"metadata":{"github-id":"IC_kwDODBZtRc5MdWG6","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282761146"},"message":"* **Dandi Version:** My dandi version is **0.46.3**\n* **Log File Size:** Without pyout we're down to 702 MB, I'm uploading it here\n* **More Contesxt:** See attachment\n\nhttps://drive.google.com/file/d/1ueZ4g2Pqsuwg5iEY1-VN-CRVNaPaAm7x/view?usp=sharing","files":null},{"type":6,"author":{"id":"adccd23cf679e6fb55b1c23d1d08cb100dec6f4e"},"timestamp":1666191082,"metadata":{"github-id":"UCE_lALODBZtRc5MdWG6ziiLW6M"},"target":"f28d6d926ec46e546f16af2a63110a29e27d910d5af3f67230386d507676a1d6","message":"* **Dandi Version:** My dandi version is **0.46.3**\n* **Log File Size:** Without pyout we're down to 702 MB, I'm uploading it here\n* **More Context:** See attachment\n\nhttps://drive.google.com/file/d/1ueZ4g2Pqsuwg5iEY1-VN-CRVNaPaAm7x/view?usp=sharing","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666115183,"metadata":{"github-id":"IC_kwDODBZtRc5MdbAt","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282781229"},"message":"\u003e @yarikoptic No, my point was that we already implemented retrying in order to deal with this exact issue, only in a reactive way rather than a proactive, monkey-patching way.\n\ndigesting for myself: indeed so because with tenacity  we wrap around the entire requests call for retrying it, and not relying on some internal requests retrying functionality which would trigger *after* assessing the load size (which is what I thought might be the case).","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666117020,"metadata":{"github-id":"IC_kwDODBZtRc5MdlU5","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282823481"},"message":"Notable observations from Slayton's logs:\n\n* I see eight instances of Zarr entry uploads being retried repeatedly until they ran out of retries and just failed.  Curiously, in the instances that I checked, urllib3 logged the first request (which returned 500 rather than 501) but none of the retried requests.\n* The 400 responses with a body of \"No upload in progress\" are harmless errors that should be fixed by #1139.","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666117109,"metadata":{"github-id":"UCE_lALODBZtRc5MdlU5ziiAyZM"},"target":"1f0e7f4546874da8834d110cebbf2bd50cd57de22c338b654a5fb93a0ece78b9","message":"Notable observations from Slayton's logs:\n\n* I see eight instances of Zarr entry uploads being retried repeatedly until they ran out of retries and just failed.  So retrying is happening, but the underlying error cause isn't going away.\n    * Curiously, in the instances that I checked, urllib3 logged the first request (which returned 500 rather than 501) but none of the retried requests.\n* The 400 responses with a body of \"No upload in progress\" are harmless errors that should be fixed by #1139.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666121305,"metadata":{"github-id":"IC_kwDODBZtRc5Md4NP","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282900815"},"message":"FWIW my quick google for that 501 offered https://stackoverflow.com/questions/7670156/amazon-s3-getting-501-error-on-put which just confirms your earlier analysis @jwodder but also pointed to https://github.com/aws/aws-sdk-go/issues/3429 where it was\n```\nContent-Length: 71429089\nContent-Range: bytes 0-71428789/530045183\n```\nso length is provided but it is part of the upload!  Could requests may be do smth like that?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666121640,"metadata":{"github-id":"IC_kwDODBZtRc5Md5nb","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282906587"},"message":"@yarikoptic I'm not clear what you're asking.  requests' normal behavior is to send a Content-Length header in requests; it's only when it can't determine the value for that header that it falls back to \"chunked\" transfer-encoding, which has no need for such a header.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1666123496,"metadata":{"github-id":"IC_kwDODBZtRc5MeBlh","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282939233"},"message":"I was asking if requests somehow tries to provide partial upload, but I guess it is not the case (I also found no \"Content-Range\" mentioning in requests code base).  \nWhere is that logic/code path within  https://github.com/psf/requests ? If that is https://github.com/psf/requests/blob/HEAD/requests/models.py#L549 \n\n```\n            if length:\n                self.headers[\"Content-Length\"] = builtin_str(length)\n            else:\n                self.headers[\"Transfer-Encoding\"] = \"chunked\"\n```\nthen it would choose \"chunked\" even for 0-length files... but in our case (unless that zarr was written while being uploaded) it is not the case\n\n```\n(base) dandi@drogon:~$ s3cmd -c .s3cfg-dandi-backup ls s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/2\n2022-10-04 08:28      2201134  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/20\n2022-10-04 08:29      2183252  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/21\n2022-10-04 08:29      2184069  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/22\n2022-10-04 08:29      2197303  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/23\n2022-10-04 08:29      2228476  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/24\n2022-10-04 08:29      2299655  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/25\n2022-10-04 08:29      2322689  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/26\n2022-10-04 08:28      2321217  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/27\n2022-10-04 08:29      2326670  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/28\n2022-10-04 08:29      2333477  s3://dandiarchive/zarr/1251b078-041c-42ec-88ff-415d405f556e/1/0/0/3/0/29\n```\n\nUnless we get some fixable idea on what is going on, we might have to instrument  `requests.super_len` to log what it returns (or raises!) for every call get more details about why it is choosing \"chunked\" if that is what is happening, or what are the details (headers) of that particular request for `/21` and/or how is it different from any other surrounding it file (20 and 22 succeed).","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1666124980,"metadata":{"github-id":"IC_kwDODBZtRc5MeIUU","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1282966804"},"message":"@yarikoptic The important points in requests' code are:\n\n* At [`[models.py:518]`](https://github.com/psf/requests/blob/7104ad4b135daab0ed19d8e41bd469874702342b/requests/models.py#L518), because dandi has supplied a file object as the data, `is_stream` gets set to `True`.\n* Hence, at [`[models.py:525-529]`](https://github.com/psf/requests/blob/7104ad4b135daab0ed19d8e41bd469874702342b/requests/models.py#L525-529), `super_len()` is called on the data, and if it fails for any reason, `None` is used as the result.\n* Within `super_len(o)` with `o` being a file object, we move to [`[utils.py:138]`](https://github.com/psf/requests/blob/7104ad4b135daab0ed19d8e41bd469874702342b/requests/utils.py#L138), where the file's file descriptor is obtained and then used in an fstat call to get the size of the underlying file.\n    * In Slayton's case, it appears that the code is failing at either the `fileno()` call or the `fstat()` call. \n* If `super_len()` failed, then at [`[models.py:552]`](https://github.com/psf/requests/blob/7104ad4b135daab0ed19d8e41bd469874702342b/requests/models.py#L552), the Transfer-Encoding is set to \"chunked\".","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1678372324,"metadata":{"github-id":"IC_kwDODBZtRc5XJtf0","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1462163444"},"message":"zarr upload mechanism was redone.  @jwodder do you think this issue still applies?\n@slaytonmarx - did you upload zarrs any time recently and ran into the same issue?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1678372559,"metadata":{"github-id":"IC_kwDODBZtRc5XJu7P","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1462169295"},"message":"@yarikoptic The new Zarr mechanism doesn't even have \"uploads\" or a need for them to not be simultaneous, so it no longer applies (unless you're referring to the chunked encoding issue, which is a separate thing that isn't affected by the change to Zarrs).","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1678373535,"metadata":{"github-id":"IC_kwDODBZtRc5XJ07K","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1462193866"},"message":"yeah -- there were multiple issues buried in this \"issue\". Let's wait for a day for a reply from @slaytonmarx on either he is still experiencing the chunked encoding one by any chance, and if not or no reply - consider it resolved for now.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1679318817,"metadata":{"github-id":"IC_kwDODBZtRc5X_YQX","github-url":"https://github.com/dandi/dandi-cli/issues/1028#issuecomment-1476232215"},"message":"let's consider resolved then","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1679318817,"metadata":{"github-id":"CE_lADODBZtRc5LZcmhzwAAAAIMMhY5"},"status":2}]}