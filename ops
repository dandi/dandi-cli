{"version":2,"ops":[{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1608062480,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdElzc3VlRWRpdDo0NjkwNzk4NDU="},"target":"f15e03a37d37d21a15557d2d2114f534f7731eba285cb39f4d6b75268b932ba3","message":"A decision was made in https://github.com/dandi/dandi-cli/pull/283 to aim to get `master` in a shape to support interaction with both current girder-based deployed dandiarchive **and** WiP https://github.com/dandi/dandi-api implementations within the same code base. I think it is doable.  #283 will provide \"internal\" interfaces for an upload/download cycle and then we would need to use/expose  them through top level interfaces.  For that, I think we should\n\n- to `known_instances` add a new entry `\"dandi-api\"` which would have no girder, we ui, redirector and only API. \n  - we would need also at least a `dandi-api-local-docker-tests` to point to the fixture'd instance\n  - we should not occlude other existing fixtures/instances such as `local-docker-tests` since they reflect the instances of currently deployed dandiarchive setup (albeit now without any API which was provided by publish. for a bit)\n    -  edit: https://github.com/dandi/dandi-cli/pull/283/files#diff-96e695b73dd490b5f194b670b03c04d549000cb6c3e9b3fef76e8065c68c041aR100 suggests to reuse the same record, which seems to be Ok ATM since we have no longer `publish.` API to worry about.  But I think it would just delay establishing such a dedicated record, whenever we do get a test deployment of new web ui/redirector which would work with new API.  So IMHO might be better to be explicit and have separate dedicated records\n  - most likely we should add `metadata-version` \"field\" to those records, where for old ones it would be 0 (unversioned ad-hoc), and then `1` for the new version of metadata (ideally it should [be the API server](https://github.com/dandi/dandi-api/issues/36) which tells which version of metadata schema it expects, but that is -- later).\n\n### upload\n\n- `--dandi-instance` option of `dandi upload` (in DANDI_DEVEL mode) would automagically list those added instance(s)\n  - `upload` code should be RFed (main logic is in [`process_path`](https://github.com/dandi/dandi-cli/blob/master/dandi/upload.py#L147) so it could support both upload to original girder-based client and new API-based one\n     - for new API-based one, metadata extraction should use new metadata (version 1) schema\n\n### download\n\nfor `download`, which does not rely on explicit specification of which instance to talk to, but parses from URL/identifier we need to come up with a \"schema\" on how to reference content from new API server, which would be easy on humans and flexible to support multiple instances/servers.  Specification/parsing of such urls should be added to `known_urls` (https://github.com/dandi/dandi-cli/blob/master/dandi/dandiarchive.py#L109).\n\nSo what about just taking what we had/(have) on a recent iteration with `publish` API and tune it to correspond to our API (`/dandisets/{version__dandiset__pk}/versions/{version__version}/assets/paths/`) call:\n\n```python\n       f\"{server_grp}#.*/(?P\u003casset_type\u003edandiset)s/{dandiset_id_grp}\"\n        \"/(?P\u003cversion\u003eversions/([.0-9]{5,}|draft))\"\n        \"(/assets/path(?location=(?P\u003clocation\u003e.*)?)?)?\"\n        \"$\": {\"server_type\": \"dandi-api\"}\n```\n\nNB initially I thought we might need to add some optional prefix `f\"(dandi-api::)?\" for early \"decision making\" but because of unique `/dandisets/` I think we do not need it\n\nso sample url for download would look like   \n\n- `https://api.dandiarchive.org/dandisets/000001`, `https://api.dandiarchive.org/dandisets/000001/versions/draft`, `https://api.dandiarchive.org/dandisets/000001/versions/draft/path/`  -- entire dataset, draft version\n- `https://api.dandiarchive.org/dandisets/000001/0.0.1` -- entire dataset, `0.0.1` version\n- `https://api.dandiarchive.org/dandisets/000001/draft/path/sub-XXX` -- sub-XXX folder (or a file if points to an asset) of draft version\n\ninstead of `api.dandiarchive.org`, urls could point to `localhost:port` in the test.\n\nLater, whenever web UI starts using API, we would need to adjust other \"schemas\". redirector will start redirecting to new web ui, possibly different urls.  But for now, IMHO it is sensible to just follow the API URLs.  Those will not be really \"visible\" to users, but would allow us to test new functionality/interaction with API server.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1608301502,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc0ODExMTE5OA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-748111198"},"message":"@yarikoptic \n\n\u003e we would need also at least a `dandi-api-local-docker-tests` to point to the fixture'd instance\n\nThe dandi-api Docker Compose setup seems to currently depend on the Girder Docker Compose setup, so they can't be split apart, so creating separate `known_instance` values doesn't seem like a good idea.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1608302779,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc0ODEyMjYzMA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-748122630"},"message":"I don't exactly see how known_instances so tightly bound to docker compose setup - it is ok to reuse the same compose setup for multiple instances with some code support","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1610740403,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MTE2NTM0MA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-761165340"},"message":"@yarikoptic The Girder upload code has a number of provisions for handling files that have already been uploaded.  Should this be carried over to the new API?  I'm not entirely sure how all the parts should be translated.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1610742152,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MTE3ODI4OA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-761178288"},"message":"No. In our reimplantation, iirc, we will rely on gc (not sure if there already) to delete no longer used assets and unfinished uploads.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1610742171,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MTE3ODQ0NA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-761178444"},"message":"No. In our reimplantation, iirc, we will rely on gc (not sure if there already) to delete no longer used assets and unfinished uploads.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1611000922,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MjQ1MTk2NQ==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-762451965"},"message":"@yarikoptic Adding a new `dandi-api` server type for the new download URL pattern requires adding a `dandi-api` entry to `_dandi_url_parser.map_to` and populating it.  How exactly should that be done?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1611013054,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MjUxNDU5Mw==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-762514593"},"message":"That is something I do not have immediate answer for.  I have suggested/asked on slack either we might want to establish `gui-beta.dandiarchive.org` and then provide such mapping.  But I am not sure if that is the approach we would be taking, so for now let's just breed a custom `api+\u003cURL\u003e` url schema to parse, so `https://gui.dandiarchive.org/#/dandiset/000007` - would be old girder based, and `api+https://gui.dandiarchive.org/#/dandiset/000007` would be the new one.  That would allow later to change easily.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1611086112,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MzA5MDE3NA==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-763090174"},"message":"@yarikoptic I'm not entirely clear on what you're proposing here.  Could you elaborate?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1611112862,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc2MzMwMjEwMg==","github-url":"https://github.com/dandi/dandi-cli/issues/320#issuecomment-763302102"},"message":"I have pushed f9fa14bd9ed464d982864eefd34349b3f043e979 to #330 which adds that and trims lots of elderly no longer needed URL schemas etc.  See commit message (and some TODOs in the diff) for more information.  Now you should be able to download `api+https://gui.dandiarchive.org/#/dandiset/000007/draft` or `https://gui.dandiarchive.org/#/dandiset/000007/draft` (which would be entirely different things ;)).","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1611612992,"metadata":{"github-id":"MDExOkNsb3NlZEV2ZW50NDI0Nzk2NzcxMw=="},"status":2}]}