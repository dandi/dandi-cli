{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1753811118,"metadata":{"github-id":"IC_kwDODBZtRc66xOIC","github-url":"https://github.com/dandi/dandi-cli/issues/1670#issuecomment-3133465090"},"message":"FWIW -- we already (ab)use caching extensively, primarily in cases of local files via our https://github.com/con/fscacher \n\n```shell\n❯ git grep -A1 '^[^#]*_cache.memo'\ndandi/metadata/nwb.py:@metadata_cache.memoize_path\ndandi/metadata/nwb.py-def get_metadata(\n--\ndandi/pynwb_utils.py:@metadata_cache.memoize_path\ndandi/pynwb_utils.py-def get_neurodata_types(filepath: str | Path | Readable) -\u003e list[str]:\n--\ndandi/pynwb_utils.py:@validate_cache.memoize_path\ndandi/pynwb_utils.py-def validate(path: str | Path, devel_debug: bool = False) -\u003e list[ValidationResult]:\n--\ndandi/pynwb_utils.py:@metadata_cache.memoize_path\ndandi/pynwb_utils.py-def nwb_has_external_links(filepath: str | Path | Readable) -\u003e bool:\n```\n\nand a few other online interactions\n\n```shell\n❯ git grep -A10 @lru\ndandi/metadata/util.py:@lru_cache(maxsize=None)  # type: ignore[arg-type]\n...\ndandi/metadata/util.py-def parse_purlobourl(\ndandi/metadata/util.py-    url: str, lookup: tuple[str, ...] | None = None\ndandi/metadata/util.py-) -\u003e dict[str, str] | None:\ndandi/metadata/util.py-    \"\"\"Parse an Ontobee URL to return properties of a Class node\n...\n--\ndandi/utils.py:@lru_cache\ndandi/utils.py-def _get_instance(\n...\n```\n\nHere indeed would be nice to establish caching support for remote calls to a corresponding instance API. But there will be no guarantee ATM that our \"marker\" of dandiset modification time would be consistently updated. Based on our experiences with https://github.com/dandi/backups2datalad most of such issues were identified and fixed, but some AFAIK are still lingering, e.g.\n\n- https://github.com/dandi/dandi-archive/issues/2050\n- https://github.com/dandi/dandi-archive/issues/1871\n\nand may be more (these are the ones I quickly found) .  Nevertheless, I think it is worth developing such a feature/functionality even now since in most of the cases it should suffice but we might want to make it optional/opt-in for now.\n\nAdditional aspects to consider\n- do cleanup prior cached version if change was observed\n- add some `dandi cleanup` or alike command which would clean up cache(s) based on age etc\n   - related in fscacher: https://github.com/con/fscacher/issues/43","files":null}]}