{"version":2,"ops":[{"type":1,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1591112148,"metadata":{"github-id":"MDU6SXNzdWU2MjkzMDUxMjU=","github-url":"https://github.com/dandi/dandi-cli/issues/114","origin":"github"},"title":"organize: \"dry run\" on an external dandiset","message":"`organize` has (well, still has although unused) a `simulate` mode, and ability to load metadata from a .json (json lines) file:\n\n```\n    if len(paths) == 1 and paths[0].endswith(\".json\"):\n        # Our dumps of metadata\n        metadata = load_jsonl(paths[0])\n```\n\n`download` already uses a helper to traverse an asset (dandiset or a folder) on dandiarchive:  https://github.com/dandi/dandi-cli/blob/9bdb769430d6c9219b17db24438ecdbd51244608/dandi/girder.py#L200 and I believe full metadata records are included.\n\nThus it should be possible to provide functionality to\n- get listing for all files/assets in dandiset\n- run organize on that metadata\n- compare new paths with original and report which would change.\n\nThat could be ran relatively quickly across **all** draft dandisets to see what would be effected whenever changes to `organize` logic would be introduced.\n\nShortcoming: metadata online might be lacking additional fields which we start to extract (e.g. `probe_ids`), so it might not provide 100% assurance, but at least it would be better than nothing ;)","files":null}]}