{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1680713093,"metadata":{"github-id":"IC_kwDODBZtRc5ZRsht","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1497811053"},"message":"@bendichter @rly does it smell like some bug in pynwb/hdmf somewhere in that `object_id` gets somehow \"killed\"?","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1680729404,"metadata":{"github-id":"IC_kwDODBZtRc5ZTFOq","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1498174378"},"message":"That does not seem possible given [the code](https://github.com/hdmf-dev/hdmf/blob/79f5886e8f1fc505caa313f62597ed638db5a5f8/src/hdmf/container.py#L250-L257), but it's hard to say. @colleenjg could you share those two files with us? I'll send you a link over the dandi slack.","files":null},{"type":3,"author":{"id":"23a0b490ec2a3aef708e5bf3548508030984c8bd"},"timestamp":1680780938,"metadata":{"github-id":"IC_kwDODBZtRc5ZV8eH","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1498924935"},"message":"I just tested it out just downloading one of my files from dandi and updating the object IDs, and I was able to reproduce the problem. Here are the steps I followed (running on `Ubuntu` with the latest package versions (`dandi==0.52.0` and `pynwb==2.3.1`): \n\n1. `bash`: Get a file from **dandiset [000037](https://gui.dandiarchive.org/#/dandiset/000037)**.\n```\nmkdir test_files\nmkdir organize_files\ncd test_files\ndandi download https://api.dandiarchive.org/api/assets/64fba8b4-7d7a-44e4-865e-595fec01e41e/download/\n```\n\n2. `python`: Make a new version of the file in which the **object IDs are updated** using `nwbfile.generate_new_id()`\n```\nfilepath = \"sub-408021_ses-758519303_behavior+ophys.nwb\"\nnew_filepath = filepath.replace(\".nwb\", \"_new_IDs.nwb\")\n\nimport pynwb\nwith pynwb.NWBHDF5IO(filepath, \"r\") as read_io:\n    nwbfile = read_io.read()\n    nwbfile.generate_new_id()\n    with pynwb.NWBHDF5IO(new_filepath, \"w\") as write_io:\n       write_io.export(src_io=read_io, nwbfile=nwbfile)\n```\n\n3. `bash`: Run the **NWB inspector**.\n```\nnwbinspector . --config dandi\n```\n\n\u003e ```\n\u003e Found 11 issues over 3 files: \n\u003e        1 - CRITICAL\n\u003e       10 - BEST_PRACTICE_SUGGESTION\n\u003e ...\n\u003e ```\n\nAs an aside: I'm not sure why it calculates that there are 3 files - there are just 2.\n\nThe **critical error** is a `check_unique_identifiers` error, caused by the fact that I copied the file without changing its `identifier` (only changing its `object_id`). The next step is optional and just to **avoid the validation error** (it doesn't cause or prevent the `dandi organize` error.)\n\n4. [optional] `python`: Optionally **change the identifier** for the new file. FYI, I don't know how to do this via `pynwb`, so I just use `h5py` :/. It's probably not ideal, but as said above, the `dandi organize` error occurs independently of this step.\n\n```\nimport h5py\nwith h5py.File(new_filepath, \"a\") as f:\n    identifier = f[\"identifier\"][()].decode()\n    f[\"identifier\"][()] = f\"{identifier}_test_IDs\"\n```\n\n5. [optional] `bash`: Rerun the **NWB inspector**.\n```\nnwbinspector . --config dandi\n```\n\u003e ```\n\u003e Found 10 issues over 2 files: \n\u003e       10 - BEST_PRACTICE_SUGGESTION\n\u003e ...\n\u003e ```\n\nThe **critical error** is gone now.\n\n6. `bash`: Run **`dandi organize`**.\n```\ncd ../organize_files  \ndandi download DANDI:000037/draft --download dandiset.yaml\ncd 000037\ndandi organize ../../test_files -f dry\n```\n\nThis is where the **`Completely empty record`** error occurs.\n\n\u003e```\n\u003e 2023-04-06 07:00:58,212 [    INFO] Loading metadata from 2 files\n\u003e [Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n\u003e /home/user/.conda/envs/nwbup/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.5.0 because version 2.6.0-alpha is already loaded.\n\u003e   warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n\u003e [Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n\u003e [Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    3.2s finished\n\u003e 2023-04-06 07:01:01,429 [ WARNING] Completely empty record for ../../test_files/sub-408021_ses-758519303_behavior+ophys_new_IDs.nwb\n\u003e 2023-04-06 07:01:01,430 [    INFO] Logs saved in /home/user/.cache/dandi-cli/log/20230406110056Z-253278.log\n\u003e Error: 1 out of 2 files were found not containing all necessary metadata: ../../test_files/sub-408021_ses-758519303_behavior+ophys_new_IDs.nwb\n\u003e```\n\n\n**NOTES**:\n- I found that this error does **not** occur if I use `nwbfile.generate_new_id(recurse=False)` (in my case, this is a sufficient solution). So I assume it's caused by changes in the IDs of the objects in the NWB file.\n- I tested the same code out on 2 other files. The test on a file from dandiset [000448](https://dandiarchive.org/dandiset/000448/draft/files?location=sub-002-F) doesn't result in this error. The test on a file from dandiset [000167](https://dandiarchive.org/dandiset/000167/0.220928.1306/files?location=sub-7) does reproduce the error. So I would imagine it's due to objects/modules in common between my file and this one. \n\nThere ends my investigation...!","files":null},{"type":6,"author":{"id":"23a0b490ec2a3aef708e5bf3548508030984c8bd"},"timestamp":1680781041,"metadata":{"github-id":"UCE_lALODBZtRc5ZV8eHzi-dpqE"},"target":"501219f12ce4631257fecd48868ea6b15df2dfcabf52d7ede9309049a6693ce5","message":"I tested it out just downloading one of my files from dandi and updating the object IDs, and I was able to reproduce the problem. Here are the steps I followed (running on `Ubuntu` with the latest package versions (`dandi==0.52.0` and `pynwb==2.3.1`): \n\n1. `bash`: Get a file from **dandiset [000037](https://gui.dandiarchive.org/#/dandiset/000037)**.\n```\nmkdir test_files\nmkdir organize_files\ncd test_files\ndandi download https://api.dandiarchive.org/api/assets/64fba8b4-7d7a-44e4-865e-595fec01e41e/download/\n```\n\n2. `python`: Make a new version of the file in which the **object IDs are updated** using `nwbfile.generate_new_id()`\n```\nfilepath = \"sub-408021_ses-758519303_behavior+ophys.nwb\"\nnew_filepath = filepath.replace(\".nwb\", \"_new_IDs.nwb\")\n\nimport pynwb\nwith pynwb.NWBHDF5IO(filepath, \"r\") as read_io:\n    nwbfile = read_io.read()\n    nwbfile.generate_new_id()\n    with pynwb.NWBHDF5IO(new_filepath, \"w\") as write_io:\n       write_io.export(src_io=read_io, nwbfile=nwbfile)\n```\n\n3. `bash`: Run the **NWB inspector**.\n```\nnwbinspector . --config dandi\n```\n\n\u003e ```\n\u003e Found 11 issues over 3 files: \n\u003e        1 - CRITICAL\n\u003e       10 - BEST_PRACTICE_SUGGESTION\n\u003e ...\n\u003e ```\n\nAs an aside: I'm not sure why it calculates that there are 3 files - there are just 2.\n\nThe **critical error** is a `check_unique_identifiers` error, caused by the fact that I copied the file without changing its `identifier` (only changing its `object_id`). The next step is optional and just to **avoid the validation error** (it doesn't cause or prevent the `dandi organize` error.)\n\n4. [optional] `python`: Optionally **change the identifier** for the new file. FYI, I don't know how to do this via `pynwb`, so I just use `h5py` :/. It's probably not ideal, but as said above, the `dandi organize` error occurs independently of this step.\n\n```\nimport h5py\nwith h5py.File(new_filepath, \"a\") as f:\n    identifier = f[\"identifier\"][()].decode()\n    f[\"identifier\"][()] = f\"{identifier}_test_IDs\"\n```\n\n5. [optional] `bash`: Rerun the **NWB inspector**.\n```\nnwbinspector . --config dandi\n```\n\u003e ```\n\u003e Found 10 issues over 2 files: \n\u003e       10 - BEST_PRACTICE_SUGGESTION\n\u003e ...\n\u003e ```\n\nThe **critical error** is gone now.\n\n6. `bash`: Run **`dandi organize`**.\n```\ncd ../organize_files  \ndandi download DANDI:000037/draft --download dandiset.yaml\ncd 000037\ndandi organize ../../test_files -f dry\n```\n\nThis is where the **`Completely empty record`** error occurs.\n\n\u003e```\n\u003e 2023-04-06 07:00:58,212 [    INFO] Loading metadata from 2 files\n\u003e [Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n\u003e /home/user/.conda/envs/nwbup/lib/python3.9/site-packages/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.5.0 because version 2.6.0-alpha is already loaded.\n\u003e   warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n\u003e [Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    3.2s remaining:    0.0s\n\u003e [Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    3.2s finished\n\u003e 2023-04-06 07:01:01,429 [ WARNING] Completely empty record for ../../test_files/sub-408021_ses-758519303_behavior+ophys_new_IDs.nwb\n\u003e 2023-04-06 07:01:01,430 [    INFO] Logs saved in /home/user/.cache/dandi-cli/log/20230406110056Z-253278.log\n\u003e Error: 1 out of 2 files were found not containing all necessary metadata: ../../test_files/sub-408021_ses-758519303_behavior+ophys_new_IDs.nwb\n\u003e```\n\n\n**NOTES**:\n- I found that this error does **not** occur if I use `nwbfile.generate_new_id(recurse=False)` (in my case, this is a sufficient solution). So I assume it's caused by changes in the IDs of the objects in the NWB file, and not by the change to `nwbfile.object_id`.\n- I tested the same code out on 2 other files. The test on a file from dandiset [000448](https://dandiarchive.org/dandiset/000448/draft/files?location=sub-002-F) doesn't result in this error. The test on a file from dandiset [000167](https://dandiarchive.org/dandiset/000167/0.220928.1306/files?location=sub-7) does reproduce the error. So I would imagine it's due to objects/modules in common between my file and this one. \n\nThere ends my investigation...!","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681247042,"metadata":{"github-id":"IC_kwDODBZtRc5ZppUJ","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1504089353"},"message":"Thank you @colleenjg for the detailed minimum working example. I can reproduce the error and will investigate.","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681261425,"metadata":{"github-id":"IC_kwDODBZtRc5ZqsU3","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1504363831"},"message":"@colleenjg please try installing this branch of HDMF referenced in https://github.com/hdmf-dev/hdmf/pull/847:\n```\npip uninstall hdmf --yes\npip install git+https://github.com/hdmf-dev/hdmf.git@fix/export_links\n```\n\nAnd let me know if that resolves the error. It does on my end. I now get on `dandi organize`:\n```\ndev ‚ùØ dandi organize ../dandiset000037 \n2023-04-11 17:59:05,028 [    INFO] Loading metadata from 2 files\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n/Users/rly/Documents/NWB/hdmf/src/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.5.1 is already loaded.\n  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n/Users/rly/Documents/NWB/hdmf/src/hdmf/spec/namespace.py:531: UserWarning: Ignoring cached namespace 'core' version 2.2.5 because version 2.6.0-alpha is already loaded.\n  warn(\"Ignoring cached namespace '%s' version %s because version %s is already loaded.\"\n[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.6s remaining:    0.0s\n[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    1.6s finished\n2023-04-11 17:59:06,678 [    INFO] Symlink support autodetected; setting files_mode='symlink'\n2023-04-11 17:59:06,682 [    INFO] 1 out of 2 paths are not unique. We will try adding _obj- based on crc32 of object_id\n2023-04-11 17:59:06,683 [    INFO] Organized 2 paths. Visit /Users/rly/Downloads/000037/\n2023-04-11 17:59:06,683 [    INFO] Logs saved in /Users/rly/Library/Logs/dandi-cli/20230412005903Z-13065.log\n```\n\nNote that `1 out of 2 paths are not unique. We will try adding _obj- based on crc32 of object_id` is returned. I'm not sure why. The session `identifier` was modified in the exported file. That should be enough to create two different file names, even if the subject ID is the same.","files":null},{"type":3,"author":{"id":"23a0b490ec2a3aef708e5bf3548508030984c8bd"},"timestamp":1681296297,"metadata":{"github-id":"IC_kwDODBZtRc5ZtVtW","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1505057622"},"message":"I just tried it out, and even rerunning everything from scratch after reinstalling `hdmf` doesn't work on my end, unfortunately. I still get the metadata error.\n\nHere is my `pip freeze` output:\n```\nappdirs==1.4.4\narrow==1.2.3\nasciitree==0.3.3\nasttokens==2.2.1\nattrs==22.2.0\nbackcall==0.2.0\nbidsschematools==0.6.0\nblessings==1.7\nboto3==1.24.96\nbotocore==1.27.96\ncertifi @ file:///croot/certifi_1665076670883/work/certifi\ncffi==1.15.1\ncharset-normalizer==3.0.1\nci-info==0.3.0\nclick==8.1.3\nclick-didyoumean==0.3.0\ncryptography==39.0.1\ndandi==0.52.0\ndandischema==0.8.2\ndecorator==5.1.1\ndnspython==2.3.0\nemail-validator==1.3.1\nentrypoints==0.4\netelemetry==0.3.0\nexecuting==1.2.0\nfasteners==0.18\nfqdn==1.5.1\nfscacher==0.3.0\nh5py==3.8.0\nhdmf @ git+https://github.com/hdmf-dev/hdmf.git@8af3ee7e0047e70b50ef389aafa6e468f313a25b\nhumanize==4.6.0\nidna==3.4\nimportlib-metadata==6.0.0\ninterleave==0.2.1\nipython==8.10.0\nisodate==0.6.1\nisoduration==20.11.0\njaraco.classes==3.2.3\njedi==0.18.2\njeepney==0.8.0\njmespath==1.0.1\njoblib==1.2.0\njsonpointer==2.3\njsonschema==4.17.3\nkeyring==23.13.1\nkeyrings.alt==4.2.0\nmatplotlib-inline==0.1.6\nmore-itertools==9.0.0\nnatsort==8.2.0\nnumcodecs==0.11.0\nnumpy==1.23.5\nnwbinspector==0.4.26\npackaging==23.0\npandas==1.5.3\nparso==0.8.3\npexpect==4.8.0\npickleshare==0.7.5\nprompt-toolkit==3.0.36\nptyprocess==0.7.0\npure-eval==0.2.2\npycparser==2.21\npycryptodomex==3.17\npydantic==1.10.5\nPygments==2.14.0\npynwb==2.3.1\npyout==0.7.2\npyrsistent==0.19.3\npython-dateutil==2.8.2\npytz==2022.7.1\nPyYAML==6.0\nrequests==2.28.2\nrfc3339-validator==0.1.4\nrfc3987==1.3.8\nruamel.yaml==0.17.21\nruamel.yaml.clib==0.2.7\ns3transfer==0.6.0\nscipy==1.10.0\nSecretStorage==3.3.3\nsemantic-version==2.10.0\nsix==1.16.0\nstack-data==0.6.2\ntenacity==8.2.1\ntqdm==4.64.1\ntraitlets==5.9.0\ntyping_extensions==4.5.0\nuri-template==1.2.0\nurllib3==1.26.14\nwcwidth==0.2.6\nwebcolors==1.12\nzarr==2.14.1\nzarr-checksum==0.2.8\nzipp==3.14.0\n```\n\nAs an aside, I'm not surprised that you got `1 out of 2 paths are not unique. We will try adding _obj- based on crc32 of object_id`, since the `session_id` is used in generating the file name, but not the unique identifier is not part of the naming convention, at present.","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681334541,"metadata":{"github-id":"IC_kwDODBZtRc5ZwzqY","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1505966744"},"message":"Thanks @colleenjg . I figured out the discrepancy -- my filepath had a \"/\" in it and apparently that makes a difference. I'll work on a fix.","files":null},{"type":6,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681334631,"metadata":{"github-id":"UCE_lALODBZtRc5ZwzqYzi_eNII"},"target":"e2d6d52e2ad81354c365c088e56a4ee01dfa3bc531f47e5e97c32b96826e9efd","message":"Thanks @colleenjg . I figured out the discrepancy -- ~my filepath had a \"/\" in it~ I had changed the filepath to be an absolute path and apparently that makes a difference. I'll work on a fix.","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681338023,"metadata":{"github-id":"IC_kwDODBZtRc5ZxF1L","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1506041163"},"message":"@colleenjg I pushed a fix. Could you please try again? Thanks for your patience on this!","files":null},{"type":3,"author":{"id":"23a0b490ec2a3aef708e5bf3548508030984c8bd"},"timestamp":1681338571,"metadata":{"github-id":"IC_kwDODBZtRc5ZxHlE","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1506048324"},"message":"It worked! :)","files":null},{"type":3,"author":{"id":"24891a1a9a6057dee135acf783d3b5f6d886008e"},"timestamp":1681339057,"metadata":{"github-id":"IC_kwDODBZtRc5ZxJQ0","github-url":"https://github.com/dandi/dandi-cli/issues/1266#issuecomment-1506055220"},"message":"Awesome. We'll release a fix later today.","files":null},{"type":4,"author":{"id":"23a0b490ec2a3aef708e5bf3548508030984c8bd"},"timestamp":1682217612,"metadata":{"github-id":"CE_lADODBZtRc5ir960zwAAAAIc200y"},"status":2}]}