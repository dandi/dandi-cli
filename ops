{"version":2,"ops":[{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1645047276,"metadata":{"github-id":"IC_kwDODBZtRc4-ILd4","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1042331512"},"message":"\u003e benefit is not yet 100% clear\n\nisn't 20x less a benefit :)","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645063777,"metadata":{"github-id":"IC_kwDODBZtRc4-Izxl","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1042496613"},"message":"Ha ha, we don't see that 20x yet in facacher - we might be starting too much or just having it too Pythonic ;-) yet to profile etc","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645111289,"metadata":{"github-id":"IC_kwDODBZtRc4-K-R-","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1043063934"},"message":"I've created a script at https://github.com/jwodder/zarr-digest-timings for timing different Zarr checksumming methods with different caching configurations.  In my initial tests (using large directory trees of small files), just using fscacher (both threaded \u0026 non-threaded) has had the worst effect on performance.  Please try out the script on any decent sample Zarrs you have.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645212089,"metadata":{"github-id":"IC_kwDODBZtRc4-Sj5b","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1045053019"},"message":"@yarikoptic @satra Following up on the above: My attempts to do the benchmarking on the Hub were thwarted because my sesssion kept disconnecting, so I spun up a $10/month DigitalOcean droplet and used that.  From timing on a directory tree of random data with a layout matching/based on `test128.ngff` (37480 files, five directory levels deep, with random sizes in the six digits), using five threads (the amount that `concurrent.futures` would use as the default `max_workers` on the droplet), I got the following times:\n\n|  | sync | fastio | oothreads | trio | recursive |\n| --- | --- | --- | --- | --- | --- |\n| No Caching | 171.871 | 61.8478 | 67.2708 |  101.9 | 154.549 |\n| Caching Files | 184.005 / 15.9847 | 94.5188 / 14.863 | 98.3243 / 16.5179 | — | 179.106 / 15.7787 |\n| Caching Directories (No Threads) | 159.681 / 10.9414 |  74.77 / 11.4389 | 80.3404 / 11.9911 | 114.492 / 11.0248 | 191.263 / 11.3294 |\n| Caching Directories (Threads) | 155.546 / 11.5107 | 73.7246 / 11.1678 | 83.5654 / 13.6311 | 115.265 / 11.9566 | 191.582 / 11.5187 |\n| Caching Both (No Threads) | 190.551 / 11.3605 | 110.705 / 11.221 | 122.877 / 11.8501 | — | 223.814 / 10.9694 |\n| Caching Both (Threads) | 195.624 / 11.7084 | 114.535 / 11.6021 | 119.309 / 12.6332 | — | 230.242 / 11.5458 |\n\n(Where caching was involved, two times are shown; the first is the runtime of the initial cache-populating call, and the second is the average runtime of subsequent calls.)\n\nObservations:\n\n* The fastest checksumming implementation is one based on the fastio/threaded walk code.\n* When Zarr checksumming is cached per directory, getting an already-cached value (for the directory tree in question) always takes about 11 seconds.\n* Whether fscacher is threaded or not doesn't seem to make much of an appreciable difference\n* When checksumming a directory for the first time with an empty cache, caching file digests almost always slows things down\n\nI also tried timing with 20 threads, but that ended up being a bit slower.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645223652,"metadata":{"github-id":"IC_kwDODBZtRc4-TcVu","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1045284206"},"message":"if you still have instance available, could you please also provide timing for that `/shared/io-utils/fastio_md5.py` present on the hub to give some kind of a reference timing I think we should strive to achieve (without caching)","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645223803,"metadata":{"github-id":"IC_kwDODBZtRc4-Tc7F","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1045286597"},"message":"@yarikoptic That's what the \"fastio\" column is (except it digests files piecemeal and also calculates a final Zarr checksum).","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645224036,"metadata":{"github-id":"UCE_lALODBZtRc4-Tc7FziEMiok"},"target":"394975e10fd805a60ab227e29517934c74e63e068cba9d0d3aabcf652705ec4d","message":"@yarikoptic That's what the \"fastio\" column is (except it digests files piecemeal and also calculates a final Zarr checksum).\n\n(But if you really want the exact time for that exact script on my sample tree on the droplet, it's 59.799s.)","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645224271,"metadata":{"github-id":"IC_kwDODBZtRc4-Te_4","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1045295096"},"message":"great -- thank you!","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645454843,"metadata":{"github-id":"IC_kwDODBZtRc4-Z0S5","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1046955193"},"message":"@yarikoptic Question: What's the plan for dealing with the fact that the upload code currently calculates the digest for a Zarr twice?  The first time, the digest is used to determine whether to upload the Zarr asset at all (based on `--existing`) and to populate the digest field in the asset metadata; the second time, it's used to check that the digest recorded in the metadata is still the same and that the server reports the correct value after upload.  I recall that this was discussed, but I don't recall a conclusion, and no issue was created.  Implementing this issue and #914 would be simpler if we could drop the first digestion.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645459215,"metadata":{"github-id":"IC_kwDODBZtRc4-aFgF","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1047025669"},"message":"Well, #915 (was not assigned) was my summary which is inline (I think) with your thinking above -- that the first digesting should be dropped (for now at least).","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645556928,"metadata":{"github-id":"IC_kwDODBZtRc4-eRL4","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1048122104"},"message":"- note from https://github.com/con/fscacher/pull/71#issuecomment-1045301808 -- timings on cached read improved from 11 sec to 0.3 sec with optimizations to fscacher.\n- `fastio` seems to be consistently and notably (up to 10%) outperforming OO version of `oothreads`, so I would prefer to go with `fastio`\n- I am a little disappointed that `Caching Directories` (in any form) adds a notable overhead (~20%) to be just enabled by default. But may be it is worth rerunning benchmarking (at least for fastio) with current fscacher to see that may be overhead also shrunk with recent changes?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645558493,"metadata":{"github-id":"IC_kwDODBZtRc4-eWSM","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1048142988"},"message":"@yarikoptic\n\n\u003e But may be it is worth rerunning benchmarking (at least for fastio) with current fscacher\n\nI already ran those benchmarks; you can see them [here](https://github.com/jwodder/zarr-digest-timings/tree/master/reports/digitalocean-s-1vcpu-2gb), in the rows labelled \"PR #71 (xor_bytes)\", and the relevant comparisons are [here](https://github.com/con/fscacher/pull/67#issuecomment-1047904352).","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645564102,"metadata":{"github-id":"IC_kwDODBZtRc4-ena1","github-url":"https://github.com/dandi/dandi-cli/issues/913#issuecomment-1048213173"},"message":"`zarr64-smallfiles` results are a bit confusing, but overall it seems to me that `PR #71, 5 threads` seems to provide not that much overhead (and somehow at times faster? eg in `zarr64-smallfiles, \"oothreads\" implementation`) than `baseline, 5 threads`, unless I am looking at those results wrong","files":null},{"type":5,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645627156,"metadata":{"github-id":"LE_lADODBZtRc5D-beqzwAAAAFtG_PJ"},"added":["zarr"],"removed":[]},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1645819120,"metadata":{"github-id":"CE_lADODBZtRc5D-beqzwAAAAFuD8Xw"},"status":2}]}