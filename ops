{"version":2,"ops":[{"type":1,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1741282808,"metadata":{"github-id":"I_kwDODBZtRc6s6lg4","github-url":"https://github.com/dandi/dandi-cli/issues/1585","origin":"github"},"title":"Refactor ProgressCombiner for zarrs to eliminate waste of CPU and reduce memory footprint","message":"Originally identified in\n- https://github.com/dandi/dandi-cli/issues/1581#issuecomment-2702564472\n\nthat\n\n```shell\n‚ùØ git grep -p 'def get_done'\ndandi/download.py=class ProgressCombiner:\ndandi/download.py:    def get_done(self) -\u003e dict:\n```\n\nwhich is\n\n```python\n    def get_done(self) -\u003e dict:\n        total_downloaded = sum(\n            s.downloaded\n            for s in self.files.values()\n            if s.state\n            in (\n                DLState.DOWNLOADING,\n                DLState.CHECKSUM_ERROR,\n                DLState.SKIPPED,\n                DLState.DONE,\n            ) \n        )\n        return {\n            \"done\": total_downloaded,\n            \"done%\": total_downloaded / self.zarr_size * 100 if self.zarr_size else 0,\n        }\n```\nso for any heavy in number of files zarr it keeps recounting upon download of every particular file, which is a waste of CPU.  Also there is growing memory consumption, potentially from collecting all the `.files` information.\n\nCode should be refactored to eliminate this loop and ideally to eliminate the store of the `files` statuses etc.  Could be just requiring an adjustment of corresponding counts upon some completion or skip of any particular file.","files":null}]}