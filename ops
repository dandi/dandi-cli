{"version":2,"ops":[{"type":1,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1625074186,"metadata":{"github-id":"MDU6SXNzdWU5MzM5MzgzODg=","github-url":"https://github.com/dandi/dandi-cli/issues/692","origin":"github"},"title":"centralize logic for file2asset(path, ds)","message":"ATM upload does\n```\n            yield {\"status\": \"extracting metadata\"}\n            try:\n                asset_metadata = nwb2asset(\n                    path, digest=file_etag, digest_type=\"dandi_etag\"\n                )\n            except Exception as exc:\n                lgr.exception(\"Failed to extract metadata from %s\", path)\n                if allow_any_path:\n                    yield {\"status\": \"failed to extract metadata\"}\n                    asset_metadata = get_default_metadata(\n                        path, digest=file_etag, digest_type=\"dandi_etag\"\n                    )\n                else:\n                    yield skip_file(\"failed to extract metadata: %s\" % str(exc))\n                    return\n            metadata = asset_metadata.json_dict()\n            metadata[\"path\"] = str(relpath)\n```\nso besides fall-back to `get_default_metadata` it adds a logic to convert to json_dict (could be omitted) but also fixes up the path to be relative to the dataset.  For the purpose of metadata migration/updates etc,  would be useful to centralize that logic so we do not need to (possibly incompletely) duplicate it within backups2datalad.py etc.\n\nCould be a helper function or a class method on Asset, e.g. `from_file` then (IIRC has idea about dandiset) may be even `ds` does not need to be provided","files":null}]}