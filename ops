{"version":2,"ops":[{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645917756,"metadata":{"github-id":"IC_kwDODBZtRc4-wBpY","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1052777048"},"message":"@bendichter \n\n\u003e I would have expected the program to automatically detect how many jobs are available.\n\nDetect what, exactly?  CPUs?  Cores?\n\n\u003e If you really want to hard-code 5, wouldn't it be easier to just do it in the function signature like:\n\nNo, doing it that way means that passing `None` would no longer default to 5.  `jobs=None` has to be handled inside the function body.\n\n\u003e A better option might be to use what is [now default for Python \u003e=3.8](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor): max_workers=min(32, os.cpu_count() + 4)\n\nNote that `iter_upload()` manages the upload of a single asset, and its `jobs` parameter is the number of concurrent upload threads for just that asset.  When uploading, there will be multiple assets uploaded in parallel, each with their own collection of threads, so setting the per-asset thread count to the \"max\" would mean multiple times that many threads.","files":null},{"type":3,"author":{"id":"f068089e26f6e2e30d51a62e75a77af7d9dc5ecb"},"timestamp":1645918668,"metadata":{"github-id":"IC_kwDODBZtRc4-wFm0","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1052793268"},"message":"@jwodder how many jobs are spun up for all across assets?","files":null},{"type":6,"author":{"id":"f068089e26f6e2e30d51a62e75a77af7d9dc5ecb"},"timestamp":1645918693,"metadata":{"github-id":"UCE_lALODBZtRc4-wFm0ziE7o80"},"target":"ce044b5406348115dc6f1b6e9c8fcce6ed130614c02ea28839d8829c2b180c46","message":"@jwodder how many jobs are spun up across all assets?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1645918942,"metadata":{"github-id":"IC_kwDODBZtRc4-wGtB","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1052797761"},"message":"@bendichter Well, [pyout is told to limit the number of assets uploaded at once](https://github.com/dandi/dandi-cli/blob/a1a7fd553cf300967adc060302c7e6f6c1b921c8/dandi/upload.py#L283-L285) to a value specified on the command line, defaulting to `concurrent.futures`'s current `max_workers` default, and then [dandi-cli itself also limits the number of concurrent assets to 10](https://github.com/dandi/dandi-cli/blob/a1a7fd553cf300967adc060302c7e6f6c1b921c8/dandi/upload.py#L289), and each asset upload gets one main thread and (by default) 5 upload threads.","files":null},{"type":3,"author":{"id":"f068089e26f6e2e30d51a62e75a77af7d9dc5ecb"},"timestamp":1645919516,"metadata":{"github-id":"IC_kwDODBZtRc4-wJN1","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1052808053"},"message":"OK so it looks like you do already use the logic I was suggesting for determining the number of parallel jobs. Then with a cap of 10? Why? Would it make sense to set the default to `max_workers=min(10, os.cpu_count() + 4)`?\nIt would be nice to have some indication of this in the cli help. As a user I would expect if no default behavior is described that only a single worker is used by default, which is clearly not the case.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647394610,"metadata":{"github-id":"IC_kwDODBZtRc4_si3_","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1068641791"},"message":"well, I guess I love magic too much.  That is why I like when tools do not need more options to be specified than necessary while performing efficiently. That is why we do parallelize by default and you can consider it to be an \"opt-out\" feature to go back to a single worker.","files":null},{"type":3,"author":{"id":"f068089e26f6e2e30d51a62e75a77af7d9dc5ecb"},"timestamp":1647441398,"metadata":{"github-id":"IC_kwDODBZtRc4_uq70","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069199092"},"message":"@yarikoptic yes, there is nothing wrong with parallelizing by default! I just want that do be documented.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647447710,"metadata":{"github-id":"IC_kwDODBZtRc4_vHda","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069315930"},"message":"\u003e @yarikoptic yes, there is nothing wrong with parallelizing by default! I just want that do be documented.\n\nagree with that. @jwodder - let's figure out how to achieve that without heavy docs duplication etc.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1647448221,"metadata":{"github-id":"IC_kwDODBZtRc4_vJmg","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069324704"},"message":"@yarikoptic So just document the default behavior of `dandi upload --jobs`?  To be honest, [as I described it above](https://github.com/dandi/dandi-cli/issues/927#issuecomment-1052797761), it doesn't make much sense; should the dandi-imposed limit of 10 be removed as well?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647451032,"metadata":{"github-id":"IC_kwDODBZtRc4_vVvc","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069374428"},"message":"If in case of limiting for pyout - `10`, IIRC it has specific use-case inspired meaning, since if we would have more active tasks than there is a number of visible on the screen rows, it would cause pyout be unable to provide \"consistent display\" while trying to update all the rows which aren't even visible on the screen.  I we strip it away, keeping default of a smart `None` thus making it default to `min(32, os.cpu_count() + 4).` - it might end up to being too many parallel uploads, causing stagnation etc. What if we just make it\n\n```\n  -J, --jobs N[:M]                Number of files to upload in parallel and,\n                                  optionally, number of upload threads per\n                                  file.  [default: 5:5]\n```\n(or `10:5`) and remove explicit limiting etc?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1647452292,"metadata":{"github-id":"IC_kwDODBZtRc4_vZJ9","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069388413"},"message":"@yarikoptic What are you referring to by \"explicit limiting etc\"?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647454213,"metadata":{"github-id":"IC_kwDODBZtRc4_vdcS","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069405970"},"message":"d'oh -- I have read `min` as `max` ;-) but the issue stands -- deciding on # of parallel uploads (IO) based on number of CPUs makes little sense since we are trying to avoid wasting on waiting for IO. Thus any dynamic settings for `None` probably makes not much sense.  Our goal should be to obtain some sensible performance by default. Uploading 5 files in parallel by default with 5 threads within each makes sense to me. Ideally of cause we should do some smarter \"sensing\" and scaling of number of jobs/threads based on file sizes and observed performance, and then document just that \"By default  dandi-cli scales number of jobs automagically\". While we do not have magic here -- let's \"hardcode\" to some sensible setting and just leave it for use to tune up. There will be no `min` or `max` on anything. And that is what I meant. WDYT?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1647454348,"metadata":{"github-id":"IC_kwDODBZtRc4_vdtl","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069407077"},"message":"@yarikoptic So just have `--jobs` default to a fixed number instead of using a default based on CPU count?  Sure.  What should that number be?","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647454417,"metadata":{"github-id":"IC_kwDODBZtRc4_vd20","github-url":"https://github.com/dandi/dandi-cli/issues/927#issuecomment-1069407668"},"message":"`5:5` -- 5 jobs with 5 threads per job","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1647878956,"metadata":{"github-id":"CE_lADODBZtRc5EsOpczwAAAAF2IcHR"},"status":2}]}