{"version":2,"ops":[{"type":6,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1644519938,"metadata":{"github-id":"UCE_lAHODBZtRc5DSyZQzim9S1g"},"target":"a3f9e5e462b898628e52915b209b9ab667565e2cb2fecc25ddf2f9043c8af308","message":".zarr folder could be large in size/number of files and require  substantial investment to compute (even once) before upload even starts to commence.\n\n### Some summary notes on current design\n\n- `blobs` \n  -  globally de-duplicated across dandisets based on their checksums\n- `zarr` files \n   - are not *intended* to  be de-duplicated ATM, so there is per se no API to get the one \"matching\"\n     - it is possible to go through checksums of `GET /zarr` records to find one 'matching' **but** those could mutate in place ATM, thus it must not be relied on\n     - eventually we must make some zarrs immutable for `publish`ing\n   -  current implementation always mints a new `zarr_id` (UUID) for any given `name`\n   - `name` provided by dandi-cli is just a file name (lacks path to it)\n   - on S3 `zarr_id` is used for \"prefix\", not the name, so we cannot conflict/modify existing zarr\n\n### Upload logic and checksumming\n\nOverall ATM `upload` relies on the computed digest to decide either a given asset (blob or zarr) is to be uploaded at all since we are getting information from the server/metadata first if an asset with the etag already exists.  **I think this logic is generally applicable/beneficial to both blobs and zarr folders e.g. in cases of copying/moving zarr folders within/across dandisets. But we might need to do some sacrifices in case of zarr, especially since we are not \"deduplicating\" them ATM.**\n\nIn detail, while going through upload code logic some notes/observations:\n- `C1`: Having an etag (unconditionally) computed, `upload` code then uses it in case of an asset already existing (in `overwrite` and `refresh` modes) at the path on either that upload/change to asset should be skipped entirely. So, in principle, \n   - **etag computation could be delayed until if needed -- an asset at the path exists, is of the same size and in case of zarr -- that zarr has the same number of files** (if different -- we know that it is different -- upload regardless of checksum match)\n- if we are to proceed with upload, \n  - for a blob we do need etag to initiate upload, we \"compute\" it again (fscached call of `get_dandietag`, so not really). server can return 409 (and a blob_id) if blob with that etag exists, and we produce an asset which uses that blob_id.  \n     - **so for blobs we cannot avoid not pre-computing etag but it also could be delayed until/if needed**\n  - for zarr upload \n    - `C2`: we do use full zarr checksum to error out if zarr checksum is different from the one ~~on server since ATM we do not support \"updates\"~~ computed before, i.e. that zarr did not mutate while we were at it.  \n      - ~~It seems there is no fscacher involved so~~ we do it 2nd time (in addition to `C1`) but fscacher cached results per each file in zarr, so some speed up might be there at the cost of many inodes!\n      - It is conditional on `dandi-zarr-checksum` already to be known to metadata (on server?) so checksumming could in principle be delayed (but shouldn't be done 2nd time if was done in C1) till this point, to similarly as in `C1` decide if we need to error out\n      - Q1: it is not clear to me (@jwodder?) why we would like to proceed with the upload if checksum is known and \"the same\" since how server would know full checksum unless we finished uploading entire zarr properly?\n    - We do not really need full zarr's checksum/digest to initiate upload . We do provide per file digests here.\n    - At the end (after the `/complete` for the last batch) we verify that locally known checksum is identical to the one on server\n    - If checksum identical -- we create an asset, if not -- we error out\n    - **Let's sacrifice the check of checksum at `C1` for zarr, always `iter_upload`ing even if there is a zarr asset at the path already. Then we can avoid doing expensive \"digesting\".  `upload` logic will guard against uploading unless \"overwrite\" or \"refresh\" mode are specified**\n\n### Solution `#1`: avoid pre-checksumming of zarr files\n\n- `C1` should completely avoid checksumming of zarr archives \n- proceed to upload in \"overwrite\" unconditionally (no checksum for zarr),\n- and in \"refresh\" only if newer (but again - no checksum)\n- remove `C2` safeguard for zarrs, \n- compute zarr checksum  \"in-band\" while uploading \n- verify correctness of the upload based on that.  UX will be\n\n@jwodder - is my analysis correct above (note `Q1` question) or what other aspects am I missing, and either needed changes/developments make sense to avoid zarr checksum compute before upload?\n\n### Solution `#2`: do not make \"zarr\" too special, just speed things up\n\nIn principle, if checksumming of entire directories is made more efficient and fscaching of them more efficient (https://github.com/con/fscacher/issues/66) , I do not see how checksumming of 'zarr' directory of e.g. X GB is performance-wise different from checksumming of a blob of the same X GB, and we do/require it.  Above \"avoidance\" of checksumming zarr directories prior upload makes them \"special\", but may be  not for so good reason -- in principle we already can make them \"deduplicated\" quite easily and may be could eventually add some flag \"immutable: bool\" which would be set to `True` whenever full upload is finalized, thus letting them to be immutable forever (API should the refuse to modify an immutable zarr_id) -- needed for publishing anyways.  May be we should just keep that digesting, speed it up/fscache the result, and add API to dandi-archive to get a zarr given a checksum (as how we do for blobs)?  \nAlso in some cases pre-checksumming of zarrs could be avoided, e.g. if know that it is different (based on size, number of files) so we could instead optimize logic of upload to delay checksumming until really needed.\n\nWDYT @satra ?  Also\n\n- I do not think there is much of a point to provide any longer \"name\" (e.g. include folder from the top of the dataset) or demand `dandiset_id` field for the point of this particular issue.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644439417,"metadata":{"github-id":"IC_kwDODBZtRc49pECU","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1034174612"},"message":"@yarikoptic Is `C2` referring to this code?\n\nhttps://github.com/dandi/dandi-cli/blob/49e33afbb1eb294b7183d6c88a0fb0e75fa234ca/dandi/files.py#L790-L793\n\n`metadata` is here the metadata for the asset that's about to be uploaded, not the metadata for a pre-existing asset on the server.","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644439495,"metadata":{"github-id":"UCE_lALODBZtRc49pECUziDJhVE"},"target":"6b5a588add150aacd41debfe40f372a2dd7af3f41d2d2cf20199d3afb0eff831","message":"@yarikoptic Is `C2` referring to this code?\n\nhttps://github.com/dandi/dandi-cli/blob/49e33afbb1eb294b7183d6c88a0fb0e75fa234ca/dandi/files.py#L790-L793\n\n`metadata` is here the metadata for the asset that's about to be uploaded, not the metadata for a pre-existing asset on the server.\n\n\u003e It seems there is no fscacher involved so we do it 2nd time (in addition to C1)!\n\nWhile the digest for the Zarr as a whole is not cached, the digests for the individual files are computed via fscacher.","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644439520,"metadata":{"github-id":"UCE_lALODBZtRc49pECUziDJheM"},"target":"6b5a588add150aacd41debfe40f372a2dd7af3f41d2d2cf20199d3afb0eff831","message":"@yarikoptic Is `C2` referring to this code?\n\nhttps://github.com/dandi/dandi-cli/blob/49e33afbb1eb294b7183d6c88a0fb0e75fa234ca/dandi/files.py#L790-L793\n\n`metadata` is here the metadata for the asset that's about to be uploaded, not the metadata for a pre-existing asset on the server.\n\n\u003e It seems there is no fscacher involved so we do it 2nd time (in addition to C1)!\n\nWhile the digest for the Zarr as a whole is not cached, the digests for the individual files are cached via fscacher.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1644442340,"metadata":{"github-id":"IC_kwDODBZtRc49pNEz","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1034211635"},"message":"\u003e `metadata` is here the metadata for the asset that's about to be uploaded, not the metadata for a pre-existing asset on the server.\n\noh -- so it is just to check if file (well -- directory) was not modified since the time we \"looked\" at it  to get the digest in metadata, right?  So may be we should sacrifice that, and instead compare to the final checksum (after confirming that server has the same) and if mismatch just issue a warning (would be lame to completely discard the upload of possibly many GBs).\n\n\u003e \u003e It seems there is no fscacher involved so we do it 2nd time (in addition to C1)!\n\u003e \n\u003e While the digest for the Zarr as a whole is not cached, the digests for the individual files are cached via fscacher.\n\nah, good to know. But I think that in longer term we should fscache the state/checksum of the entire zarr, since caching individual files of zarr might actually be not really a benefit since would be coming with high cost of the cache needing thousands of individual records (inodes), whenever modifications within zarr of individual files are rare/non-existent, and thus fscaching individual files generally would be \"too costly\". WDYT?","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644442613,"metadata":{"github-id":"IC_kwDODBZtRc49pN5w","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1034215024"},"message":"@yarikoptic If we don't cache any of the digests for the files in a Zarr, then whenever a single file in a Zarr is changed, we would have to redigest every file again.","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644442658,"metadata":{"github-id":"UCE_lALODBZtRc49pN5wziDJ4W4"},"target":"734a214097fdffc72886cddb2f9466c5f8b77680c79b12764976adb18ce56b42","message":"@yarikoptic If we don't cache any of the digests for the files in a Zarr, then whenever a single file in a Zarr is changed, we would have to redigest every file again.\n\n\u003e oh -- so it is just to check if file (well -- directory) was not modified since the time we \"looked\" at it to get the digest in metadata, right?\n\nCorrect.","files":null},{"type":6,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1644442672,"metadata":{"github-id":"UCE_lALODBZtRc49pN5wziDJ4cY"},"target":"734a214097fdffc72886cddb2f9466c5f8b77680c79b12764976adb18ce56b42","message":"@yarikoptic If we don't cache any of the digests for the files in a Zarr, then whenever a single file in a Zarr is changed, we would have to redigest every file again.\n\n\u003e oh -- so it is just to check if file (well -- directory) was not modified since the time we \"looked\" at it to get the digest in metadata, right?\n\nCorrect.  We do the same thing for blobs.","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1644445580,"metadata":{"github-id":"IC_kwDODBZtRc49pZFX","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1034260823"},"message":"i'll \"digest\" the rest of the post later, but on the caching issue, i think there should be a single tree-cache in a datastructure stored in a binary file that's efficiently edited when files change (added/deleted). could be something as simple as an sqlite record. \n\nstoring each file's checksum is indeed an inode catastrophe on most filesystems. i'm sure there are solutions out there, and it seems this will also be similar to the API server. however, s3 itself doesn't have any inode limits.","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658932703,"metadata":{"github-id":"IC_kwDODBZtRc5HVnF9","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1196847485"},"message":"@yarikoptic Can this be considered resolved by #915 and #923?","files":null},{"type":5,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658933899,"metadata":{"github-id":"LE_lADODBZtRc5DSyZQzwAAAAGloXAB"},"added":["cmd-upload"],"removed":[]},{"type":5,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1658933899,"metadata":{"github-id":"LE_lADODBZtRc5DSyZQzwAAAAGloXAF"},"added":["zarr"],"removed":[]},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1704303378,"metadata":{"github-id":"IC_kwDODBZtRc5vzV4S","github-url":"https://github.com/dandi/dandi-cli/issues/903#issuecomment-1875729938"},"message":"let's consider resolved indeed for that moment","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1704303378,"metadata":{"github-id":"CE_lADODBZtRc5DSyZQzwAAAAKmZco-"},"status":2}]}