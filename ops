{"version":2,"ops":[{"type":3,"author":{"id":"e44473dfc8f95f5a722344097ba2b4fe3f83cc03"},"timestamp":1645216907,"metadata":{"github-id":"IC_kwDODBZtRc4-S8nM","github-url":"https://github.com/dandi/dandi-cli/issues/917#issuecomment-1045154252"},"message":"In https://github.com/NeurodataWithoutBorders/pynwb/pull/1432 I've extracted the code to determine the extension namespace from the file to a separate function `` pynwb.validate.get_chached_namespaces_to_validate`` so that the code can be reused to validate against cached namespaces when calling ``pynwb.validate`` directly from Python, rather than the command line. The code example below illustrates how you could fix this quickly in DANDI. Once PyNWB has been released you would then remove the ``get_chached_namespaces_to_validate`` from DANDI and simply replace it with the import from PyNWB ``from pynwb.validate import get_chached_namespaces_to_validate``. \n\n```\nfrom pynwb import validate, NWBHDF5IO\n\ndef get_chached_namespaces_to_validate(path):\n   \"\"\"\n   Determine the most specific namespace(s) (i.e., extensions) that are chached in the given\n   NWB file that should be used for validation.\n\n   :param path: Path for the NWB file\n   :return: Tuple with:\n     - List of strings with the most specific namespace(s) to use for validation.\n     - BuildManager object for opening the file for validation\n     - Dict with the full result from NWBHDF5IO.load_namespaces\n   \"\"\"\n   # Importing locally here so we can easily switch to using pynwb.validate.get_chached_namespaces_to_validate\n   # once it is part of the release\n   from hdmf.spec import NamespaceCatalog\n   from hdmf.build import BuildManager\n   from pynwb.spec import NWBDatasetSpec, NWBGroupSpec, NWBNamespace\n   from hdmf.build import TypeMap as TypeMap\n\n   catalog = NamespaceCatalog(NWBGroupSpec, NWBDatasetSpec, NWBNamespace)\n   ns_deps = NWBHDF5IO.load_namespaces(catalog, path)\n   s = set(ns_deps.keys())  # determine which namespaces are the most\n   for k in ns_deps:  # specific (i.e. extensions) and validate\n      s -= ns_deps[k].keys()  # against those\n   # TODO remove this workaround for issue https://github.com/NeurodataWithoutBorders/pynwb/issues/1357\n   if 'hdmf-experimental' in s:\n      s.remove('hdmf-experimental')  # remove validation of hdmf-experimental for now\n   namespaces = list(sorted(s))\n\n   if len(namespaces) \u003e 0:\n      tm = TypeMap(catalog)\n      manager = BuildManager(tm)\n   else:\n      manager = None\n\n   return namespaces, manager, ns_deps\n\n\nif __name__ == '__main__':\n   path = \"001_140709EXP_A1.nwb\"\n   validate_namespaces, manager, chached_namespaces = get_chached_namespaces_to_validate(path)\n   with NWBHDF5IO(path, \"r\", manager=manager) as reader:\n      errors = []\n      for ns in validate_namespaces:\n         errors += validate(io=reader, namespace=ns)\n      print(\"%i errors found\" % len(errors))\n\n\n```","files":null},{"type":3,"author":{"id":"d6410394bf8099fbcfa4e89f02cf578464b468f2"},"timestamp":1656521863,"metadata":{"github-id":"IC_kwDODBZtRc5FwHD8","github-url":"https://github.com/dandi/dandi-cli/issues/917#issuecomment-1170239740"},"message":"I'm getting related errors also, would be great to get this fix integrated!","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1656540418,"metadata":{"github-id":"IC_kwDODBZtRc5FxQ0m","github-url":"https://github.com/dandi/dandi-cli/issues/917#issuecomment-1170541862"},"message":"Since https://github.com/NeurodataWithoutBorders/pynwb/pull/1432 is not yet merged\u0026released yet, I guess we are doomed to introduce this into dandi-cli. Submitted #1036 for our consideration ;)","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1668192959,"metadata":{"github-id":"CE_lADODBZtRc5EE2a_zwAAAAHQlMh2"},"status":2}]}