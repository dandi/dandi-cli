{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1725561544,"metadata":{"github-id":"IC_kwDODBZtRc6LBaTk","github-url":"https://github.com/dandi/dandi-cli/issues/1494#issuecomment-2332402916"},"message":"so you are saying that with the new 3.14.4 something what worked before starts to fail? sounds like a possible regression in HDMF ... and indeed our CI is full of red Test fails since awhile, but largely masked by facts that I was aware of some other services running Red and thus ignoring... ok, time to look into it!  That test started to fail in 08 on 22nd and on dev-deps which install development versions of hdmf and pynwb (and keyring and nwbinspector) at https://github.com/dandi/dandi-cli/blob/master/.github/workflows/test.yml#L71\n\n```\ndandi@drogon:/mnt/backup/dandi/tinuous-logs/dandi-cli/2024/08$ git grep 'test_ambiguous FAIL' | cat\n22/github/cron/20240822T060345/44e097f/Tests/5792/16_test (ubuntu-latest, 3.8, dev-deps).txt:2024-08-22T06:22:42.4039246Z dandi/tests/test_organize.py::test_ambiguous FAILED\n22/github/cron/20240822T060345/44e097f/Tests/5792/test (ubuntu-latest, 3.8, dev-deps)/8_Run all tests.txt:2024-08-22T06:22:42.4039201Z dandi/tests/test_organize.py::test_ambiguous FAILED\n```\nfirst non-dev deps fail happened on Sep 05 \n```\ndandi@drogon:/mnt/backup/dandi/tinuous-logs/dandi-cli/2024/09$ git grep 'test_ambiguous FAIL' | grep -v dev-deps\n05/github/cron/20240905T060358/44e097f/Tests/5806/0_test (windows-2019, 3.8, normal).txt:2024-09-05T06:12:38.5921668Z dandi/tests/test_organize.py::test_ambiguous FAILED\n05/github/cron/20240905T060358/44e097f/Tests/5806/10_test (macos-latest, 3.8, normal).txt:2024-09-05T06:10:45.2083220Z dandi/tests/test_organize.py::test_ambiguous FAILED\n```\nwith hdmf\n```\ndandi@drogon:/mnt/backup/dandi/tinuous-logs/dandi-cli/2024/09$ grep 'hdmf' 05/github/cron/20240905T060358/44e097f/Tests/5806/10_test\\ \\(macos-latest\\,\\ 3.8\\,\\ normal\\).txt \n2024-09-05T06:06:55.3316630Z Collecting hdmf!=3.5.0 (from dandi==0.63.0+11.g44e097f9)\n2024-09-05T06:06:55.3363050Z   Downloading hdmf-3.14.4-py3-none-any.whl.metadata (8.8 kB)\n```\nwhenever prior day had\n```\ndandi@drogon:/mnt/backup/dandi/tinuous-logs/dandi-cli/2024/09$ grep 'hdmf' 04/github/cron/*/*/Tests/*/10_test\\ \\(macos-latest\\,\\ 3.8\\,\\ normal\\).txt \n2024-09-04T06:06:43.3920200Z Collecting hdmf!=3.5.0 (from dandi==0.63.0+11.g44e097f9)\n2024-09-04T06:06:43.3957280Z   Downloading hdmf-3.14.3-py3-none-any.whl.metadata (8.8 kB)\n```\nso indeed hdmf release of changes from around aug 22 seems to blame ;)  \n\n\u003cdetails\u003e\n\u003csummary\u003eso it is likely of those 3 changes\u003c/summary\u003e \n\n```shell\ncommit e0bedca13f167d55a4be5657044c4c6697de95ca\nAuthor: Matthew Avaylon \u003cavaylonmatthew@gmail.com\u003e\nDate:   Thu Aug 22 08:45:29 2024 -0700\n\n    Append a Dataset of References (#1135)\n\ncommit acc3d78cc5a828ddd384cca814ef60167ae92682\nAuthor: Steph Prince \u003c40640337+stephprince@users.noreply.github.com\u003e\nDate:   Wed Aug 21 22:14:24 2024 -0700\n\n    Write scalar datasets with compound data type (#1176)\n    \n    * add support for scalar compound datasets\n    \n    * add scalar compound dset io and validation tests\n    \n    * update CHANGELOG.md\n    \n    * Update tests/unit/test_io_hdf5_h5tools.py\n    \n    Co-authored-by: Ryan Ly \u003crly@lbl.gov\u003e\n    \n    * update container repr conditionals\n    \n    ---------\n    \n    Co-authored-by: Ryan Ly \u003crly@lbl.gov\u003e\n\ncommit 2b167aedc8a8f58afd75d3d0c750f6d620dc663d\nAuthor: Steph Prince \u003c40640337+stephprince@users.noreply.github.com\u003e\nDate:   Wed Aug 21 13:48:42 2024 -0700\n\n    Add support to write multidimensional string arrays (#1173)\n    \n    * add condition for multidim string arrays\n    \n    * add tests for multidim string array build\n    \n    * update condition when defining hdf5 dataset shape\n    \n    * add test to write multidim string array\n    \n    * update CHANGELOG.md\n    \n    * fix text decoding in test\n    \n    * add recursive string type for arrays of arbitrary dim\n    \n    * add test for compound data type with strings\n    \n    * add tests for multidim str attributes\n    \n    * fix line lengths\n    \n    * [pre-commit.ci] auto fixes from pre-commit.com hooks\n    \n    for more information, see https://pre-commit.ci\n    \n    * update compound dtype test\n    \n    ---------\n    \n    Co-authored-by: pre-commit-ci[bot] \u003c66853113+pre-commit-ci[bot]@users.noreply.github.com\u003e\n    Co-authored-by: Ryan Ly \u003crly@lbl.gov\u003e\n\n```\n\u003c/details\u003e\n\nsince not clear what it is -- now will look into actual test fail and see if can point more specifically the effect","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1725561733,"metadata":{"github-id":"IC_kwDODBZtRc6LBbh7","github-url":"https://github.com/dandi/dandi-cli/issues/1494#issuecomment-2332407931"},"message":"bisected to https://github.com/hdmf-dev/hdmf/commit/2b167aedc8a8f58afd75d3d0c750f6d620dc663d","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1725563390,"metadata":{"github-id":"IC_kwDODBZtRc6LBmol","github-url":"https://github.com/dandi/dandi-cli/issues/1494#issuecomment-2332453413"},"message":"it is about \n```\n2024-09-05 14:44:24,500 [ WARNING] Completely empty record for /home/yoh/.tmp/pytest-of-yoh/pytest-786/test_ambiguous0/simple2.nwb\n```\nand related to creation of that file, not loading etc...  And since it complained only about that one, and not the other one -- it is about us \"copying\" an nwb via  NWBHDF5IO in https://github.com/dandi/dandi-cli/blob/HEAD/dandi/pynwb_utils.py#L494 .\n\n```python\n    with pynwb.NWBHDF5IO(src, \"r\") as ior, pynwb.NWBHDF5IO(dest, \"w\") as iow:\n        data = ior.read()\n        data.generate_new_id()\n        iow.export(ior, nwbfile=data)\n```\n\nas a result of that commit, we are getting a new file...\n\nand it as 12 more of lines in the diff between diffs of h5dump between original and \"copied\":\n\n```\n--- /tmp/diff-good\t2024-09-05 14:58:33.994177871 -0400\n+++ /tmp/diff-bad\t2024-09-05 14:58:28.530140108 -0400\n@@ -1,8 +1,8 @@\n---- /home/yoh/.tmp/pytest-of-yoh/pytest-787/simple20/simple2.dump\t2024-09-05 14:52:36.671721691 -0400\n-+++ /home/yoh/.tmp/pytest-of-yoh/pytest-787/test_ambiguous0/simple2.dump\t2024-09-05 14:52:48.967804648 -0400\n+--- /home/yoh/.tmp/pytest-of-yoh/pytest-785/simple20/simple2.dump\t2024-09-05 14:57:09.189592043 -0400\n++++ /home/yoh/.tmp/pytest-of-yoh/pytest-785/test_ambiguous0/simple2.dump\t2024-09-05 14:56:55.105494805 -0400\n @@ -1,5 +1,14 @@\n--HDF5 \"/home/yoh/.tmp/pytest-of-yoh/pytest-787/simple20/simple2.nwb\" {\n-+HDF5 \"/home/yoh/.tmp/pytest-of-yoh/pytest-787/test_ambiguous0/simple2.nwb\" {\n+-HDF5 \"/home/yoh/.tmp/pytest-of-yoh/pytest-785/simple20/simple2.nwb\" {\n++HDF5 \"/home/yoh/.tmp/pytest-of-yoh/pytest-785/test_ambiguous0/simple2.nwb\" {\n  GROUP \"/\" {\n +   ATTRIBUTE \".specloc\" {\n +      DATATYPE  H5T_REFERENCE { H5T_STD_REF_OBJECT }\n@@ -20,17 +20,29 @@\n        }\n        DATASPACE  SCALAR\n        DATA {\n--      (0): \"8e7035b9-1bcf-4cf2-a54a-1fe81350dc21\"\n-+      (0): \"156cfbc4-e3c9-4e01-9a68-8d2e36dbf9a1\"\n+-      (0): \"d5c1f483-a32e-4da3-9eac-578581e5628a\"\n++      (0): \"fb7e80c0-bd56-4c99-9266-3c3b63e479c2\"\n        }\n     }\n     GROUP \"acquisition\" {\n+@@ -108,9 +117,9 @@\n+             CSET H5T_CSET_UTF8;\n+             CTYPE H5T_C_S1;\n+          }\n+-         DATASPACE  SIMPLE { ( 2 ) / ( 2 ) }\n++         DATASPACE  SCALAR\n+          DATA {\n+-         (0): \"keyword1\", \"keyword 2\"\n++         (0): \"\u003cStrDataset for HDF5 dataset \"keywords\": shape (2,), type \"|O\"\u003e\"\n+          }\n+       }\n+       DATASET \"lab\" {\n @@ -183,7 +192,7 @@\n              }\n              DATASPACE  SCALAR\n              DATA {\n--            (0): \"695e6d7d-c000-4a9e-bf89-a86a8fa55daf\"\n-+            (0): \"15aa5c61-0cf1-462e-9a2e-6ce7f96afebe\"\n+-            (0): \"02854e20-0941-4078-9151-cfc27c312d9f\"\n++            (0): \"ff22df57-a0e5-46c2-8b60-9c25f19ce818\"\n              }\n           }\n           DATASET \"date_of_birth\" {\n```\n\nand that \n\n```shell\n‚ùØ grep StrDataset /home/yoh/.tmp/pytest-of-yoh/pytest-785/simple20/simple2.dump /home/yoh/.tmp/pytest-of-yoh/pytest-785/test_ambiguous0/simple2.dump\n/home/yoh/.tmp/pytest-of-yoh/pytest-785/test_ambiguous0/simple2.dump:         (0): \"\u003cStrDataset for HDF5 dataset \"keywords\": shape (2,), type \"|O\"\u003e\"\n```\n\nis quite a unique \"thing\" to be used at all present only in the \"copy\" of the file. ...\n\n\nand damn -- we are managing to hide away such an error message/exception from the user even at debug level somehow, but there is a problem with HDMF being unable to load such a file\n\n```\n(Pdb) p get_metadata(paths[0])\n2024-09-05 15:05:22,983 [   DEBUG] Creating converter from 3 to 5\n2024-09-05 15:05:23,032 [   DEBUG]         Calling override function for constructor argument 'age__reference'\n2024-09-05 15:05:23,032 [   DEBUG]         Calling override function for constructor argument 'date_of_birth'\n2024-09-05 15:05:23,044 [   DEBUG]         Calling override function for constructor argument 'session_start_time'\n2024-09-05 15:05:23,044 [   DEBUG]         Calling override function for constructor argument 'file_create_date'\n2024-09-05 15:05:23,045 [   DEBUG]         Calling override function for constructor argument 'timestamps_reference_time'\n2024-09-05 15:05:23,045 [   DEBUG]         Calling override function for constructor argument 'experimenter'\n2024-09-05 15:05:23,045 [   DEBUG]         Calling override function for constructor argument 'related_publications'\n2024-09-05 15:05:23,045 [   DEBUG]         Calling override function for constructor argument 'scratch'\n*** hdmf.build.errors.ConstructError: (root GroupBuilder {'attributes': {'namespace': 'core', 'neurodata_type': 'NWBFile', 'nwb_version': '2.7.0', 'object_id': 'd5e51f36-ccf4-4a5d-bfe9-0cfe2200332f'}, 'groups': {'acquisition': root/acquisition GroupBuilder {'attributes': {}, 'groups': {}, 'datasets': {}, 'links': {}}, 'analysis': root/analysis GroupBuilder {'attributes': {}, 'groups': {}, 'datasets': {}, 'links': {}}, 'general': root/general GroupBuilder {'attributes': {}, 'groups': {'subject': root/general/subject GroupBuilder {'attributes': {'namespace': 'core', 'neurodata_type': 'Subject', 'object_id': 'ad534e99-07d7-4a45-86ed-21510c5d4f1c'}, 'groups': {}, 'datasets': {'date_of_birth': root/general/subject/date_of_birth DatasetBuilder {'attributes': {}, 'data': '2016-12-01T00:00:00+00:00'}, 'sex': root/general/subject/sex DatasetBuilder {'attributes': {}, 'data': 'U'}, 'species': root/general/subject/species DatasetBuilder {'attributes': {}, 'data': 'Mus musculus'}, 'subject_id': root/general/subject/subject_id DatasetBuilder {'attributes': {}, 'data': 'mouse001'}}, 'links': {}}}, 'datasets': {'experiment_description': root/general/experiment_description DatasetBuilder {'attributes': {}, 'data': 'experiment_description1'}, 'experimenter': root/general/experimenter DatasetBuilder {'attributes': {}, 'data': \u003cStrDataset for Closed HDF5 dataset\u003e}, 'institution': root/general/institution DatasetBuilder {'attributes': {}, 'data': 'institution1'}, 'keywords': root/general/keywords DatasetBuilder {'attributes': {}, 'data': '\u003cStrDataset for HDF5 dataset \"keywords\": shape (2,), type \"|O\"\u003e'}, 'lab': root/general/lab DatasetBuilder {'attributes': {}, 'data': 'lab1'}, 'related_publications': root/general/related_publications DatasetBuilder {'attributes': {}, 'data': \u003cStrDataset for Closed HDF5 dataset\u003e}, 'session_id': root/general/session_id DatasetBuilder {'attributes': {}, 'data': 'session_id1'}}, 'links': {}}, 'processing': root/processing GroupBuilder {'attributes': {}, 'groups': {}, 'datasets': {}, 'links': {}}, 'stimulus': root/stimulus GroupBuilder {'attributes': {}, 'groups': {'presentation': root/stimulus/presentation GroupBuilder {'attributes': {}, 'groups': {}, 'datasets': {}, 'links': {}}, 'templates': root/stimulus/templates GroupBuilder {'attributes': {}, 'groups': {}, 'datasets': {}, 'links': {}}}, 'datasets': {}, 'links': {}}}, 'datasets': {'file_create_date': root/file_create_date DatasetBuilder {'attributes': {}, 'data': \u003cClosed HDF5 dataset\u003e}, 'identifier': root/identifier DatasetBuilder {'attributes': {}, 'data': '43eb6df40f18426ab60ffea2ea05a4c8'}, 'session_description': root/session_description DatasetBuilder {'attributes': {}, 'data': 'session_description1'}, 'session_start_time': root/session_start_time DatasetBuilder {'attributes': {}, 'data': '2017-04-15T12:00:00+00:00'}, 'timestamps_reference_time': root/timestamps_reference_time DatasetBuilder {'attributes': {}, 'data': '2017-04-15T12:00:00+00:00'}}, 'links': {}}, \"Could not construct NWBFile object due to: NWBFile.__init__: incorrect type for 'keywords' (got 'str', expected 'ndarray, list, tuple, Dataset, Array, StrDataset, HDMFDataset or AbstractDataChunkIterator')\")\n```\n\nI will for now declare this version of hdmf buggy for dandi-cli and file and issue with HDMF.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1725564693,"metadata":{"github-id":"IC_kwDODBZtRc6LBvAS","github-url":"https://github.com/dandi/dandi-cli/issues/1494#issuecomment-2332487698"},"message":"Issues filed:\n- https://github.com/hdmf-dev/hdmf/issues/1186\n- https://github.com/hdmf-dev/hdmf/issues/1187","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1725905657,"metadata":{"github-id":"CE_lADODBZtRc6VgDK4zwAAAANNpeCf"},"status":2},{"type":3,"author":{"id":"7a8552494914d3e4116f4b434eb4812a914ca405"},"timestamp":1725905720,"metadata":{"github-id":"IC_kwDODBZtRc6LZwlg","github-url":"https://github.com/dandi/dandi-cli/issues/1494#issuecomment-2338785632"},"message":"\u003c!-- GITHUB_RELEASE COMMENT: released --\u003e\n:rocket: Issue was released in [`0.63.1`](https://github.com/dandi/dandi-cli/releases/tag/0.63.1) :rocket:","files":null},{"type":5,"author":{"id":"7a8552494914d3e4116f4b434eb4812a914ca405"},"timestamp":1725905720,"metadata":{"github-id":"LE_lADODBZtRc6VgDK4zwAAAANNphTy"},"added":["released"],"removed":[]}]}