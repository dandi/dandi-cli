{"version":2,"ops":[{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1626462351,"metadata":{"github-id":"IC_kwDODBZtRc40jQQo","github-url":"https://github.com/dandi/dandi-cli/issues/714#issuecomment-881656872"},"message":"what do you mean \"waiting for longer\"?  \nif I get it right -- we just send a PUT request  for that fragment and analyze the returncode... I guess the \"low level\" code we have is at https://github.com/dandi/dandi-cli/blob/master/dandi/dandiapi.py#L123 :\n\n```python\n        # urllib3's ConnectionPool isn't thread-safe, so we sometimes hit\n        # ConnectionErrors on the start of an upload.  Retry when this happens.\n        # Cf. \u003chttps://github.com/urllib3/urllib3/issues/951\u003e.\n        doretry = tenacity.retry_if_exception_type(\n            requests.ConnectionError\n        ) | tenacity.retry_if_result(lambda r: r.status_code == 503)\n        if retry is not None:\n            doretry |= retry\n\n        try:\n            result = try_multiple(5, doretry, 1.1)(\n                f,\n                url,\n                params=params,\n                data=data,\n                files=files,\n                json=json,\n                headers=headers,\n                **kwargs,\n            )\n        except Exception:\n            lgr.exception(\"HTTP connection failed\")\n            raise\n```\n\nbut may be we somehow stepping into that thread-unsafe invocation and need to establish one of the workarounds for that?\n\nattn @jwodder","files":null},{"type":3,"author":{"id":"12cb25e6e3f19b53447b05d00d7d4d53c925c908"},"timestamp":1626462796,"metadata":{"github-id":"IC_kwDODBZtRc40jRP2","github-url":"https://github.com/dandi/dandi-cli/issues/714#issuecomment-881660918"},"message":"i think i'm simply asking to change either 5 or 1.1 or both to allow for a longer retry period up to a minute. the current set of retries only waits up to a 10s at most i think.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1626464529,"metadata":{"github-id":"IC_kwDODBZtRc40jVFA","github-url":"https://github.com/dandi/dandi-cli/issues/714#issuecomment-881676608"},"message":"ah, gotcha.  @jwodder - any objections and what would be your favorite combination to make it wait up to a minute or so?  unlikely we need to propagate it all the way to become configurable, so I guess we just need to make the curve more \"exponential\" and may be try a few more times ;-)","files":null},{"type":3,"author":{"id":"364914f8b1c8a9131d300bf2978e4ffe2ff1aeeb"},"timestamp":1626464807,"metadata":{"github-id":"IC_kwDODBZtRc40jVmx","github-url":"https://github.com/dandi/dandi-cli/issues/714#issuecomment-881678769"},"message":"@yarikoptic No objections.  Fiddling with the numbers a bit, I find `ntrials=12`, `base=1.25`, which gives a total wait time of 67.76 seconds and a maximum wait between requests of 14.56 seconds.","files":null},{"type":3,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1626472450,"metadata":{"github-id":"IC_kwDODBZtRc40jkQF","github-url":"https://github.com/dandi/dandi-cli/issues/714#issuecomment-881738757"},"message":"I wonder if in the long run we should even make `requests.ConnectionError` (\"cats chew through the wire, need time to run to store and get a replacement\") special and allow for those to take nearly whatever it takes to reestablish the connection and get some sensible error or to proceed.  That is what I kinda liked about Globus -- just leave it running and it will eventually succeed, while taking care about all reconnections etc.","files":null},{"type":4,"author":{"id":"34bb3b7763ea6d04cae1c21ede40209df34305b5"},"timestamp":1626802705,"metadata":{"github-id":"MDExOkNsb3NlZEV2ZW50NTA0NTY5NzIwMg=="},"status":2}]}