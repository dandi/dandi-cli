#!/usr/bin/env python
"""
Update a Zotero collection with bibliography entries from a BibTeX file.

This script will:
- Parse a BibTeX file (e.g., dandi.bib)
- Connect to Zotero using the API
- Find existing items in the specified collection by DOI
- Update existing items if metadata has changed
- Add new items that don't exist yet
- Avoid creating duplicates

Usage:
    ./update-zotero-collection --api-key YOUR_API_KEY --group-id 5774211 \
        --collection-key T8I34DL3 --bibfile dandi.bib

Requirements:
    - pyzotero: pip install pyzotero
    - bibtexparser: pip install bibtexparser
"""

import argparse
import logging
import sys
from typing import Dict, List

import bibtexparser
from pyzotero import zotero

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    stream=sys.stderr,
)

lgr = logging.getLogger(__name__)


def parse_bibtex_file(bibfile: str) -> List[Dict]:
    """Parse a BibTeX file and return list of entries."""
    lgr.info(f"Parsing BibTeX file: {bibfile}")
    with open(bibfile, "r", encoding="utf-8") as f:
        bib_database = bibtexparser.load(f)
    lgr.info(f"Found {len(bib_database.entries)} entries in BibTeX file")
    return bib_database.entries


def bibtex_to_zotero_item(entry: Dict) -> Dict:
    """Convert a BibTeX entry to Zotero item format."""
    # Map BibTeX entry types to Zotero item types
    type_mapping = {
        "article": "journalArticle",
        "book": "book",
        "inproceedings": "conferencePaper",
        "misc": "webpage",  # DANDI uses @misc for datasets
        "phdthesis": "thesis",
        "techreport": "report",
    }

    entry_type = entry.get("ENTRYTYPE", "misc").lower()
    zotero_type = type_mapping.get(entry_type, "webpage")

    # Build the Zotero item
    item = {
        "itemType": zotero_type,
        "title": entry.get("title", ""),
        "url": entry.get("url", ""),
        "date": entry.get("year", ""),
        "extra": "",  # We'll add additional fields here
    }

    # Extract DOI
    doi = entry.get("doi", "")
    if doi:
        item["DOI"] = doi
        item["extra"] += f"DOI: {doi}\n"

    # Extract authors
    if "author" in entry:
        authors_str = entry["author"]
        # Split by "and" and parse names
        author_list = [a.strip() for a in authors_str.split(" and ")]
        item["creators"] = []
        for author in author_list:
            # Handle "Last, First" or "First Last" formats
            if "," in author:
                parts = author.split(",", 1)
                last_name = parts[0].strip()
                first_name = parts[1].strip() if len(parts) > 1 else ""
            else:
                # Assume last word is last name
                parts = author.rsplit(None, 1)
                first_name = parts[0] if len(parts) > 1 else ""
                last_name = parts[-1]

            item["creators"].append(
                {
                    "creatorType": "author",
                    "firstName": first_name,
                    "lastName": last_name,
                }
            )

    # Add publisher
    if "publisher" in entry:
        item["publisher"] = entry["publisher"]

    # Add keywords as tags
    if "keywords" in entry:
        keywords = entry["keywords"]
        # Split by comma
        tags = [{"tag": k.strip()} for k in keywords.split(",")]
        item["tags"] = tags

    # Add abstract if available
    if "abstract" in entry:
        item["abstractNote"] = entry["abstract"]

    # Store the BibTeX key for reference
    if "ID" in entry:
        item["extra"] += f"BibTeX: {entry['ID']}\n"

    return item


def get_existing_items(zot: zotero.Zotero, collection_key: str) -> Dict[str, Dict]:
    """
    Retrieve all existing items in the collection.
    Returns a dict mapping DOI to item data.
    """
    lgr.info(f"Fetching existing items from collection {collection_key}")

    # Fetch all items with pagination
    all_items = []
    start = 0
    limit = 100

    while True:
        lgr.debug(f"Fetching items starting at {start}, limit {limit}")
        items = zot.collection_items(collection_key, limit=limit, start=start)
        if not items:
            break
        all_items.extend(items)
        lgr.debug(f"Fetched {len(items)} items, total so far: {len(all_items)}")
        if len(items) < limit:
            # Last page
            break
        start += limit

    lgr.info(f"Fetched total of {len(all_items)} items from collection")

    doi_map = {}
    for item in all_items:
        # Skip notes, attachments, etc.
        if item["data"].get("itemType") in ["note", "attachment"]:
            continue

        # Try to extract DOI from the item
        doi = item["data"].get("DOI", "")
        if not doi and "extra" in item["data"]:
            # Try to extract DOI from extra field
            for line in item["data"]["extra"].split("\n"):
                if line.startswith("DOI:"):
                    doi = line.split(":", 1)[1].strip()
                    break

        if doi:
            # Normalize DOI to lowercase for case-insensitive comparison
            doi_map[doi.lower()] = item

    lgr.info(f"Found {len(doi_map)} existing items with DOIs in collection")
    return doi_map


def items_are_different(existing: Dict, new: Dict) -> bool:
    """
    Compare two items to see if they're different.
    Returns True if update is needed.
    """
    # Compare key fields
    fields_to_compare = ["title", "date", "url", "abstractNote", "publisher"]

    for field in fields_to_compare:
        existing_val = existing.get(field, "").strip()
        new_val = new.get(field, "").strip()
        if existing_val != new_val:
            return True

    # Compare creators
    existing_creators = existing.get("creators", [])
    new_creators = new.get("creators", [])

    if len(existing_creators) != len(new_creators):
        return True

    for ex_creator, new_creator in zip(existing_creators, new_creators):
        if ex_creator.get("lastName") != new_creator.get("lastName") or ex_creator.get(
            "firstName"
        ) != new_creator.get("firstName"):
            return True

    # Compare tags
    existing_tags = {t.get("tag", "") for t in existing.get("tags", [])}
    new_tags = {t.get("tag", "") for t in new.get("tags", [])}

    if existing_tags != new_tags:
        return True

    return False


def update_zotero_collection(
    zot: zotero.Zotero,
    collection_key: str,
    bib_entries: List[Dict],
    dry_run: bool = False,
    min_match_threshold: float = 0.95,
) -> None:
    """
    Update the Zotero collection with entries from BibTeX file.
    """
    # Get existing items
    existing_items = get_existing_items(zot, collection_key)

    # Build local DOI set (case-insensitive)
    local_dois = set()
    for entry in bib_entries:
        doi = entry.get("doi", "")
        if doi:
            local_dois.add(doi.lower())

    lgr.info(f"Local BibTeX file has {len(local_dois)} unique DOIs")

    # Validation: Check how many existing Zotero items are found locally
    if existing_items:
        matched_count = 0
        unmatched_dois = []

        for existing_doi, item in existing_items.items():
            if existing_doi in local_dois:
                matched_count += 1
            else:
                unmatched_dois.append(existing_doi)

        match_rate = matched_count / len(existing_items)
        lgr.info(
            f"Match validation: {matched_count}/{len(existing_items)} "
            f"({match_rate:.1%}) of existing Zotero items found in local BibTeX"
        )

        if match_rate < min_match_threshold:
            lgr.error(
                f"VALIDATION FAILED: Only {match_rate:.1%} of existing Zotero items "
                f"were found in the local BibTeX file (threshold: {min_match_threshold:.1%})"
            )
            lgr.error(f"Missing {len(unmatched_dois)} items from local BibTeX:")
            for doi in unmatched_dois[:10]:  # Show first 10
                lgr.error(f"  - {doi}")
            if len(unmatched_dois) > 10:
                lgr.error(f"  ... and {len(unmatched_dois) - 10} more")
            lgr.error(
                "This suggests either:\n"
                "  1. Local BibTeX file is incomplete/outdated\n"
                "  2. Zotero collection has items not in DANDI archive\n"
                "  3. DOI mismatch between local and remote\n"
                "Aborting to prevent data loss. Use --force to override (not yet implemented)."
            )
            sys.exit(1)

        lgr.info("Validation passed! Proceeding with sync...")
    else:
        lgr.info("No existing items in Zotero collection, will add all new items")

    # Track what we do
    added_count = 0
    updated_count = 0
    skipped_count = 0
    error_count = 0

    # Process each BibTeX entry
    for entry in bib_entries:
        # Skip entries without DOI (they're usually aliases)
        doi = entry.get("doi", "")
        if not doi:
            lgr.debug(f"Skipping entry {entry.get('ID', 'unknown')} - no DOI")
            continue

        doi_lower = doi.lower()

        try:
            # Convert to Zotero format
            new_item = bibtex_to_zotero_item(entry)

            if doi_lower in existing_items:
                # Item exists - check if update is needed
                existing = existing_items[doi_lower]
                if items_are_different(existing["data"], new_item):
                    lgr.info(f"Updating item: {entry.get('ID', 'unknown')} - {doi}")
                    if not dry_run:
                        # Update the item
                        new_item["version"] = existing["version"]
                        new_item["key"] = existing["key"]
                        zot.update_item(new_item)
                    updated_count += 1
                else:
                    lgr.debug(f"Skipping unchanged item: {doi}")
                    skipped_count += 1
            else:
                # New item - add it
                lgr.info(f"Adding new item: {entry.get('ID', 'unknown')} - {doi}")
                if not dry_run:
                    # Create item and add to collection
                    created = zot.create_items([new_item])
                    if created and "successful" in created:
                        zot.addto_collection(collection_key, created["successful"]["0"])
                added_count += 1

        except Exception as e:
            lgr.error(f"Error processing entry {entry.get('ID', 'unknown')}: {e}")
            error_count += 1
            continue

    # Summary
    lgr.info("=" * 60)
    lgr.info("Summary:")
    lgr.info(f"  Added: {added_count}")
    lgr.info(f"  Updated: {updated_count}")
    lgr.info(f"  Skipped (unchanged): {skipped_count}")
    lgr.info(f"  Errors: {error_count}")
    if dry_run:
        lgr.info("  (DRY RUN - no changes made)")


def main():
    parser = argparse.ArgumentParser(
        description="Update Zotero collection with BibTeX entries"
    )
    parser.add_argument(
        "--api-key",
        type=str,
        required=True,
        help="Zotero API key (get from https://www.zotero.org/settings/keys)",
    )
    parser.add_argument(
        "--group-id",
        type=str,
        default="5774211",
        help="Zotero group ID (default: 5774211)",
    )
    parser.add_argument(
        "--collection-key",
        type=str,
        default="T8I34DL3",
        help="Zotero collection key (default: T8I34DL3)",
    )
    parser.add_argument(
        "--bibfile",
        type=str,
        default="dandi.bib",
        help="Path to BibTeX file (default: dandi.bib)",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="Dry run mode - don't actually make changes",
    )
    parser.add_argument(
        "-v",
        "--verbose",
        action="store_true",
        help="Verbose logging (DEBUG level)",
    )
    parser.add_argument(
        "--min-match-threshold",
        type=float,
        default=0.95,
        help="Minimum match rate threshold for validation (default: 0.95 = 95%%)",
    )

    args = parser.parse_args()

    if args.verbose:
        lgr.setLevel(logging.DEBUG)

    # Parse BibTeX file
    bib_entries = parse_bibtex_file(args.bibfile)

    # Connect to Zotero
    lgr.info("Connecting to Zotero API...")
    zot = zotero.Zotero(args.group_id, "group", args.api_key)

    # Update collection
    update_zotero_collection(
        zot, args.collection_key, bib_entries, args.dry_run, args.min_match_threshold
    )

    lgr.info("Done!")


if __name__ == "__main__":
    main()
