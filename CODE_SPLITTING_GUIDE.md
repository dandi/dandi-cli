# Code Splitting Guide for bids-duckdb

This guide shows exactly how to split `dandi/bids_duckdb.py` into the standalone package structure.

## Module Structure

```
src/bids_duckdb/
├── __init__.py       # Public API exports
├── schema.py         # Schema fetching and parsing
├── loader.py         # Main BIDSDuckDBLoader class
├── cli.py           # Command-line interface (optional)
├── _version.py      # Auto-generated by setuptools-scm
└── py.typed         # PEP 561 type marker
```

## 1. schema.py

Extract these components from `dandi/bids_duckdb.py`:

```python
"""BIDS schema fetching and parsing utilities."""

from __future__ import annotations

from functools import lru_cache
from typing import Any
from urllib.request import urlopen

try:
    import yaml
    HAS_YAML = True
except ImportError:
    HAS_YAML = False


class BIDSSchemaError(Exception):
    """Raised when there's an error loading or parsing the BIDS schema."""
    pass


@lru_cache(maxsize=1)
def fetch_bids_schema(
    schema_url: str = "https://raw.githubusercontent.com/bids-standard/bids-specification/master/src/schema/objects/entities.yaml",
) -> dict[str, dict[str, Any]]:
    """
    Fetch and parse the BIDS schema from the official specification.

    [Copy full docstring and implementation from dandi/bids_duckdb.py]
    """
    if not HAS_YAML:
        raise BIDSSchemaError(
            "PyYAML is required to parse BIDS schema. Install with: pip install pyyaml"
        )

    try:
        with urlopen(schema_url) as response:
            schema_yaml = response.read().decode("utf-8")
        schema = yaml.safe_load(schema_yaml)
        return schema
    except Exception as e:
        raise BIDSSchemaError(f"Failed to fetch or parse BIDS schema: {e}") from e


def get_entity_patterns(
    schema: dict[str, dict[str, Any]] | None = None,
) -> dict[str, str]:
    """
    Generate regex patterns for extracting BIDS entities from filenames.

    [Copy full docstring and implementation from dandi/bids_duckdb.py]
    """
    if schema is None:
        schema = fetch_bids_schema()

    entity_map = {}
    for entity_key, entity_props in schema.items():
        name = entity_props.get("name")
        display_name = entity_props.get("display_name")
        if name and display_name:
            col_name = display_name.lower().replace(" ", "_").replace("-", "_")
            entity_map[col_name] = name

    return entity_map
```

## 2. loader.py

Keep the main loader class:

```python
"""Main BIDSDuckDBLoader class for loading BIDS datasets into DuckDB."""

from __future__ import annotations

from pathlib import Path
from typing import Any, Optional

try:
    import duckdb
    from duckdb import DuckDBPyConnection
    HAS_DUCKDB = True
except ImportError:
    HAS_DUCKDB = False
    DuckDBPyConnection = Any

# Import from schema module
from .schema import fetch_bids_schema, get_entity_patterns


class DuckDBNotInstalledError(ImportError):
    """Raised when DuckDB is required but not installed."""

    def __init__(self) -> None:
        super().__init__(
            "DuckDB is required but not installed. "
            "Install it with: pip install duckdb"
        )


class BIDSDuckDBLoader:
    """
    Load BIDS datasets into DuckDB with schema-driven entity extraction.

    [Copy full class implementation from dandi/bids_duckdb.py]
    """

    def __init__(
        self,
        bids_root: Path,
        db_path: Optional[str] = None,
        schema_url: Optional[str] = None,
    ):
        # [Copy full implementation]
        pass

    # [Copy all methods...]
```

## 3. __init__.py

Create the public API:

```python
"""
BIDS to DuckDB loader with schema-driven entity extraction.

This package provides tools to load BIDS datasets into DuckDB for
efficient querying and analysis of neuroimaging metadata.

Example:
    >>> from pathlib import Path
    >>> from bids_duckdb import BIDSDuckDBLoader
    >>>
    >>> with BIDSDuckDBLoader(Path("/path/to/bids")) as loader:
    ...     loader.load_participants()
    ...     loader.load_sidecar_json()
    ...     df = loader.query("SELECT * FROM participants")
"""

from __future__ import annotations

from .loader import BIDSDuckDBLoader, DuckDBNotInstalledError
from .schema import BIDSSchemaError, fetch_bids_schema, get_entity_patterns

try:
    from ._version import version as __version__
except ImportError:
    __version__ = "unknown"

__all__ = [
    "BIDSDuckDBLoader",
    "DuckDBNotInstalledError",
    "BIDSSchemaError",
    "fetch_bids_schema",
    "get_entity_patterns",
    "__version__",
]


def __dir__() -> list[str]:
    return list(__all__)
```

## 4. cli.py (Optional)

Add a command-line interface:

```python
"""Command-line interface for bids-duckdb."""

from __future__ import annotations

import argparse
import sys
from pathlib import Path

from .loader import BIDSDuckDBLoader


def main() -> int:
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        prog="bids-duckdb",
        description="Load BIDS datasets into DuckDB for analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Load all data into in-memory database
  bids-duckdb /path/to/bids --load-all

  # Create persistent database file
  bids-duckdb /path/to/bids --output bids.duckdb --load-all

  # Use specific BIDS version
  bids-duckdb /path/to/bids --schema-url https://raw.githubusercontent.com/.../v1.9.0/.../entities.yaml
        """,
    )
    parser.add_argument(
        "bids_root",
        type=Path,
        help="Path to BIDS dataset root directory",
    )
    parser.add_argument(
        "--output",
        "-o",
        type=Path,
        help="Output DuckDB database file (default: in-memory)",
    )
    parser.add_argument(
        "--schema-url",
        help="URL to BIDS schema entities.yaml (default: latest master)",
    )
    parser.add_argument(
        "--load-all",
        action="store_true",
        help="Load all data types (participants, JSON sidecars, TSV files)",
    )
    parser.add_argument(
        "--datatype",
        help="Filter to specific datatype (e.g., 'func', 'anat')",
    )
    parser.add_argument(
        "--info",
        action="store_true",
        help="Show schema information and exit",
    )
    parser.add_argument(
        "--version",
        action="store_true",
        help="Show version and exit",
    )

    args = parser.parse_args()

    # Handle version
    if args.version:
        from . import __version__
        print(f"bids-duckdb {__version__}")
        return 0

    # Validate BIDS root
    if not args.bids_root.exists():
        print(f"Error: BIDS root not found: {args.bids_root}", file=sys.stderr)
        return 1

    try:
        # Create loader
        with BIDSDuckDBLoader(
            args.bids_root,
            db_path=str(args.output) if args.output else None,
            schema_url=args.schema_url,
        ) as loader:

            # Show info and exit
            if args.info:
                info = loader.get_schema_info()
                print(f"BIDS Schema Information:")
                print(f"  Total entities: {info['num_entities']}")
                print(f"  Entities: {', '.join(info['entity_names'])}")
                return 0

            # Load data
            if args.load_all:
                print(f"Loading BIDS dataset from: {args.bids_root}")

                # Load participants
                try:
                    loader.load_participants()
                    print("  ✓ Loaded participants.tsv")
                except FileNotFoundError:
                    print("  ⚠ No participants.tsv found")
                except Exception as e:
                    print(f"  ✗ Error loading participants: {e}")

                # Load JSON sidecars
                try:
                    loader.load_sidecar_json(datatype=args.datatype)
                    print("  ✓ Loaded JSON sidecars")
                except Exception as e:
                    print(f"  ✗ Error loading JSON: {e}")

                # Load TSV files
                try:
                    loader.load_tsv_files()
                    print("  ✓ Loaded TSV files")
                except Exception as e:
                    print(f"  ✗ Error loading TSV: {e}")

                # Show summary
                tables = loader.get_tables()
                print(f"\nCreated {len(tables)} tables: {', '.join(tables)}")

                if args.output:
                    print(f"\n✓ Saved to: {args.output}")
                    print(f"\nTo query later:")
                    print(f"  import duckdb")
                    print(f"  conn = duckdb.connect('{args.output}')")
                    print(f"  df = conn.execute('SELECT * FROM participants').fetchdf()")
                else:
                    print("\nUse --output to save to a file for later querying")

            else:
                # Just show what's available
                info = loader.get_schema_info()
                print(f"BIDS dataset: {args.bids_root}")
                print(f"Available entities: {len(info['entities'])}")
                print(f"\nUse --load-all to load data")
                print(f"Use --info to see entity details")

        return 0

    except Exception as e:
        print(f"Error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
```

Then add to `pyproject.toml`:

```toml
[project.scripts]
bids-duckdb = "bids_duckdb.cli:main"
```

## 5. Update Tests

In `tests/test_loader.py`, update imports:

```python
# Change from:
from dandi.bids_duckdb import BIDSDuckDBLoader, fetch_bids_schema, get_entity_patterns

# To:
from bids_duckdb import BIDSDuckDBLoader, fetch_bids_schema, get_entity_patterns
```

Create `tests/test_schema.py`:

```python
"""Tests for BIDS schema fetching and parsing."""

import pytest

from bids_duckdb.schema import BIDSSchemaError, fetch_bids_schema, get_entity_patterns


def test_fetch_bids_schema() -> None:
    """Test fetching and parsing the BIDS schema."""
    schema = fetch_bids_schema()

    assert isinstance(schema, dict)
    assert len(schema) > 0
    assert "subject" in schema
    assert schema["subject"]["name"] == "sub"
    assert "session" in schema
    assert schema["session"]["name"] == "ses"


def test_get_entity_patterns() -> None:
    """Test entity pattern extraction from schema."""
    patterns = get_entity_patterns()

    assert isinstance(patterns, dict)
    assert len(patterns) > 0
    assert "subject" in patterns
    assert patterns["subject"] == "sub"


def test_get_entity_patterns_with_custom_schema() -> None:
    """Test using custom schema."""
    custom_schema = {
        "subject": {
            "name": "sub",
            "display_name": "Subject",
        },
        "session": {
            "name": "ses",
            "display_name": "Session",
        },
    }

    patterns = get_entity_patterns(custom_schema)
    assert patterns == {"subject": "sub", "session": "ses"}


def test_fetch_bids_schema_caching() -> None:
    """Test that schema is cached."""
    schema1 = fetch_bids_schema()
    schema2 = fetch_bids_schema()

    # Should be the exact same object (cached)
    assert schema1 is schema2
```

## 6. Update Examples

In `examples/basic_usage.py`, update imports:

```python
# Change from:
from dandi.bids_duckdb import BIDSDuckDBLoader

# To:
from bids_duckdb import BIDSDuckDBLoader
```

## Quick Reference: Import Changes

| Old Import (dandi-cli) | New Import (bids-duckdb) |
|------------------------|--------------------------|
| `from dandi.bids_duckdb import BIDSDuckDBLoader` | `from bids_duckdb import BIDSDuckDBLoader` |
| `from dandi.bids_duckdb import fetch_bids_schema` | `from bids_duckdb import fetch_bids_schema` |
| `from dandi.bids_duckdb import get_entity_patterns` | `from bids_duckdb import get_entity_patterns` |

## Validation Checklist

After splitting the code:

- [ ] All imports updated
- [ ] Tests pass: `pytest`
- [ ] Type checking passes: `mypy src`
- [ ] Linting passes: `black src tests && isort src tests`
- [ ] Package installs: `pip install -e .`
- [ ] CLI works: `bids-duckdb --help`
- [ ] Examples run: `python examples/basic_usage.py`
- [ ] Documentation builds (if using mkdocs/sphinx)

## Testing the Split

```bash
# Create test environment
python -m venv test_env
source test_env/bin/activate  # or test_env\Scripts\activate on Windows

# Install in development mode
pip install -e ".[dev]"

# Run tests
pytest -v

# Test CLI
bids-duckdb --help
bids-duckdb --version

# Test import
python -c "from bids_duckdb import BIDSDuckDBLoader; print('✓ Import works')"
```

## Common Issues

### Issue 1: Circular Imports
**Problem**: `loader.py` imports from `schema.py` and vice versa
**Solution**: Keep imports one-way (loader imports schema, not reverse)

### Issue 2: Missing __init__.py
**Problem**: Package not found
**Solution**: Ensure `src/bids_duckdb/__init__.py` exists and exports public API

### Issue 3: Type Checking Errors
**Problem**: mypy can't find modules
**Solution**: Add `py.typed` file and ensure package is installed

### Issue 4: Tests Can't Find Package
**Problem**: `ModuleNotFoundError: No module named 'bids_duckdb'`
**Solution**: Install in editable mode: `pip install -e .`

## Final Steps

After splitting and testing:

1. Commit changes: `git add . && git commit -m "Split code into modular structure"`
2. Create git tag: `git tag v0.1.0`
3. Push to GitHub: `git push && git push --tags`
4. Build package: `python -m build`
5. Test upload: `twine upload --repository testpypi dist/*`
6. Production upload: `twine upload dist/*`
